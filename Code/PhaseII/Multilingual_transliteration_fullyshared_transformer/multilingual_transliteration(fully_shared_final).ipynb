{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "multilingual_transliteration(fully_shared_final).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "s_qNSzzyaCbD"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s_qNSzzyaCbD"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "jmjh290raIky",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "# Transformer model for language understanding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AOpGoE2T-YXS"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/text/transformer\">\n",
        "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
        "    View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/text/transformer.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M-f8TnGpE_ex"
      },
      "source": [
        "This tutorial trains a <a href=\"https://arxiv.org/abs/1706.03762\" class=\"external\">Transformer model</a> to translate Portuguese to English. This is an advanced example that assumes knowledge of [text generation](text_generation.ipynb) and [attention](nmt_with_attention.ipynb).\n",
        "\n",
        "The core idea behind the Transformer model is *self-attention*—the ability to attend to different positions of the input sequence to compute a representation of that sequence. Transformer creates stacks of self-attention layers and is explained below in the sections *Scaled dot product attention* and *Multi-head attention*.\n",
        "\n",
        "A transformer model handles variable-sized input using stacks of self-attention layers instead of [RNNs](text_classification_rnn.ipynb) or [CNNs](../images/intro_to_cnns.ipynb). This general architecture has a number of advantages:\n",
        "\n",
        "* It make no assumptions about the temporal/spatial relationships across the data. This is ideal for processing a set of objects (for example, [StarCraft units](https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/#block-8)).\n",
        "* Layer outputs can be calculated in parallel, instead of a series like an RNN.\n",
        "* Distant items can affect each other's output without passing through many RNN-steps, or convolution layers (see [Scene Memory Transformer](https://arxiv.org/pdf/1903.03878.pdf) for example).\n",
        "* It can learn long-range dependencies. This is a challenge in many sequence tasks.\n",
        "\n",
        "The downsides of this architecture are:\n",
        "\n",
        "* For a time-series, the output for a time-step is calculated from the *entire history* instead of only the inputs and current hidden-state. This _may_ be less efficient.   \n",
        "* If the input *does* have a  temporal/spatial relationship, like text, some positional encoding must be added or the model will effectively see a bag of words. \n",
        "\n",
        "After training the model in this notebook, you will be able to input a Portuguese sentence and return the English translation.\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/attention_map_portuguese.png\" width=\"800\" alt=\"Attention heatmap\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JjJJyJTZYebt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "9fbbf29a-2f9a-44bd-e940-941a26517c86"
      },
      "source": [
        "!pip install tf-nightly\n",
        "import tensorflow as tf\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/ab/5a68ae0d19a84116e807408404a6a6624337fbe30da4a45fc70053a2ea42/tf_nightly-2.2.0.dev20200506-cp36-cp36m-manylinux2010_x86_64.whl (520.9MB)\n",
            "\u001b[K     |████████████████████████████████| 520.9MB 32kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.2.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.34.2)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.10.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.4.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.3.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.28.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.18.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.10.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.6.3)\n",
            "Collecting tb-nightly<2.4.0a0,>=2.3.0a0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/1c/0011ad96768aca0b0e96c16d29084078b5ded06c14e714ab50f132bb5339/tb_nightly-2.3.0a20200506-py3-none-any.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 43.1MB/s \n",
            "\u001b[?25hCollecting tf-estimator-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/28/c1c485ac58540a6c5bacff775893f3a6c0ca4f63a58a442cba2c16cc0449/tf_estimator_nightly-2.3.0.dev2020050601-py2.py3-none-any.whl (456kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 54.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tf-nightly) (46.1.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.6.0.post3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.7.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.1.0)\n",
            "Installing collected packages: tb-nightly, tf-estimator-nightly, tf-nightly\n",
            "Successfully installed tb-nightly-2.3.0a20200506 tf-estimator-nightly-2.3.0.dev2020050601 tf-nightly-2.2.0.dev20200506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bsj_rfWL1AVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fd1NWMxjfsDd"
      },
      "source": [
        "## Setup input pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_yvkorBxWW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# En-Hi pairs\n",
        "drive = GoogleDrive(gauth)\n",
        "link = 'https://drive.google.com/open?id=1lh4phSO2d1qmjWENgIaGdcwpZzYB5i0M'\n",
        "fluff, id = link.split('=')\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('Filename1.txt')  \n",
        "df1 = open('Filename1.txt', 'rb').read().decode(encoding='utf-8')\n",
        "# Dataset is now stored in a Pandas Dataframe\n",
        "df1 = df1.split()\n",
        "df1[0] = \"khushboo\"\n",
        "\n",
        "# En-Gujrati pairs\n",
        "drive = GoogleDrive(gauth)\n",
        "link = 'https://drive.google.com/open?id=1TjTOnK6YA4v1qwB4DHlk-7dwICNVEDw-'\n",
        "fluff, id = link.split('=')\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('Filename2.txt')  \n",
        "df2 = open('Filename2.txt', 'rb').read().decode(encoding='utf-8')\n",
        "# Dataset is now stored in a Pandas Dataframe\n",
        "df2 = df2.split()\n",
        "df2[0] = \"akasmaat\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtibTyUmyaNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataf = []\n",
        "special_words =[]\n",
        "dataf.append(df1)\n",
        "dataf.append(df2)\n",
        "special_words.append('$')\n",
        "special_words.append('#')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqH7JMfWQVds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessWord(list,start):\n",
        "  modifList = []\n",
        "  for w in list:\n",
        "    w = start+w.lower()+\"@\"\n",
        "    modifList.append(w)\n",
        "  return modifList\n",
        "\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "for d,s in zip(dataf,special_words):\n",
        "  input_texts.append(preprocessWord(d[0::2],s))\n",
        "  target_texts.append(preprocessWord(d[1::2],s))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMCZxP6kyzBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_temp = []\n",
        "target_temp = []\n",
        "\n",
        "for input_text,target_text in zip(input_texts,target_texts):\n",
        "  for i in range(len(input_text)):\n",
        "    if(len(input_text[i]) <= 25):\n",
        "      input_temp.append(input_text[i])\n",
        "      target_temp.append(target_text[i])\n",
        "#     print(target_text[i],len(target_text[i]))\n",
        "iptxt = input_texts\n",
        "trgtxt = target_texts\n",
        "input_text = input_temp\n",
        "target_text = target_temp\n",
        "input_vocab = sorted(set(\"\".join(input_text)))\n",
        "target_vocab = sorted(set(\"\".join(target_text)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYNUjtauRy5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sz = 0;\n",
        "tsz =0;\n",
        "for inp_text,targ_text in zip(iptxt,trgtxt):\n",
        "  sz+=len(inp_text)\n",
        "  tsz+=len(targ_text)\n",
        "\n",
        "assert sz == tsz\n",
        "assert sz == len(input_text)\n",
        "assert sz == len(target_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZH34ZtH0Af9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a mapping from unique characters to indices in input text English\n",
        "char2idxEn = {}\n",
        "idx2charEn = {}\n",
        "char2idxEn[\"<\"] = 0\n",
        "for index, word in enumerate(input_vocab):\n",
        "      char2idxEn[word] = index + 1\n",
        "# print(char2idxEn)\n",
        "for word, index in char2idxEn.items():\n",
        "      idx2charEn[index] = word\n",
        "\n",
        "\n",
        "# Creating a mapping from unique characters to indices in input text Hindi\n",
        "char2idxHi = {}\n",
        "idx2charHi = {}\n",
        "char2idxHi[\"<\"] = 0\n",
        "for index, word in enumerate(target_vocab):\n",
        "      char2idxHi[word] = index + 1\n",
        "for word, index in char2idxHi.items():\n",
        "      idx2charHi[index] = word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNrjrlAXWJzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbUIfi8_0H3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getIpTextasInt(c):\n",
        "  f=np.array([ char2idxEn[i] for i in c])\n",
        "  return f\n",
        "\n",
        "def getTargTextasInt(c):\n",
        "  f=np.array([ char2idxHi[i] for i in c])\n",
        "  return f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSzz977U0LM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_text_as_int = np.array([getIpTextasInt(c) for c in input_text])\n",
        "input_char_dataset = [tf.data.Dataset.from_tensor_slices(i) for i in input_text_as_int]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPfkcaje0L-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_text_as_int = np.array([getTargTextasInt(c) for c in target_text])\n",
        "target_char_dataset = [tf.data.Dataset.from_tensor_slices(i) for i in target_text_as_int]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLBAK8J10TsH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ac590ec-0256-44a6-d207-bec895ea2583"
      },
      "source": [
        "examples_per_epoch = len(input_text)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = examples_per_epoch//BATCH_SIZE\n",
        "BUFFER_SIZE = 10000\n",
        "steps_per_epoch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "490"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKJro36t0fRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mtr7vcW80ig5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tensor = [];\n",
        "target_tensor = [];\n",
        "for i in range(0, len(input_text)):\n",
        "  input_tensor.append(tf.convert_to_tensor(input_text_as_int[i]))\n",
        "  target_tensor.append(tf.convert_to_tensor(target_text_as_int[i]))\n",
        "maxlen_inp = max_length(input_tensor);\n",
        "maxlen_targ = max_length(input_tensor);\n",
        "input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, padding='post', maxlen = maxlen_inp)\n",
        "target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, padding='post', maxlen = maxlen_targ)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4vO93baaSg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffle_in_unison(a, b):\n",
        "    rng_state = np.random.get_state()\n",
        "    np.random.shuffle(a)\n",
        "    np.random.set_state(rng_state)\n",
        "    np.random.shuffle(b)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOPSM7s6ae9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shuffle_in_unison(input_tensor,target_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aJ0S_yl0vGK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19eecad7-7f3c-4423-80a5-947e9776a3dc"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25095, 25095, 6274, 6274)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYVg9tDeaf8S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4d954439-92db-4dd3-9318-d5359d18d590"
      },
      "source": [
        "for i in input_tensor_train:\n",
        "  if((i[0]==1)):\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1 16 12 23 21 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22  4  4 16 23  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4 23 11 24 21  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 21  8  8 23  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13 24  7  4  4 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19 21  4 14 11 28  4 23  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 10 12 21 17  4 21  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 21 25 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  6 11 11  4 19  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  4 22 23 24 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 17 12 21 16  4 15  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16 18 18 15  5 11 18 18 23  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19 24 21 24 22 11  4 17  8  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4 19  8 14 22 11  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22 11  4 17 23 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19  4  4 22  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5 11  4 25  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4  4 16  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4 15 26  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 15  4  4 10  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22  4 14  4 15 23  4  4 17 18  3  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 23  4 16  4 17  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  6 11 11 18 14 21  4 17  4  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19 21 12 23  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19  4  7  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  4 21 22  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4  4 13 17  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 15 18 14 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 11 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 21 25 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14 28  4 28  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19 21  4 23 11  4 16  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 11  4 12 28  4 16  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22  4 16  4 13 23 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 18  6 11 11 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25 12  7 11 28  4 21 23 11 12 18 17  8  3  0  0  0  0  0  0  0  0]\n",
            "[ 1 13  4 26  4 28  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 10 24 15  4  5 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 21  4 26  4  4 17 18  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 23  4 16  8 23 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 21 25 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13 12 17  7  4 10 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22  4 21 25  4 22 11 21  8 22 11 23 11  4  3  0  0  0  0  0  0  0]\n",
            "[ 1 21  4 13 28  4 17 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22 26  4  7 12 22 11 23 11  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22 18  9 23 26  4 21  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19 24 15  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 15 12 22 18 23  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 11  4 17 12 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 21 24 19 12 28 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22 11 24  5 11 14  4 16 17  4  3  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 15  4  4 10  8 15  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22  4 21 25  4 23 21  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22  4 15  4  4 11  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 21 25  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4 15  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5 11 24 23 14  4  4 15 17 18  3  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14 11 18 18  5  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 17 18  7 11  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 24 13 25  4 17 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19 21  4 22 11 17 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22  4 23  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4 11  4 25 12  7 11 28  4 15  4 28  4  3  0  0  0  0  0  0  0]\n",
            "[ 1  5 11  4  4 21  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 11  8 25  4  4 28  4  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13 18 25  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  4  7 11 23  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4  4 19 23 11 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 10  4 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4  8 17  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25 12 22 11 26  4  4 22  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  9  8 21  4 25 25  4 17 24  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 21  4  7 11  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19  4 11  8 15  4 16  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 11 21  4  7  4 28  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  8 15  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 11 24 17  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 21 12 17  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19  4 21  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4 23  4 17 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  7 11 24 16 21  4 19  4  4 17  3  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19 21  4 14  4  4 22 11  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5  4 17  4 25 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14 28  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22 23 21  8  8 17  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22 11 21  4 25  4 17  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19  4 11 18 28  4 25  4  4 17 24  3  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  6 11 12 17 23  4 17 22 11  8  8 15  3  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 21  4 11 28  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4 17 23 12 16  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13  8 17  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 28  4  4  7  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13 24 17 10 15 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5  4  4 15  4 14 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19 21 18 23 22  4  4 11 12 23  3  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  4 22 23 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 21  4 14 22 11  4  5  4 17  7 11  4 17  3  0  0  0  0  0  0  0  0]\n",
            "[ 1 22  4  9  4 15 23  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  4  4 23 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 10 24 13  4 21  4 23 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4 17  4 17  7  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  6 11 11  8 15 15  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  8  8 21  4 11  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14 11 18 23 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19 21  8  8 23  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4  4 14  4 22 11  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 10  4  4 23 11 12 28  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19 21  4  4 17  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13 18 28 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16 18 23 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19 24 21 23 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5 11  4 21 26  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5 11  4 25 12 22 11 28  4  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 23 11  4  4 25  4 17 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 17  4 28  4 17  4 17  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4 23  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 21  4 13 14 18 23  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 21 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 17 14 18 23  4 21 12  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  7  4  7 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13  4 17 12 23  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 17  8  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 10 28  4  4 17  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 10  4  4 16 16  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4  4 14 11 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 28  4 23 21  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5  4  4 17 17  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 10 24 13  4 21  4 23  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5 18 15  4 25 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  4 10 11  4 21 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19  4 11  8 15  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5  4  7 11 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4  8 14  4 15 23  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  7 11  4  7  4 14  4 16  4  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  4 12 21  4  4 10 28  4  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19  4 21  4 28 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 10  4 17  7 11 12 17  4 10  4 21  3  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22  4 24 23 11 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4 17  7  4 13  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 24 16  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14 11 18 15  4 25  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4  4 25  4 17  4 21  4  4  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 24 16  8 21  4  4 22 11  8  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19  4  4 17  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4 11 18 23 22  4 25  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  6 11  4  4 15 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13  4 15  7 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13  8 16  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4  4 21 23 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13  8  7  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5 11  4 10  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 10 11  4 23 17  4  4 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 15 12  7 11 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14 18 17  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13  4  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19 21  4 25  8 22 11  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4  4  7 11  4 21  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13  4  4 28  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19 24 21 24 17  4  4 16  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 21  4  7  4 25  8  8 17  8  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 17  4 23 11 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19  4 16 19  4 15 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  7 11 18 17 12 17 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4 21  4 17  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 11  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5 18 15  4 25  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4 15 22 11  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16 18 11  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  6 18 15 15  8  6 23 18 21 18 17 12  3  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22  4 17 14 11 28  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  8 14  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 23 28  4  4 21  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4 16  7  4 25  4  4  7 17  4  3  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13  8  8 25  4 25  4  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  7 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 10 18 19 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19 21  4 14 21 12 28  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 12  6 11 11 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13  4 21 24 21 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4 15 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4  4 19 17  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 10  4  4  7 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 24 23  4 25  4 15  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22  4  4 28 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13  4 26  4 17 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 17  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  8  8 21  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4  4 21 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 21 24 28 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4  4  6 11 14 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 17  4 23 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  4  4  7 15 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22  4 16  4 28  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  7 11 26  4 13  4 25  4 11  4 17  3  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 11  4 23 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5 11  4 22 11  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13  4 17  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 21  4 17 10  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16 24 16  5  4 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  7 11 18 14 15  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 23  4 23 19  4 21  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 23 11  4 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25 28  4 19  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 11 12 17  7 18 15  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22  4 17  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14 24 23  6 11  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13  4 12 28  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 23 18 28  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  4 11  4  4 15  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 21  4 17 10 15 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22 26 12 14  4  4 21  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22  4 17 22 23 11  4 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 10 12 21  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5 11  4 21  4 23  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22  4 16  4 21 19  4 17  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19 21  8 16  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  6 11  4  4 15 23 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  6 11 11 18 14 21 12 17  4  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4 24 23  4 11  4 22 12 14  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  7  8 14 11  4 28  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22  4 19  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16 24 14 23 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[1 4 8 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[ 1 23  8 17 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14 11  4 25  4 23 11 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 28 18 16  4 22 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4  4 21 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 28  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4  4 11  4 23  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22 23 11  4 15 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  6 11 11 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5  4  7 15  4  4 23  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4 11 12 17  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4  4 22 19  4  4 22 16  4  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4  4 17  4 22  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5 11  8 10 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[1 4 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[ 1 22 11  4 11 21 24 14 11  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 24 17 10 11  4 28  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 21 23 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  7  8 15 11 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22  4 16  4  4 25 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 23  4 16  4  4 21 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14 28  4 21  8 28  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4 16  4 22 23  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22  4 14 21 12 28  4 23  4  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13  4 23 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 23 11 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  4 21 22 11  4 17  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4  4 25 28  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  4 28 28  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4  4 19 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5  4 22 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22 24 14 11 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 17  4 25 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 23  4 15 25  4  4 21 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5 11 24 15  4 23  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  8 23 15 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4 21 28  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22 26  4 23  4 17 23 21 28  4  3  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  6 11  4 21  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4 17 24 22 11 28  4 17  8  3  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  6 11  8 17 17  4 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  8 23 15  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  4 22 23 12  4  4 17 14  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 21 12 23  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19  4 22  4 17  7 10 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13  8  8 25  4 17  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 25 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  4 21 22 11  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22 24 17  7  4 21  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16 24 14 11  4 21 13  8  8  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 21 22 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 11  4  4 21 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5  8 11 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19  4  7  4 28 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 21  4  4 13  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4  8 23 15 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22 24 21 28  4 22 23  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22 24 14 11  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19  4  7 11  7 11  4 23 12  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  8 23 15 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4 17  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4 22 11  8  8 17 18 17 12  3  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 23 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 21 25 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 10  4 21  5  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  8 24 21 18 19  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  4  4 10 28  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5 11  4  4 10 28  4 25  4 17 23  3  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 23  8 17  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22 11  4 14 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  8  8 23 11  4 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 23  8 14 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 17  4  9 21  4 23  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  8  8 13  8 23  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22 11 26  4  4 22  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 17  4  4 11 25  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 15  4 17 14  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13  4 15  8  5 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 21  4 17 10 15 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22 11 26  4 22  4 16  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 15  8 25  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19 18 18 21 17  4 25 12 21  4 16  3  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 17 24 14 22  4  4 17  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22  4 17 10 11  4 21 22 11  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 23  4 16  4 21  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 23  4 17  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 21 18 17 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22 16 21  4 23 12 15  4 14 22 11 12  3  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19 21  8 16 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 21 23  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22  4 16 13 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4  8 14  4 17 23  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4  4 21 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  4 10  4 21  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22 24  7 11 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 15  4 10  5 11  4 10  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19  4  4 22  8 23 11 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22 11  4 14  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5 11  4  4 10 28  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4 23  8 17 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14 11  4 21  6 11  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 23  4 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 23 11 18  7 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  7 24 17 10 15 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 11  4 13 21 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19 12 23  4 17 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  4 10 11  4 21  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 11  4 23 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 24 23  4  4 21 25  4  4 17 12  3  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13 12 15 15  4 16  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 12 22 11 26  4 21  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13  4 28  4  4 21  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4  7 11  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4 16  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14 28  4  4 21  8 14  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25 12 22 11 26  4 17 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 15  8  8 15 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19  4 17  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5  4 11 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  8 11  4 21  5  4 17 12  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5  4 17  7 11  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 24 23 23  4 21  4 14 11  4 17  7  3  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4 11  4 23 25  4 17 12  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13  4  4 25  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19  4 21 12 14 22 11  4 18  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4 17  8 14  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  4 21 23  4 16  4  4 17 17  8  3  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22 11 18  7 11  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4 14 22 11  4 21  7 11  4 16  3  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 10  4 16 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  6 11 18 21 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  6 11  4  7  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 21  4 17 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 23 21  4 17  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25 12 28 18 10  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4  8 17 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 17  4 11 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  6 11  4  4 15 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  6 11  4  4 15 23 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22  8  8 14 11 25  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  6 11  4 14  7 18 15  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 21  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 17  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16 18 23 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 23 11  4 28 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  4  4 10  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  7 18 18 21  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25 28  4 22  4 17  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22 24 14 12  5 11  4 13 12  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 25 12 23  4 22 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  4 17 29  4 21  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  7 11 12 21  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4 23 21  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 11  4 23 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 23 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  4  4 21  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 17  4 25  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14 28  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  7 12 25  4 22  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5  4 10  7 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5  4 10 11  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4 28  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 11 17 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4 17 16  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  7 21 12  7 11  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 15  4 28  4 14  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 17  4  4 16  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4 17 21  4  7 11  4 21  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  4 21 22  4  4  7  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 21 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  6 11 12 23 21 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  8 11  4 17  7 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  4 21 22 11  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  4  4 11  4 15  4  7  4 14  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19  4 21 25 17 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 15  8  8 15 18 23  4 21 12  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4 15 12 17  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14 11  8  6 11  4  4 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 11  4 12 28  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14 11  4  5  4 21  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 13  4 17  4 25 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19  4  8  7 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 25  4 12 22 11 17  4 25  4  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19  4 21  4 13 12 23  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4  4 17 10 23  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4  7  4  7  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  6 11 11 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22  8 25  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 23 11  8 19 15  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5 18 15 22 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19 24 22 23  4 14 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 15  4 15 13 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19 12  7 12 23 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 23  8 25 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19  8  8  7  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  6 11 11  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[1 5 8 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[ 1  4  8 14 16  4 23 21  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 19  4  6 11 11  4  7 17 12  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 17  4 23  4 14  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 17 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 22  4 21 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 10 11  4 17 12 14 11  4 21 12  3  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1  5  4  4 23  4 21  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4 21  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 10  4 28 24  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 16  4 11 12 15  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 14  4  7 18 17 12  4 17 12  3  0  0  0  0  0  0  0  0  0  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G28qapZV1IIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor)\n",
        "BATCH_SIZE = 64\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "embedding_dim = 512\n",
        "d_model = 512\n",
        "num_heads = 8\n",
        "input_vocab_size = len(input_vocab)\n",
        "target_vocab_size = len(target_vocab)\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_fXvfYVfQr2n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d0c4098a-bcb1-4c33-d2ac-646ea0872605"
      },
      "source": [
        "char2idxHi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'#': 1,\n",
              " '$': 2,\n",
              " '<': 0,\n",
              " '@': 3,\n",
              " 'ँ': 4,\n",
              " 'ं': 5,\n",
              " 'ः': 6,\n",
              " 'अ': 7,\n",
              " 'आ': 8,\n",
              " 'इ': 9,\n",
              " 'ई': 10,\n",
              " 'उ': 11,\n",
              " 'ऊ': 12,\n",
              " 'ए': 13,\n",
              " 'ऐ': 14,\n",
              " 'ऑ': 15,\n",
              " 'ओ': 16,\n",
              " 'औ': 17,\n",
              " 'क': 18,\n",
              " 'ख': 19,\n",
              " 'ग': 20,\n",
              " 'घ': 21,\n",
              " 'च': 22,\n",
              " 'छ': 23,\n",
              " 'ज': 24,\n",
              " 'झ': 25,\n",
              " 'ट': 26,\n",
              " 'ठ': 27,\n",
              " 'ड': 28,\n",
              " 'ढ': 29,\n",
              " 'ण': 30,\n",
              " 'त': 31,\n",
              " 'थ': 32,\n",
              " 'द': 33,\n",
              " 'ध': 34,\n",
              " 'न': 35,\n",
              " 'प': 36,\n",
              " 'फ': 37,\n",
              " 'ब': 38,\n",
              " 'भ': 39,\n",
              " 'म': 40,\n",
              " 'य': 41,\n",
              " 'र': 42,\n",
              " 'ल': 43,\n",
              " 'ळ': 44,\n",
              " 'व': 45,\n",
              " 'श': 46,\n",
              " 'ष': 47,\n",
              " 'स': 48,\n",
              " 'ह': 49,\n",
              " '़': 50,\n",
              " 'ा': 51,\n",
              " 'ि': 52,\n",
              " 'ी': 53,\n",
              " 'ु': 54,\n",
              " 'ू': 55,\n",
              " 'ृ': 56,\n",
              " 'े': 57,\n",
              " 'ै': 58,\n",
              " 'ॉ': 59,\n",
              " 'ो': 60,\n",
              " 'ौ': 61,\n",
              " '्': 62,\n",
              " 'क़': 63,\n",
              " 'ख़': 64,\n",
              " 'ग़': 65,\n",
              " 'ज़': 66,\n",
              " 'ड़': 67,\n",
              " 'ढ़': 68,\n",
              " 'फ़': 69,\n",
              " 'ં': 70,\n",
              " 'અ': 71,\n",
              " 'આ': 72,\n",
              " 'ઇ': 73,\n",
              " 'ઈ': 74,\n",
              " 'ઉ': 75,\n",
              " 'ઊ': 76,\n",
              " 'ઍ': 77,\n",
              " 'એ': 78,\n",
              " 'ઐ': 79,\n",
              " 'ઓ': 80,\n",
              " 'ક': 81,\n",
              " 'ખ': 82,\n",
              " 'ગ': 83,\n",
              " 'ઘ': 84,\n",
              " 'ચ': 85,\n",
              " 'છ': 86,\n",
              " 'જ': 87,\n",
              " 'ઝ': 88,\n",
              " 'ઞ': 89,\n",
              " 'ટ': 90,\n",
              " 'ઠ': 91,\n",
              " 'ડ': 92,\n",
              " 'ઢ': 93,\n",
              " 'ણ': 94,\n",
              " 'ત': 95,\n",
              " 'થ': 96,\n",
              " 'દ': 97,\n",
              " 'ધ': 98,\n",
              " 'ન': 99,\n",
              " 'પ': 100,\n",
              " 'ફ': 101,\n",
              " 'બ': 102,\n",
              " 'ભ': 103,\n",
              " 'મ': 104,\n",
              " 'ય': 105,\n",
              " 'ર': 106,\n",
              " 'લ': 107,\n",
              " 'ળ': 108,\n",
              " 'વ': 109,\n",
              " 'શ': 110,\n",
              " 'ષ': 111,\n",
              " 'સ': 112,\n",
              " 'હ': 113,\n",
              " 'ા': 114,\n",
              " 'િ': 115,\n",
              " 'ી': 116,\n",
              " 'ુ': 117,\n",
              " 'ૂ': 118,\n",
              " 'ૃ': 119,\n",
              " 'ે': 120,\n",
              " 'ૈ': 121,\n",
              " 'ો': 122,\n",
              " 'ૌ': 123,\n",
              " '્': 124}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nBQuibYA4n0n"
      },
      "source": [
        "## Positional encoding\n",
        "\n",
        "Since this model doesn't contain any recurrence or convolution, positional encoding is added to give the model some information about the relative position of the words in the sentence. \n",
        "\n",
        "The positional encoding vector is added to the embedding vector. Embeddings represent a token in a d-dimensional space where tokens with similar meaning will be closer to each other. But the embeddings do not encode the relative position of words in a sentence. So after adding the positional encoding, words will be closer to each other based on the *similarity of their meaning and their position in the sentence*, in the d-dimensional space.\n",
        "\n",
        "See the notebook on [positional encoding](https://github.com/tensorflow/examples/blob/master/community/en/position_encoding.ipynb) to learn more about it. The formula for calculating the positional encoding is as follows:\n",
        "\n",
        "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
        "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WhIOZjMNKujn",
        "colab": {}
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1Rz82wEs5biZ",
        "colab": {}
      },
      "source": [
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  \n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "  \n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    \n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    \n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1kLCla68EloE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "3b08fe4f-84c8-453a-f23e-2ae5bcfe594d"
      },
      "source": [
        "pos_encoding = positional_encoding(50, 512)\n",
        "print (pos_encoding.shape)\n",
        "\n",
        "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0, 512))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 50, 512)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a_b4ou4TYqUN"
      },
      "source": [
        "## Masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s42Uydjkv0hF"
      },
      "source": [
        "Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value `0` is present: it outputs a `1` at those locations, and a `0` otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U2i8-e1s8ti9",
        "colab": {}
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  \n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A7BYeBCNvi7n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "91541609-c38e-4b05-eeff-809fe0d4fbfd"
      },
      "source": [
        "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
        "create_padding_mask(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
              "array([[[[0., 0., 1., 1., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., 1., 1.]]],\n",
              "\n",
              "\n",
              "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z0hzukDBgVom"
      },
      "source": [
        "The look-ahead mask is used to mask the future tokens in a sequence. In other words, the mask indicates which entries should not be used.\n",
        "\n",
        "This means that to predict the third word, only the first and second word will be used. Similarly to predict the fourth word, only the first, second and the third word will be used and so on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dVxS8OPI9uI0",
        "colab": {}
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yxKGuXxaBeeE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "eb28bc75-7275-4b9d-e5ef-0b905a7244eb"
      },
      "source": [
        "x = tf.random.uniform((1, 3))\n",
        "temp = create_look_ahead_mask(x.shape[1])\n",
        "temp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[0., 1., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xluDl5cXYy4y"
      },
      "source": [
        "## Scaled dot product attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vsxEE_-Wa1gF"
      },
      "source": [
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/scaled_attention.png\" width=\"500\" alt=\"scaled_dot_product_attention\">\n",
        "\n",
        "The attention function used by the transformer takes three inputs: Q (query), K (key), V (value). The equation used to calculate the attention weights is:\n",
        "\n",
        "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$\n",
        "\n",
        "The dot-product attention is scaled by a factor of square root of the depth. This is done because for large values of depth, the dot product grows large in magnitude pushing the softmax function where it has small gradients resulting in a very hard softmax. \n",
        "\n",
        "For example, consider that `Q` and `K` have a mean of 0 and variance of 1. Their matrix multiplication will have a mean of 0 and variance of `dk`. Hence, *square root of `dk`* is used for scaling (and not any other number) because the matmul of `Q` and `K` should have a mean of 0 and variance of 1, and you get a gentler softmax.\n",
        "\n",
        "The mask is multiplied with -1e9 (close to negative infinity). This is done because the mask is summed with the scaled matrix multiplication of Q and K and is applied immediately before a softmax. The goal is to zero out these cells, and large negative inputs to softmax are near zero in the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LazzUq3bJ5SH",
        "colab": {}
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead) \n",
        "  but it must be broadcastable for addition.\n",
        "  \n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable \n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "    \n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FiqETnhCkoXh"
      },
      "source": [
        "As the softmax normalization is done on K, its values decide the amount of importance given to Q.\n",
        "\n",
        "The output represents the multiplication of the attention weights and the V (value) vector. This ensures that the words you want to focus on are kept as-is and the irrelevant words are flushed out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n90YjClyInFy",
        "colab": {}
      },
      "source": [
        "def print_out(q, k, v):\n",
        "  temp_out, temp_attn = scaled_dot_product_attention(\n",
        "      q, k, v, None)\n",
        "  print ('Attention weights are:')\n",
        "  print (temp_attn)\n",
        "  print ('Output is:')\n",
        "  print (temp_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yAzUAf2DPlNt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "22d018e0-6ff9-444a-fba8-f1d7cce7d437"
      },
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "temp_k = tf.constant([[10,0,0],\n",
        "                      [0,10,0],\n",
        "                      [0,0,10],\n",
        "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
        "\n",
        "temp_v = tf.constant([[   1,0],\n",
        "                      [  10,0],\n",
        "                      [ 100,5],\n",
        "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
        "\n",
        "# This `query` aligns with the second `key`,\n",
        "# so the second `value` is returned.\n",
        "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention weights are:\n",
            "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
            "Output is:\n",
            "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zg6k-fGhgXra",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "76070967-b8e7-4456-85bd-f792d25ad47a"
      },
      "source": [
        "# This query aligns with a repeated key (third and fourth), \n",
        "# so all associated values get averaged.\n",
        "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention weights are:\n",
            "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
            "Output is:\n",
            "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UAq3YOzUgXhb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ce6ee04f-a0ae-43b4-f5e5-3f6c82de267d"
      },
      "source": [
        "# This query aligns equally with the first and second key, \n",
        "# so their values get averaged.\n",
        "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention weights are:\n",
            "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
            "Output is:\n",
            "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aOz-4_XIhaTP"
      },
      "source": [
        "Pass all the queries together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6dlU8Tm-hYrF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "569ba40b-a0d9-4c37-d8c5-78922ad25cd1"
      },
      "source": [
        "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention weights are:\n",
            "tf.Tensor(\n",
            "[[0.  0.  0.5 0.5]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
            "Output is:\n",
            "tf.Tensor(\n",
            "[[550.    5.5]\n",
            " [ 10.    0. ]\n",
            " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kmzGPEy64qmA"
      },
      "source": [
        "## Multi-head attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fz5BMC8Kaoqo"
      },
      "source": [
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/multi_head_attention.png\" width=\"500\" alt=\"multi-head attention\">\n",
        "\n",
        "\n",
        "Multi-head attention consists of four parts:\n",
        "*    Linear layers and split into heads.\n",
        "*    Scaled dot-product attention.\n",
        "*    Concatenation of heads.\n",
        "*    Final linear layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JPmbr6F1C-v_"
      },
      "source": [
        "Each multi-head attention block gets three inputs; Q (query), K (key), V (value). These are put through linear (Dense) layers and split up into multiple heads. \n",
        "\n",
        "The `scaled_dot_product_attention` defined above is applied to each head (broadcasted for efficiency). An appropriate mask must be used in the attention step.  The attention output for each head is then concatenated (using `tf.transpose`, and `tf.reshape`) and put through a final `Dense` layer.\n",
        "\n",
        "Instead of one single attention head, Q, K, and V are split into multiple heads because it allows the model to jointly attend to information at different positions from different representational spaces. After the split each head has a reduced dimensionality, so the total computation cost is the same as a single head attention with full dimensionality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BSV3PPKsYecw",
        "colab": {}
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "    \n",
        "    assert d_model % self.num_heads == 0\n",
        "    \n",
        "    self.depth = d_model // self.num_heads\n",
        "    \n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "    \n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "    \n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "    \n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "    \n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "    \n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention, \n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    # why this extra line, coz this was not mentioned in model\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "        \n",
        "    return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0D8FJue5lDyZ"
      },
      "source": [
        "Create a `MultiHeadAttention` layer to try out. At each location in the sequence, `y`, the `MultiHeadAttention` runs all 8 attention heads across all other locations in the sequence, returning a new vector of the same length at each location."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hu94p-_-2_BX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fabe8bfe-fbc8-40c8-bbdd-02041bc4ef8e"
      },
      "source": [
        "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
        "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
        "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
        "out.shape, attn.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RdDqGayx67vv"
      },
      "source": [
        "## Point wise feed forward network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gBqzJXGfHK3X"
      },
      "source": [
        "Point wise feed forward network consists of two fully-connected layers with a ReLU activation in between."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ET7xLt0yCT6Z",
        "colab": {}
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mytb1lPyOHLB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad69d8bc-aa73-492d-c466-551be115cbc6"
      },
      "source": [
        "sample_ffn = point_wise_feed_forward_network(500, 2048)\n",
        "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 50, 500])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7e7hKcxn6-zd"
      },
      "source": [
        "## Encoder and decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yScbC0MUH8dS"
      },
      "source": [
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\" width=\"600\" alt=\"transformer\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MfYJG-Kvgwy2"
      },
      "source": [
        "The transformer model follows the same general pattern as a standard [sequence to sequence with attention model](nmt_with_attention.ipynb). \n",
        "\n",
        "* The input sentence is passed through `N` encoder layers that generates an output for each word/token in the sequence.\n",
        "* The decoder attends on the encoder's output and its own input (self-attention) to predict the next word. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QFv-FNYUmvpn"
      },
      "source": [
        "### Encoder layer\n",
        "\n",
        "Each encoder layer consists of sublayers:\n",
        "\n",
        "1.   Multi-head attention (with padding mask) \n",
        "2.    Point wise feed forward networks. \n",
        "\n",
        "Each of these sublayers has a residual connection around it followed by a layer normalization. Residual connections help in avoiding the vanishing gradient problem in deep networks.\n",
        "\n",
        "The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis. There are N encoder layers in the transformer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ncyS-Ms3i2x_",
        "colab": {}
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    return out2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AzZRXdO0mI48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eed217be-c029-482d-eecc-537da3951ecd"
      },
      "source": [
        "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
        "\n",
        "sample_encoder_layer_output = sample_encoder_layer(\n",
        "    tf.random.uniform((64, 43, 512)), False, None)\n",
        "\n",
        "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 43, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6LO_48Owmx_o"
      },
      "source": [
        "### Decoder layer\n",
        "\n",
        "Each decoder layer consists of sublayers:\n",
        "\n",
        "1.   Masked multi-head attention (with look ahead mask and padding mask)\n",
        "2.   Multi-head attention (with padding mask). V (value) and K (key) receive the *encoder output* as inputs. Q (query) receives the *output from the masked multi-head attention sublayer.*\n",
        "3.   Point wise feed forward networks\n",
        "\n",
        "Each of these sublayers has a residual connection around it followed by a layer normalization. The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis.\n",
        "\n",
        "There are N decoder layers in the transformer.\n",
        "\n",
        "As Q receives the output from decoder's first attention block, and K receives the encoder output, the attention weights represent the importance given to the decoder's input based on the encoder's output. In other words, the decoder predicts the next word by looking at the encoder output and self-attending to its own output. See the demonstration above in the scaled dot product attention section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9SoX0-vd1hue",
        "colab": {}
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        " \n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "    \n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ne2Bqx8k71l0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b25548a7-0e9b-4b01-f0c5-9f7fe45d0d4b"
      },
      "source": [
        "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
        "\n",
        "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
        "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
        "    False, None, None)\n",
        "\n",
        "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 50, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SE1H51Ajm0q1"
      },
      "source": [
        "### Encoder\n",
        "\n",
        "The `Encoder` consists of:\n",
        "1.   Input Embedding\n",
        "2.   Positional Encoding\n",
        "3.   N encoder layers\n",
        "\n",
        "The input is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jpEox7gJ8FCI",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
        "                                            self.d_model)\n",
        "    \n",
        "    \n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "  \n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    \n",
        "    # adding embedding and position encoding.\n",
        "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    # print(x)\n",
        "    # print(\"check3 passed\")\n",
        "    # print(x)\n",
        "    # why this??\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "    # print(\"check4 passed\")\n",
        "    x = self.dropout(x, training=training)\n",
        "    # print(\"check4' passed\")\n",
        "    # print(x)\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "    # print(\"check5 passed\")\n",
        "    return x  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p-uO6ls8m2O5"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZtT7PKzrXkNr"
      },
      "source": [
        " The `Decoder` consists of:\n",
        "1.   Output Embedding\n",
        "2.   Positional Encoding\n",
        "3.   N decoder layers\n",
        "\n",
        "The target is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the decoder layers. The output of the decoder is the input to the final linear layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d5_d5-PLQXwY",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "     \n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "    \n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "    \n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "    \n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "      \n",
        "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "    \n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y54xnJnuYgJ7"
      },
      "source": [
        "## Create the Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uERO1y54cOKq"
      },
      "source": [
        "Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PED3bIpOYkBu",
        "colab": {}
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
        "                           input_vocab_size, pe_input, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
        "                           target_vocab_size, pe_target, rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "  def call(self, inp, tar, training, enc_padding_mask, \n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "    # print(\"check6 passed\")\n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "    # print(\"check7 passed\")\n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "    \n",
        "    return final_output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wsINyf1VEQLC"
      },
      "source": [
        "## Set hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zVjWCxFNcgbt"
      },
      "source": [
        "To keep this example small and relatively fast, the values for *num_layers, d_model, and dff* have been reduced. \n",
        "\n",
        "The values used in the base model of transformer were; *num_layers=6*, *d_model = 512*, *dff = 2048*. See the [paper](https://arxiv.org/abs/1706.03762) for all the other versions of the transformer.\n",
        "\n",
        "Note: By changing the values below, you can get the model that achieved state of the art on many tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plVe4eXD2DJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lnJn5SLA2ahP",
        "colab": {}
      },
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "\n",
        "input_vocab_size = input_vocab_size+2\n",
        "target_vocab_size = target_vocab_size+2\n",
        "dropout_rate = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xYEGhEOtzn5W"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GOmWW--yP3zx"
      },
      "source": [
        "Use the Adam optimizer with a custom learning rate scheduler according to the formula in the [paper](https://arxiv.org/abs/1706.03762).\n",
        "\n",
        "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iYQdOO1axwEI",
        "colab": {}
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    \n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "    \n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "    \n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7r4scdulztRx",
        "colab": {}
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YgkDE7hzo8r5"
      },
      "source": [
        "## Loss and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oxGJtoDuYIHL"
      },
      "source": [
        "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MlhsJMm0TW_B",
        "colab": {}
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "67oqVHiT0Eiu",
        "colab": {}
      },
      "source": [
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "  \n",
        "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "phlyxMnm-Tpx",
        "colab": {}
      },
      "source": [
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aeHumfr7zmMa"
      },
      "source": [
        "## Training and checkpointing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UiysUa--4tOU",
        "colab": {}
      },
      "source": [
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size, \n",
        "                          pe_input=input_vocab_size, \n",
        "                          pe_target=target_vocab_size,\n",
        "                          rate=dropout_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZOJUSB1T8GjM",
        "colab": {}
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "  # Encoder padding mask\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # Used in the 2nd attention block in the decoder.\n",
        "  # This padding mask is used to mask the encoder outputs.\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # Used in the 1st attention block in the decoder.\n",
        "  # It is used to pad and mask future tokens in the input received by \n",
        "  # the decoder.\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "  \n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fzuf06YZp66w"
      },
      "source": [
        "Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hNhuYfllndLZ",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"./checkpoints/train\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print ('Latest checkpoint restored!!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCpJrfkTB3HS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6KWiBZ87uw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LKpoA6q1sJFj",
        "colab": {}
      },
      "source": [
        "EPOCHS = 25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iJwmp9OE29oj",
        "colab": {}
      },
      "source": [
        "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
        "# execution. The function specializes to the precise shape of the argument\n",
        "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
        "# batch sizes (the last batch is smaller), use input_signature to specify\n",
        "# more generic shapes.\n",
        "\n",
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(64, 23), dtype=tf.int32),\n",
        "    tf.TensorSpec(shape=(64, 23), dtype=tf.int32),\n",
        "]\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "  # print(tar_inp)\n",
        "  # print(inp)\n",
        "  # print(\"hi\")\n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "  # print(\"hi\")\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions, _ = transformer(inp, tar_inp, \n",
        "                                 True, \n",
        "                                 enc_padding_mask, \n",
        "                                 combined_mask, \n",
        "                                 dec_padding_mask)\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "  \n",
        "  train_loss(loss)\n",
        "  train_accuracy(tar_real, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qM2PDWGDJ_8V"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "English is used as the input language and Hindi is the target language."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bbvmaKNiznHZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c20e9ec0-022e-42fe-ebb2-c4b788f5bccf"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "  \n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  \n",
        "  # inp -> portuguese, tar -> english\n",
        "  for (batch, (inp, tar)) in enumerate(dataset):\n",
        "    train_step(inp, tar)\n",
        "    if batch % 50 == 0:\n",
        "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "      \n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
        "                                                         ckpt_save_path))\n",
        "    \n",
        "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
        "                                                train_loss.result(), \n",
        "                                                train_accuracy.result()))\n",
        "\n",
        "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 5.0613 Accuracy 0.0000\n",
            "Epoch 1 Batch 50 Loss 4.5432 Accuracy 0.0232\n",
            "Epoch 1 Batch 100 Loss 4.1683 Accuracy 0.0345\n",
            "Epoch 1 Batch 150 Loss 3.9604 Accuracy 0.0407\n",
            "Epoch 1 Batch 200 Loss 3.7721 Accuracy 0.0479\n",
            "Epoch 1 Batch 250 Loss 3.5982 Accuracy 0.0544\n",
            "Epoch 1 Batch 300 Loss 3.4390 Accuracy 0.0608\n",
            "Epoch 1 Batch 350 Loss 3.2962 Accuracy 0.0671\n",
            "Epoch 1 Loss 3.1861 Accuracy 0.0721\n",
            "Time taken for 1 epoch: 20.90396785736084 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 2.1686 Accuracy 0.1243\n",
            "Epoch 2 Batch 50 Loss 2.0391 Accuracy 0.1273\n",
            "Epoch 2 Batch 100 Loss 1.9542 Accuracy 0.1313\n",
            "Epoch 2 Batch 150 Loss 1.8711 Accuracy 0.1364\n",
            "Epoch 2 Batch 200 Loss 1.8066 Accuracy 0.1404\n",
            "Epoch 2 Batch 250 Loss 1.7392 Accuracy 0.1448\n",
            "Epoch 2 Batch 300 Loss 1.6725 Accuracy 0.1493\n",
            "Epoch 2 Batch 350 Loss 1.6051 Accuracy 0.1538\n",
            "Epoch 2 Loss 1.5476 Accuracy 0.1577\n",
            "Time taken for 1 epoch: 13.28403115272522 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.0155 Accuracy 0.2067\n",
            "Epoch 3 Batch 50 Loss 0.9052 Accuracy 0.2059\n",
            "Epoch 3 Batch 100 Loss 0.8517 Accuracy 0.2087\n",
            "Epoch 3 Batch 150 Loss 0.8141 Accuracy 0.2112\n",
            "Epoch 3 Batch 200 Loss 0.7703 Accuracy 0.2144\n",
            "Epoch 3 Batch 250 Loss 0.7338 Accuracy 0.2170\n",
            "Epoch 3 Batch 300 Loss 0.7086 Accuracy 0.2192\n",
            "Epoch 3 Batch 350 Loss 0.6871 Accuracy 0.2208\n",
            "Epoch 3 Loss 0.6705 Accuracy 0.2224\n",
            "Time taken for 1 epoch: 13.33591890335083 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.6709 Accuracy 0.2237\n",
            "Epoch 4 Batch 50 Loss 0.4853 Accuracy 0.2371\n",
            "Epoch 4 Batch 100 Loss 0.4902 Accuracy 0.2367\n",
            "Epoch 4 Batch 150 Loss 0.4908 Accuracy 0.2363\n",
            "Epoch 4 Batch 200 Loss 0.4863 Accuracy 0.2369\n",
            "Epoch 4 Batch 250 Loss 0.4791 Accuracy 0.2376\n",
            "Epoch 4 Batch 300 Loss 0.4765 Accuracy 0.2381\n",
            "Epoch 4 Batch 350 Loss 0.4710 Accuracy 0.2387\n",
            "Epoch 4 Loss 0.4668 Accuracy 0.2389\n",
            "Time taken for 1 epoch: 13.274601936340332 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.5236 Accuracy 0.2216\n",
            "Epoch 5 Batch 50 Loss 0.4264 Accuracy 0.2436\n",
            "Epoch 5 Batch 100 Loss 0.4182 Accuracy 0.2433\n",
            "Epoch 5 Batch 150 Loss 0.4179 Accuracy 0.2428\n",
            "Epoch 5 Batch 200 Loss 0.4126 Accuracy 0.2430\n",
            "Epoch 5 Batch 250 Loss 0.4100 Accuracy 0.2431\n",
            "Epoch 5 Batch 300 Loss 0.4122 Accuracy 0.2430\n",
            "Epoch 5 Batch 350 Loss 0.4105 Accuracy 0.2431\n",
            "Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-1\n",
            "Epoch 5 Loss 0.4094 Accuracy 0.2434\n",
            "Time taken for 1 epoch: 13.483606815338135 secs\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.3535 Accuracy 0.2479\n",
            "Epoch 6 Batch 50 Loss 0.3719 Accuracy 0.2464\n",
            "Epoch 6 Batch 100 Loss 0.3792 Accuracy 0.2455\n",
            "Epoch 6 Batch 150 Loss 0.3803 Accuracy 0.2454\n",
            "Epoch 6 Batch 200 Loss 0.3795 Accuracy 0.2459\n",
            "Epoch 6 Batch 250 Loss 0.3784 Accuracy 0.2462\n",
            "Epoch 6 Batch 300 Loss 0.3784 Accuracy 0.2460\n",
            "Epoch 6 Batch 350 Loss 0.3787 Accuracy 0.2459\n",
            "Epoch 6 Loss 0.3793 Accuracy 0.2458\n",
            "Time taken for 1 epoch: 13.301278591156006 secs\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.3739 Accuracy 0.2408\n",
            "Epoch 7 Batch 50 Loss 0.3647 Accuracy 0.2455\n",
            "Epoch 7 Batch 100 Loss 0.3629 Accuracy 0.2467\n",
            "Epoch 7 Batch 150 Loss 0.3684 Accuracy 0.2464\n",
            "Epoch 7 Batch 200 Loss 0.3735 Accuracy 0.2466\n",
            "Epoch 7 Batch 250 Loss 0.3727 Accuracy 0.2463\n",
            "Epoch 7 Batch 300 Loss 0.3723 Accuracy 0.2465\n",
            "Epoch 7 Batch 350 Loss 0.3711 Accuracy 0.2467\n",
            "Epoch 7 Loss 0.3708 Accuracy 0.2466\n",
            "Time taken for 1 epoch: 13.301994562149048 secs\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.4482 Accuracy 0.2330\n",
            "Epoch 8 Batch 50 Loss 0.3642 Accuracy 0.2448\n",
            "Epoch 8 Batch 100 Loss 0.3629 Accuracy 0.2461\n",
            "Epoch 8 Batch 150 Loss 0.3567 Accuracy 0.2469\n",
            "Epoch 8 Batch 200 Loss 0.3641 Accuracy 0.2467\n",
            "Epoch 8 Batch 250 Loss 0.3633 Accuracy 0.2472\n",
            "Epoch 8 Batch 300 Loss 0.3604 Accuracy 0.2472\n",
            "Epoch 8 Batch 350 Loss 0.3626 Accuracy 0.2470\n",
            "Epoch 8 Loss 0.3626 Accuracy 0.2473\n",
            "Time taken for 1 epoch: 13.29202938079834 secs\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.4262 Accuracy 0.2450\n",
            "Epoch 9 Batch 50 Loss 0.3557 Accuracy 0.2461\n",
            "Epoch 9 Batch 100 Loss 0.3570 Accuracy 0.2470\n",
            "Epoch 9 Batch 150 Loss 0.3593 Accuracy 0.2473\n",
            "Epoch 9 Batch 200 Loss 0.3598 Accuracy 0.2478\n",
            "Epoch 9 Batch 250 Loss 0.3571 Accuracy 0.2478\n",
            "Epoch 9 Batch 300 Loss 0.3560 Accuracy 0.2478\n",
            "Epoch 9 Batch 350 Loss 0.3562 Accuracy 0.2478\n",
            "Epoch 9 Loss 0.3552 Accuracy 0.2478\n",
            "Time taken for 1 epoch: 13.315156936645508 secs\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.4297 Accuracy 0.2500\n",
            "Epoch 10 Batch 50 Loss 0.3474 Accuracy 0.2477\n",
            "Epoch 10 Batch 100 Loss 0.3469 Accuracy 0.2475\n",
            "Epoch 10 Batch 150 Loss 0.3491 Accuracy 0.2483\n",
            "Epoch 10 Batch 200 Loss 0.3502 Accuracy 0.2485\n",
            "Epoch 10 Batch 250 Loss 0.3569 Accuracy 0.2477\n",
            "Epoch 10 Batch 300 Loss 0.3563 Accuracy 0.2479\n",
            "Epoch 10 Batch 350 Loss 0.3536 Accuracy 0.2481\n",
            "Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-2\n",
            "Epoch 10 Loss 0.3545 Accuracy 0.2480\n",
            "Time taken for 1 epoch: 13.549766778945923 secs\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.3022 Accuracy 0.2543\n",
            "Epoch 11 Batch 50 Loss 0.3435 Accuracy 0.2485\n",
            "Epoch 11 Batch 100 Loss 0.3447 Accuracy 0.2487\n",
            "Epoch 11 Batch 150 Loss 0.3488 Accuracy 0.2484\n",
            "Epoch 11 Batch 200 Loss 0.3484 Accuracy 0.2486\n",
            "Epoch 11 Batch 250 Loss 0.3501 Accuracy 0.2484\n",
            "Epoch 11 Batch 300 Loss 0.3529 Accuracy 0.2481\n",
            "Epoch 11 Batch 350 Loss 0.3503 Accuracy 0.2484\n",
            "Epoch 11 Loss 0.3515 Accuracy 0.2481\n",
            "Time taken for 1 epoch: 13.344595670700073 secs\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.3622 Accuracy 0.2521\n",
            "Epoch 12 Batch 50 Loss 0.3056 Accuracy 0.2518\n",
            "Epoch 12 Batch 100 Loss 0.3135 Accuracy 0.2512\n",
            "Epoch 12 Batch 150 Loss 0.3170 Accuracy 0.2509\n",
            "Epoch 12 Batch 200 Loss 0.3191 Accuracy 0.2501\n",
            "Epoch 12 Batch 250 Loss 0.3230 Accuracy 0.2497\n",
            "Epoch 12 Batch 300 Loss 0.3252 Accuracy 0.2499\n",
            "Epoch 12 Batch 350 Loss 0.3247 Accuracy 0.2499\n",
            "Epoch 12 Loss 0.3235 Accuracy 0.2500\n",
            "Time taken for 1 epoch: 13.362911939620972 secs\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.3873 Accuracy 0.2472\n",
            "Epoch 13 Batch 50 Loss 0.3150 Accuracy 0.2501\n",
            "Epoch 13 Batch 100 Loss 0.3177 Accuracy 0.2485\n",
            "Epoch 13 Batch 150 Loss 0.3185 Accuracy 0.2494\n",
            "Epoch 13 Batch 200 Loss 0.3164 Accuracy 0.2505\n",
            "Epoch 13 Batch 250 Loss 0.3130 Accuracy 0.2508\n",
            "Epoch 13 Batch 300 Loss 0.3119 Accuracy 0.2506\n",
            "Epoch 13 Batch 350 Loss 0.3134 Accuracy 0.2507\n",
            "Epoch 13 Loss 0.3142 Accuracy 0.2509\n",
            "Time taken for 1 epoch: 13.363942861557007 secs\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.3921 Accuracy 0.2521\n",
            "Epoch 14 Batch 50 Loss 0.2938 Accuracy 0.2529\n",
            "Epoch 14 Batch 100 Loss 0.2970 Accuracy 0.2521\n",
            "Epoch 14 Batch 150 Loss 0.3016 Accuracy 0.2516\n",
            "Epoch 14 Batch 200 Loss 0.3014 Accuracy 0.2513\n",
            "Epoch 14 Batch 250 Loss 0.2976 Accuracy 0.2517\n",
            "Epoch 14 Batch 300 Loss 0.2987 Accuracy 0.2517\n",
            "Epoch 14 Batch 350 Loss 0.2992 Accuracy 0.2517\n",
            "Epoch 14 Loss 0.2987 Accuracy 0.2519\n",
            "Time taken for 1 epoch: 13.307230472564697 secs\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.2738 Accuracy 0.2635\n",
            "Epoch 15 Batch 50 Loss 0.2799 Accuracy 0.2521\n",
            "Epoch 15 Batch 100 Loss 0.2813 Accuracy 0.2521\n",
            "Epoch 15 Batch 150 Loss 0.2883 Accuracy 0.2523\n",
            "Epoch 15 Batch 200 Loss 0.2883 Accuracy 0.2526\n",
            "Epoch 15 Batch 250 Loss 0.2895 Accuracy 0.2524\n",
            "Epoch 15 Batch 300 Loss 0.2909 Accuracy 0.2522\n",
            "Epoch 15 Batch 350 Loss 0.2902 Accuracy 0.2523\n",
            "Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-3\n",
            "Epoch 15 Loss 0.2880 Accuracy 0.2528\n",
            "Time taken for 1 epoch: 13.559635877609253 secs\n",
            "\n",
            "Epoch 16 Batch 0 Loss 0.2760 Accuracy 0.2514\n",
            "Epoch 16 Batch 50 Loss 0.2754 Accuracy 0.2526\n",
            "Epoch 16 Batch 100 Loss 0.2815 Accuracy 0.2530\n",
            "Epoch 16 Batch 150 Loss 0.2797 Accuracy 0.2536\n",
            "Epoch 16 Batch 200 Loss 0.2770 Accuracy 0.2534\n",
            "Epoch 16 Batch 250 Loss 0.2781 Accuracy 0.2538\n",
            "Epoch 16 Batch 300 Loss 0.2763 Accuracy 0.2536\n",
            "Epoch 16 Batch 350 Loss 0.2783 Accuracy 0.2534\n",
            "Epoch 16 Loss 0.2776 Accuracy 0.2535\n",
            "Time taken for 1 epoch: 13.432374000549316 secs\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.3831 Accuracy 0.2422\n",
            "Epoch 17 Batch 50 Loss 0.2620 Accuracy 0.2561\n",
            "Epoch 17 Batch 100 Loss 0.2612 Accuracy 0.2548\n",
            "Epoch 17 Batch 150 Loss 0.2653 Accuracy 0.2543\n",
            "Epoch 17 Batch 200 Loss 0.2682 Accuracy 0.2543\n",
            "Epoch 17 Batch 250 Loss 0.2676 Accuracy 0.2542\n",
            "Epoch 17 Batch 300 Loss 0.2680 Accuracy 0.2542\n",
            "Epoch 17 Batch 350 Loss 0.2673 Accuracy 0.2542\n",
            "Epoch 17 Loss 0.2682 Accuracy 0.2541\n",
            "Time taken for 1 epoch: 13.34540581703186 secs\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.2627 Accuracy 0.2635\n",
            "Epoch 18 Batch 50 Loss 0.2531 Accuracy 0.2537\n",
            "Epoch 18 Batch 100 Loss 0.2537 Accuracy 0.2547\n",
            "Epoch 18 Batch 150 Loss 0.2542 Accuracy 0.2555\n",
            "Epoch 18 Batch 200 Loss 0.2572 Accuracy 0.2553\n",
            "Epoch 18 Batch 250 Loss 0.2599 Accuracy 0.2551\n",
            "Epoch 18 Batch 300 Loss 0.2597 Accuracy 0.2548\n",
            "Epoch 18 Batch 350 Loss 0.2588 Accuracy 0.2547\n",
            "Epoch 18 Loss 0.2596 Accuracy 0.2548\n",
            "Time taken for 1 epoch: 13.362987995147705 secs\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.1923 Accuracy 0.2855\n",
            "Epoch 19 Batch 50 Loss 0.2381 Accuracy 0.2571\n",
            "Epoch 19 Batch 100 Loss 0.2534 Accuracy 0.2553\n",
            "Epoch 19 Batch 150 Loss 0.2540 Accuracy 0.2557\n",
            "Epoch 19 Batch 200 Loss 0.2527 Accuracy 0.2561\n",
            "Epoch 19 Batch 250 Loss 0.2539 Accuracy 0.2554\n",
            "Epoch 19 Batch 300 Loss 0.2545 Accuracy 0.2554\n",
            "Epoch 19 Batch 350 Loss 0.2548 Accuracy 0.2550\n",
            "Epoch 19 Loss 0.2529 Accuracy 0.2553\n",
            "Time taken for 1 epoch: 13.359163284301758 secs\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.2034 Accuracy 0.2578\n",
            "Epoch 20 Batch 50 Loss 0.2336 Accuracy 0.2555\n",
            "Epoch 20 Batch 100 Loss 0.2363 Accuracy 0.2569\n",
            "Epoch 20 Batch 150 Loss 0.2417 Accuracy 0.2565\n",
            "Epoch 20 Batch 200 Loss 0.2453 Accuracy 0.2561\n",
            "Epoch 20 Batch 250 Loss 0.2451 Accuracy 0.2561\n",
            "Epoch 20 Batch 300 Loss 0.2479 Accuracy 0.2558\n",
            "Epoch 20 Batch 350 Loss 0.2467 Accuracy 0.2560\n",
            "Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-4\n",
            "Epoch 20 Loss 0.2463 Accuracy 0.2559\n",
            "Time taken for 1 epoch: 13.577368021011353 secs\n",
            "\n",
            "Epoch 21 Batch 0 Loss 0.2704 Accuracy 0.2528\n",
            "Epoch 21 Batch 50 Loss 0.2337 Accuracy 0.2564\n",
            "Epoch 21 Batch 100 Loss 0.2397 Accuracy 0.2561\n",
            "Epoch 21 Batch 150 Loss 0.2407 Accuracy 0.2562\n",
            "Epoch 21 Batch 200 Loss 0.2399 Accuracy 0.2562\n",
            "Epoch 21 Batch 250 Loss 0.2399 Accuracy 0.2562\n",
            "Epoch 21 Batch 300 Loss 0.2400 Accuracy 0.2565\n",
            "Epoch 21 Batch 350 Loss 0.2403 Accuracy 0.2565\n",
            "Epoch 21 Loss 0.2399 Accuracy 0.2564\n",
            "Time taken for 1 epoch: 13.412058115005493 secs\n",
            "\n",
            "Epoch 22 Batch 0 Loss 0.2082 Accuracy 0.2621\n",
            "Epoch 22 Batch 50 Loss 0.2196 Accuracy 0.2591\n",
            "Epoch 22 Batch 100 Loss 0.2248 Accuracy 0.2590\n",
            "Epoch 22 Batch 150 Loss 0.2264 Accuracy 0.2577\n",
            "Epoch 22 Batch 200 Loss 0.2286 Accuracy 0.2575\n",
            "Epoch 22 Batch 250 Loss 0.2316 Accuracy 0.2572\n",
            "Epoch 22 Batch 300 Loss 0.2328 Accuracy 0.2568\n",
            "Epoch 22 Batch 350 Loss 0.2331 Accuracy 0.2568\n",
            "Epoch 22 Loss 0.2332 Accuracy 0.2567\n",
            "Time taken for 1 epoch: 13.398160457611084 secs\n",
            "\n",
            "Epoch 23 Batch 0 Loss 0.2690 Accuracy 0.2486\n",
            "Epoch 23 Batch 50 Loss 0.2176 Accuracy 0.2597\n",
            "Epoch 23 Batch 100 Loss 0.2210 Accuracy 0.2586\n",
            "Epoch 23 Batch 150 Loss 0.2239 Accuracy 0.2575\n",
            "Epoch 23 Batch 200 Loss 0.2248 Accuracy 0.2579\n",
            "Epoch 23 Batch 250 Loss 0.2258 Accuracy 0.2571\n",
            "Epoch 23 Batch 300 Loss 0.2253 Accuracy 0.2571\n",
            "Epoch 23 Batch 350 Loss 0.2261 Accuracy 0.2572\n",
            "Epoch 23 Loss 0.2279 Accuracy 0.2570\n",
            "Time taken for 1 epoch: 13.37515902519226 secs\n",
            "\n",
            "Epoch 24 Batch 0 Loss 0.1699 Accuracy 0.2756\n",
            "Epoch 24 Batch 50 Loss 0.2030 Accuracy 0.2605\n",
            "Epoch 24 Batch 100 Loss 0.2128 Accuracy 0.2589\n",
            "Epoch 24 Batch 150 Loss 0.2169 Accuracy 0.2581\n",
            "Epoch 24 Batch 200 Loss 0.2157 Accuracy 0.2584\n",
            "Epoch 24 Batch 250 Loss 0.2189 Accuracy 0.2579\n",
            "Epoch 24 Batch 300 Loss 0.2219 Accuracy 0.2579\n",
            "Epoch 24 Batch 350 Loss 0.2221 Accuracy 0.2576\n",
            "Epoch 24 Loss 0.2225 Accuracy 0.2576\n",
            "Time taken for 1 epoch: 13.439056396484375 secs\n",
            "\n",
            "Epoch 25 Batch 0 Loss 0.1970 Accuracy 0.2798\n",
            "Epoch 25 Batch 50 Loss 0.2007 Accuracy 0.2579\n",
            "Epoch 25 Batch 100 Loss 0.2072 Accuracy 0.2583\n",
            "Epoch 25 Batch 150 Loss 0.2112 Accuracy 0.2578\n",
            "Epoch 25 Batch 200 Loss 0.2132 Accuracy 0.2580\n",
            "Epoch 25 Batch 250 Loss 0.2143 Accuracy 0.2583\n",
            "Epoch 25 Batch 300 Loss 0.2146 Accuracy 0.2580\n",
            "Epoch 25 Batch 350 Loss 0.2156 Accuracy 0.2577\n",
            "Saving checkpoint for epoch 25 at ./checkpoints/train/ckpt-5\n",
            "Epoch 25 Loss 0.2163 Accuracy 0.2578\n",
            "Time taken for 1 epoch: 13.619416952133179 secs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QfcsSWswSdGV"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTPOYBJNqTqe",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y6APsFrgImLW"
      },
      "source": [
        "The following steps are used for evaluation:\n",
        "\n",
        "* Encode the input sentence using the Portuguese tokenizer (`tokenizer_pt`). Moreover, add the start and end token so the input is equivalent to what the model is trained with. This is the encoder input.\n",
        "* The decoder input is the `start token == tokenizer_en.vocab_size`.\n",
        "* Calculate the padding masks and the look ahead masks.\n",
        "* The `decoder` then outputs the predictions by looking at the `encoder output` and its own output (self-attention).\n",
        "* Select the last word and calculate the argmax of that.\n",
        "* Concatentate the predicted word to the decoder input as pass it to the decoder.\n",
        "* In this approach, the decoder predicts the next word based on the previous words it predicted.\n",
        "\n",
        "Note: The model used here has less capacity to keep the example relatively faster so the predictions maybe less right. To reproduce the results in the paper, use the entire dataset and base transformer model or transformer XL, by changing the hyperparameters above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR5FQmjw_dAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5buvMlnvyrFm",
        "colab": {}
      },
      "source": [
        "def evaluate(word):\n",
        "  inputs = [char2idxEn[i] for i in (word)]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=23, padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "  encoder_input = inputs\n",
        "  # as the target is english, the first word to the transformer should be the\n",
        "  # english start token.\n",
        "  decoder_input = [char2idxHi[word[0]]]\n",
        "  output = tf.expand_dims(decoder_input, 0)\n",
        "  # print(\"check1 passed\")\n",
        "  for i in range(MAX_LENGTH):\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "        encoder_input, output)\n",
        "    # print(\"check2 passed\")\n",
        "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "    predictions, attention_weights = transformer(encoder_input, \n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "    # print(\"check3 passed\")\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "    \n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if predicted_id == char2idxHi[\"@\"]:\n",
        "      return tf.squeeze(output, axis=0), attention_weights\n",
        "    \n",
        "    # concatentate the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "  return tf.squeeze(output, axis=0), attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2PMjhzTSzMc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99d158d9-bd89-44d0-85bb-7c94d6646050"
      },
      "source": [
        "char2idxHi[\"@\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lU2_yG_vBGza",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "  \n",
        "  result, attention_weights = evaluate(sentence)\n",
        "  predicted_sentence = \"\"\n",
        "  for i in result:\n",
        "    if i != 1 and i != 2:\n",
        "      predicted_sentence += idx2charHi[i.numpy()]\n",
        "  print(predicted_sentence)\n",
        " \n",
        "  # print(predicted_sentence)  \n",
        "\n",
        "  # print('Input: {}'.format(sentence))\n",
        "  # print('Predicted translation: {}'.format(predicted_sentence))\n",
        "  \n",
        "  # if plot:\n",
        "  #   plot_attention_weights(attention_weights, sentence, result, plot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4ygXkf1awiT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42a8beae-08e5-4823-c6ea-b3a305e5df09"
      },
      "source": [
        "idx2charHi[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'$'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YsxrAlvFG8SZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9a4767c-fd54-4d41-bfc0-3896dba9587c"
      },
      "source": [
        "translate(\"#amasta@\")\n",
        "# print (\"Real translation: this is a problem we have to solve .\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "અમસ્તા\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrms1PbslaAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @tf.function\n",
        "def predictAccuracyHi(mismatch_pair,strmismatch):\n",
        "  ip = \"\";\n",
        "  cnt = 0;\n",
        "  output = \"\";\n",
        "  trueVal = \"\";\n",
        "  cnt2char = 0;\n",
        "  totalcharcnt = 0;\n",
        "  avgmismatch = 0;\n",
        "  mismatchcnt = 0;\n",
        "  total_hindi_words = 0;\n",
        "  l = (int)(len(input_tensor_val)/20);\n",
        "  for i in range(0, l):\n",
        "    print(100*i/l, \"% completed\")\n",
        "    input_word = input_tensor_val[i];\n",
        "    target_word = target_tensor_val[i];\n",
        "    if(input_word[0] == 1):\n",
        "      continue;\n",
        "    total_hindi_words += 1;\n",
        "    for r in input_word:\n",
        "      if(r == 0):\n",
        "        break\n",
        "      else: \n",
        "        ip += idx2charEn[r]\n",
        "    result, _ = evaluate(ip)\n",
        "    for k in result:\n",
        "      if (k != 1 and k != 2 and k!= 3):\n",
        "        output += idx2charHi[k.numpy()]\n",
        "    # print(output)\n",
        "    \n",
        "    # print(word)\n",
        "    for r in target_word:\n",
        "      if(r != 0 and r!= 1 and r != 2 and r!= 3):\n",
        "        trueVal += idx2charHi[r]\n",
        "    # print(trueVal+\"  : \"+output);\n",
        "    # print(output)\n",
        "    if(len(output) == len(trueVal)):\n",
        "      wordlen = len(trueVal);\n",
        "      totalcharcnt += int(wordlen);\n",
        "      tempcnt = 0;\n",
        "      for k in range(0,int(wordlen)):\n",
        "        if(output[k] == trueVal[k]):\n",
        "          cnt2char +=  1;\n",
        "        else :\n",
        "          mismatch_pair.append({output[k], trueVal[k]});\n",
        "          strmismatch += output[k];\n",
        "          tempcnt += 1;\n",
        "          mismatchcnt += 1;\n",
        "      avgmismatch += (tempcnt/wordlen);\n",
        "    if(output==trueVal):\n",
        "      cnt = cnt+1; \n",
        "    ip = \"\"\n",
        "    output = \"\"\n",
        "    trueVal = \"\"\n",
        "    \n",
        "  print(100*cnt/(int(total_hindi_words)))\n",
        "  print(100*cnt2char/totalcharcnt);\n",
        "  print(avgmismatch/(l-cnt));\n",
        "  print(set(strmismatch));\n",
        "  return 100*cnt/(int(l)), 100*cnt2char/totalcharcnt, (avgmismatch/(l-cnt)), set(strmismatch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8CkiIml9G51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @tf.function\n",
        "def predictAccuracyGj(mismatch_pair,strmismatch):\n",
        "  ip = \"\";\n",
        "  cnt = 0;\n",
        "  output = \"\";\n",
        "  trueVal = \"\";\n",
        "  cnt2char = 0;\n",
        "  totalcharcnt = 0;\n",
        "  avgmismatch = 0;\n",
        "  mismatchcnt = 0;\n",
        "  total_guj_words = 0;\n",
        "  l = (int)(len(input_tensor_val));\n",
        "  for i in range(0, l):\n",
        "    print(100*i/l, \"% completed\")\n",
        "    input_word = input_tensor_val[i];\n",
        "    target_word = target_tensor_val[i];\n",
        "    if(input_word[0] == 2):\n",
        "      continue;\n",
        "    total_guj_words += 1;\n",
        "    for r in input_word:\n",
        "      if(r == 0):\n",
        "        break\n",
        "      else: \n",
        "        ip += idx2charEn[r]\n",
        "    result, _ = evaluate(ip)\n",
        "    for k in result:\n",
        "      if (k != 1 and k != 2 and k!= 3):\n",
        "        output += idx2charHi[k.numpy()]\n",
        "    # print(output)\n",
        "    \n",
        "    # print(word)\n",
        "    for r in target_word:\n",
        "      if(r != 0 and r!= 1 and r != 2 and r!= 3):\n",
        "        trueVal += idx2charHi[r]\n",
        "    # print(trueVal+\"  : \"+output);\n",
        "    # print(output)\n",
        "    if(len(output) == len(trueVal)):\n",
        "      wordlen = len(trueVal);\n",
        "      totalcharcnt += int(wordlen);\n",
        "      tempcnt = 0;\n",
        "      for k in range(0,int(wordlen)):\n",
        "        if(output[k] == trueVal[k]):\n",
        "          cnt2char +=  1;\n",
        "        else :\n",
        "          mismatch_pair.append({output[k], trueVal[k]});\n",
        "          strmismatch += output[k];\n",
        "          tempcnt += 1;\n",
        "          mismatchcnt += 1;\n",
        "      avgmismatch += (tempcnt/wordlen);\n",
        "    if(output==trueVal):\n",
        "      cnt = cnt+1; \n",
        "    ip = \"\"\n",
        "    output = \"\"\n",
        "    trueVal = \"\"\n",
        "    \n",
        "  print(100*cnt/(int(total_guj_words)))\n",
        "  print(100*cnt2char/totalcharcnt);\n",
        "  print(avgmismatch/(l-cnt));\n",
        "  print(set(strmismatch));\n",
        "  return 100*cnt/(int(l)), 100*cnt2char/totalcharcnt, (avgmismatch/(l-cnt)), set(strmismatch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dKRg87Q8xBD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e17f775-b2d5-4507-b3e1-a9d0d66ad689"
      },
      "source": [
        "char2idxHi[\"#\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7EH5y_aqI4t1",
        "colab": {}
      },
      "source": [
        "mismatch_pair = [];\n",
        "strmismatch = \"\";\n",
        "# a,b,c,d = predictAccuracyHi(mismatch_pair,strmismatch)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGrjquLMV6Ny",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6eb86a87-e223-43d9-d939-6fb200f8649e"
      },
      "source": [
        "mismatch_pair = [];\n",
        "strmismatch = \"\";\n",
        "a1, b1, c1, d1 = predictAccuracyGj(mismatch_pair,strmismatch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "20.385718839655723 % completed\n",
            "20.401657634682817 % completed\n",
            "20.417596429709914 % completed\n",
            "20.43353522473701 % completed\n",
            "20.449474019764107 % completed\n",
            "20.4654128147912 % completed\n",
            "20.481351609818297 % completed\n",
            "20.497290404845394 % completed\n",
            "20.51322919987249 % completed\n",
            "20.529167994899584 % completed\n",
            "20.54510678992668 % completed\n",
            "20.561045584953778 % completed\n",
            "20.576984379980875 % completed\n",
            "20.592923175007968 % completed\n",
            "20.608861970035065 % completed\n",
            "20.62480076506216 % completed\n",
            "20.64073956008926 % completed\n",
            "20.65667835511635 % completed\n",
            "20.67261715014345 % completed\n",
            "20.688555945170545 % completed\n",
            "20.704494740197642 % completed\n",
            "20.720433535224736 % completed\n",
            "20.736372330251832 % completed\n",
            "20.75231112527893 % completed\n",
            "20.768249920306026 % completed\n",
            "20.78418871533312 % completed\n",
            "20.800127510360216 % completed\n",
            "20.816066305387313 % completed\n",
            "20.83200510041441 % completed\n",
            "20.847943895441503 % completed\n",
            "20.8638826904686 % completed\n",
            "20.879821485495697 % completed\n",
            "20.895760280522794 % completed\n",
            "20.911699075549887 % completed\n",
            "20.927637870576984 % completed\n",
            "20.94357666560408 % completed\n",
            "20.959515460631177 % completed\n",
            "20.97545425565827 % completed\n",
            "20.991393050685367 % completed\n",
            "21.007331845712464 % completed\n",
            "21.02327064073956 % completed\n",
            "21.039209435766654 % completed\n",
            "21.05514823079375 % completed\n",
            "21.071087025820848 % completed\n",
            "21.087025820847945 % completed\n",
            "21.102964615875038 % completed\n",
            "21.118903410902135 % completed\n",
            "21.134842205929232 % completed\n",
            "21.15078100095633 % completed\n",
            "21.166719795983422 % completed\n",
            "21.18265859101052 % completed\n",
            "21.198597386037616 % completed\n",
            "21.214536181064712 % completed\n",
            "21.23047497609181 % completed\n",
            "21.246413771118903 % completed\n",
            "21.262352566146 % completed\n",
            "21.278291361173096 % completed\n",
            "21.294230156200193 % completed\n",
            "21.310168951227286 % completed\n",
            "21.326107746254383 % completed\n",
            "21.34204654128148 % completed\n",
            "21.357985336308577 % completed\n",
            "21.37392413133567 % completed\n",
            "21.389862926362767 % completed\n",
            "21.405801721389864 % completed\n",
            "21.42174051641696 % completed\n",
            "21.437679311444054 % completed\n",
            "21.45361810647115 % completed\n",
            "21.469556901498247 % completed\n",
            "21.485495696525344 % completed\n",
            "21.501434491552438 % completed\n",
            "21.517373286579534 % completed\n",
            "21.53331208160663 % completed\n",
            "21.549250876633728 % completed\n",
            "21.56518967166082 % completed\n",
            "21.581128466687918 % completed\n",
            "21.597067261715015 % completed\n",
            "21.613006056742112 % completed\n",
            "21.628944851769205 % completed\n",
            "21.644883646796302 % completed\n",
            "21.6608224418234 % completed\n",
            "21.676761236850496 % completed\n",
            "21.69270003187759 % completed\n",
            "21.708638826904686 % completed\n",
            "21.724577621931783 % completed\n",
            "21.74051641695888 % completed\n",
            "21.756455211985973 % completed\n",
            "21.77239400701307 % completed\n",
            "21.788332802040166 % completed\n",
            "21.804271597067263 % completed\n",
            "21.820210392094356 % completed\n",
            "21.836149187121453 % completed\n",
            "21.85208798214855 % completed\n",
            "21.868026777175647 % completed\n",
            "21.88396557220274 % completed\n",
            "21.899904367229837 % completed\n",
            "21.915843162256934 % completed\n",
            "21.93178195728403 % completed\n",
            "21.947720752311124 % completed\n",
            "21.96365954733822 % completed\n",
            "21.979598342365318 % completed\n",
            "21.995537137392414 % completed\n",
            "22.011475932419508 % completed\n",
            "22.027414727446605 % completed\n",
            "22.0433535224737 % completed\n",
            "22.059292317500798 % completed\n",
            "22.07523111252789 % completed\n",
            "22.09116990755499 % completed\n",
            "22.107108702582085 % completed\n",
            "22.123047497609182 % completed\n",
            "22.138986292636275 % completed\n",
            "22.154925087663372 % completed\n",
            "22.17086388269047 % completed\n",
            "22.186802677717566 % completed\n",
            "22.20274147274466 % completed\n",
            "22.218680267771756 % completed\n",
            "22.234619062798853 % completed\n",
            "22.25055785782595 % completed\n",
            "22.266496652853043 % completed\n",
            "22.28243544788014 % completed\n",
            "22.298374242907236 % completed\n",
            "22.314313037934333 % completed\n",
            "22.330251832961427 % completed\n",
            "22.346190627988523 % completed\n",
            "22.36212942301562 % completed\n",
            "22.378068218042717 % completed\n",
            "22.39400701306981 % completed\n",
            "22.409945808096907 % completed\n",
            "22.425884603124004 % completed\n",
            "22.4418233981511 % completed\n",
            "22.457762193178194 % completed\n",
            "22.47370098820529 % completed\n",
            "22.489639783232388 % completed\n",
            "22.505578578259485 % completed\n",
            "22.521517373286578 % completed\n",
            "22.537456168313675 % completed\n",
            "22.55339496334077 % completed\n",
            "22.56933375836787 % completed\n",
            "22.58527255339496 % completed\n",
            "22.60121134842206 % completed\n",
            "22.617150143449155 % completed\n",
            "22.633088938476252 % completed\n",
            "22.649027733503345 % completed\n",
            "22.664966528530442 % completed\n",
            "22.68090532355754 % completed\n",
            "22.696844118584636 % completed\n",
            "22.71278291361173 % completed\n",
            "22.728721708638826 % completed\n",
            "22.744660503665923 % completed\n",
            "22.76059929869302 % completed\n",
            "22.776538093720117 % completed\n",
            "22.79247688874721 % completed\n",
            "22.808415683774307 % completed\n",
            "22.824354478801403 % completed\n",
            "22.8402932738285 % completed\n",
            "22.856232068855594 % completed\n",
            "22.87217086388269 % completed\n",
            "22.888109658909787 % completed\n",
            "22.904048453936884 % completed\n",
            "22.919987248963977 % completed\n",
            "22.935926043991074 % completed\n",
            "22.95186483901817 % completed\n",
            "22.967803634045268 % completed\n",
            "22.98374242907236 % completed\n",
            "22.999681224099458 % completed\n",
            "23.015620019126555 % completed\n",
            "23.03155881415365 % completed\n",
            "23.047497609180745 % completed\n",
            "23.06343640420784 % completed\n",
            "23.07937519923494 % completed\n",
            "23.095313994262035 % completed\n",
            "23.11125278928913 % completed\n",
            "23.127191584316225 % completed\n",
            "23.143130379343322 % completed\n",
            "23.15906917437042 % completed\n",
            "23.175007969397512 % completed\n",
            "23.19094676442461 % completed\n",
            "23.206885559451706 % completed\n",
            "23.222824354478803 % completed\n",
            "23.238763149505896 % completed\n",
            "23.254701944532993 % completed\n",
            "23.27064073956009 % completed\n",
            "23.286579534587187 % completed\n",
            "23.30251832961428 % completed\n",
            "23.318457124641377 % completed\n",
            "23.334395919668474 % completed\n",
            "23.35033471469557 % completed\n",
            "23.366273509722664 % completed\n",
            "23.38221230474976 % completed\n",
            "23.398151099776857 % completed\n",
            "23.414089894803954 % completed\n",
            "23.430028689831047 % completed\n",
            "23.445967484858144 % completed\n",
            "23.46190627988524 % completed\n",
            "23.477845074912338 % completed\n",
            "23.49378386993943 % completed\n",
            "23.509722664966528 % completed\n",
            "23.525661459993625 % completed\n",
            "23.54160025502072 % completed\n",
            "23.557539050047815 % completed\n",
            "23.573477845074912 % completed\n",
            "23.58941664010201 % completed\n",
            "23.605355435129106 % completed\n",
            "23.6212942301562 % completed\n",
            "23.637233025183296 % completed\n",
            "23.653171820210392 % completed\n",
            "23.66911061523749 % completed\n",
            "23.685049410264583 % completed\n",
            "23.70098820529168 % completed\n",
            "23.716927000318776 % completed\n",
            "23.732865795345873 % completed\n",
            "23.748804590372966 % completed\n",
            "23.764743385400063 % completed\n",
            "23.78068218042716 % completed\n",
            "23.796620975454257 % completed\n",
            "23.81255977048135 % completed\n",
            "23.828498565508447 % completed\n",
            "23.844437360535544 % completed\n",
            "23.86037615556264 % completed\n",
            "23.876314950589734 % completed\n",
            "23.89225374561683 % completed\n",
            "23.908192540643928 % completed\n",
            "23.924131335671024 % completed\n",
            "23.940070130698118 % completed\n",
            "23.956008925725214 % completed\n",
            "23.97194772075231 % completed\n",
            "23.987886515779408 % completed\n",
            "24.0038253108065 % completed\n",
            "24.019764105833598 % completed\n",
            "24.035702900860695 % completed\n",
            "24.051641695887792 % completed\n",
            "24.067580490914885 % completed\n",
            "24.083519285941982 % completed\n",
            "24.09945808096908 % completed\n",
            "24.115396875996176 % completed\n",
            "24.13133567102327 % completed\n",
            "24.147274466050366 % completed\n",
            "24.163213261077463 % completed\n",
            "24.17915205610456 % completed\n",
            "24.195090851131653 % completed\n",
            "24.21102964615875 % completed\n",
            "24.226968441185846 % completed\n",
            "24.242907236212943 % completed\n",
            "24.25884603124004 % completed\n",
            "24.274784826267133 % completed\n",
            "24.29072362129423 % completed\n",
            "24.306662416321327 % completed\n",
            "24.322601211348424 % completed\n",
            "24.338540006375517 % completed\n",
            "24.354478801402614 % completed\n",
            "24.37041759642971 % completed\n",
            "24.386356391456808 % completed\n",
            "24.4022951864839 % completed\n",
            "24.418233981510998 % completed\n",
            "24.434172776538094 % completed\n",
            "24.45011157156519 % completed\n",
            "24.466050366592285 % completed\n",
            "24.48198916161938 % completed\n",
            "24.49792795664648 % completed\n",
            "24.513866751673575 % completed\n",
            "24.52980554670067 % completed\n",
            "24.545744341727765 % completed\n",
            "24.561683136754862 % completed\n",
            "24.57762193178196 % completed\n",
            "24.593560726809052 % completed\n",
            "24.60949952183615 % completed\n",
            "24.625438316863246 % completed\n",
            "24.641377111890343 % completed\n",
            "24.657315906917436 % completed\n",
            "24.673254701944533 % completed\n",
            "24.68919349697163 % completed\n",
            "24.705132291998726 % completed\n",
            "24.72107108702582 % completed\n",
            "24.737009882052917 % completed\n",
            "24.752948677080013 % completed\n",
            "24.76888747210711 % completed\n",
            "24.784826267134203 % completed\n",
            "24.8007650621613 % completed\n",
            "24.816703857188397 % completed\n",
            "24.832642652215494 % completed\n",
            "24.848581447242587 % completed\n",
            "24.864520242269684 % completed\n",
            "24.88045903729678 % completed\n",
            "24.896397832323878 % completed\n",
            "24.91233662735097 % completed\n",
            "24.928275422378068 % completed\n",
            "24.944214217405165 % completed\n",
            "24.96015301243226 % completed\n",
            "24.976091807459355 % completed\n",
            "24.99203060248645 % completed\n",
            "25.00796939751355 % completed\n",
            "25.023908192540645 % completed\n",
            "25.03984698756774 % completed\n",
            "25.055785782594835 % completed\n",
            "25.071724577621932 % completed\n",
            "25.08766337264903 % completed\n",
            "25.103602167676122 % completed\n",
            "25.11954096270322 % completed\n",
            "25.135479757730316 % completed\n",
            "25.151418552757413 % completed\n",
            "25.167357347784506 % completed\n",
            "25.183296142811603 % completed\n",
            "25.1992349378387 % completed\n",
            "25.215173732865797 % completed\n",
            "25.23111252789289 % completed\n",
            "25.247051322919987 % completed\n",
            "25.262990117947083 % completed\n",
            "25.27892891297418 % completed\n",
            "25.294867708001274 % completed\n",
            "25.31080650302837 % completed\n",
            "25.326745298055467 % completed\n",
            "25.342684093082564 % completed\n",
            "25.358622888109657 % completed\n",
            "25.374561683136754 % completed\n",
            "25.39050047816385 % completed\n",
            "25.406439273190948 % completed\n",
            "25.42237806821804 % completed\n",
            "25.438316863245138 % completed\n",
            "25.454255658272235 % completed\n",
            "25.47019445329933 % completed\n",
            "25.486133248326425 % completed\n",
            "25.50207204335352 % completed\n",
            "25.51801083838062 % completed\n",
            "25.533949633407715 % completed\n",
            "25.54988842843481 % completed\n",
            "25.565827223461906 % completed\n",
            "25.581766018489002 % completed\n",
            "25.5977048135161 % completed\n",
            "25.613643608543192 % completed\n",
            "25.62958240357029 % completed\n",
            "25.645521198597386 % completed\n",
            "25.661459993624483 % completed\n",
            "25.677398788651576 % completed\n",
            "25.693337583678673 % completed\n",
            "25.70927637870577 % completed\n",
            "25.725215173732867 % completed\n",
            "25.74115396875996 % completed\n",
            "25.757092763787057 % completed\n",
            "25.773031558814154 % completed\n",
            "25.78897035384125 % completed\n",
            "25.804909148868347 % completed\n",
            "25.82084794389544 % completed\n",
            "25.836786738922537 % completed\n",
            "25.852725533949634 % completed\n",
            "25.86866432897673 % completed\n",
            "25.884603124003824 % completed\n",
            "25.90054191903092 % completed\n",
            "25.916480714058018 % completed\n",
            "25.932419509085115 % completed\n",
            "25.948358304112208 % completed\n",
            "25.964297099139305 % completed\n",
            "25.980235894166402 % completed\n",
            "25.9961746891935 % completed\n",
            "26.012113484220592 % completed\n",
            "26.02805227924769 % completed\n",
            "26.043991074274786 % completed\n",
            "26.059929869301882 % completed\n",
            "26.075868664328976 % completed\n",
            "26.091807459356072 % completed\n",
            "26.10774625438317 % completed\n",
            "26.123685049410266 % completed\n",
            "26.13962384443736 % completed\n",
            "26.155562639464456 % completed\n",
            "26.171501434491553 % completed\n",
            "26.18744022951865 % completed\n",
            "26.203379024545743 % completed\n",
            "26.21931781957284 % completed\n",
            "26.235256614599937 % completed\n",
            "26.251195409627034 % completed\n",
            "26.267134204654127 % completed\n",
            "26.283072999681224 % completed\n",
            "26.29901179470832 % completed\n",
            "26.314950589735417 % completed\n",
            "26.33088938476251 % completed\n",
            "26.346828179789608 % completed\n",
            "26.362766974816704 % completed\n",
            "26.3787057698438 % completed\n",
            "26.394644564870894 % completed\n",
            "26.41058335989799 % completed\n",
            "26.426522154925088 % completed\n",
            "26.442460949952185 % completed\n",
            "26.45839974497928 % completed\n",
            "26.474338540006375 % completed\n",
            "26.490277335033472 % completed\n",
            "26.50621613006057 % completed\n",
            "26.522154925087662 % completed\n",
            "26.53809372011476 % completed\n",
            "26.554032515141856 % completed\n",
            "26.569971310168953 % completed\n",
            "26.585910105196046 % completed\n",
            "26.601848900223143 % completed\n",
            "26.61778769525024 % completed\n",
            "26.633726490277336 % completed\n",
            "26.64966528530443 % completed\n",
            "26.665604080331526 % completed\n",
            "26.681542875358623 % completed\n",
            "26.69748167038572 % completed\n",
            "26.713420465412813 % completed\n",
            "26.72935926043991 % completed\n",
            "26.745298055467007 % completed\n",
            "26.761236850494104 % completed\n",
            "26.777175645521197 % completed\n",
            "26.793114440548294 % completed\n",
            "26.80905323557539 % completed\n",
            "26.824992030602488 % completed\n",
            "26.84093082562958 % completed\n",
            "26.856869620656678 % completed\n",
            "26.872808415683775 % completed\n",
            "26.88874721071087 % completed\n",
            "26.904686005737965 % completed\n",
            "26.92062480076506 % completed\n",
            "26.93656359579216 % completed\n",
            "26.952502390819255 % completed\n",
            "26.96844118584635 % completed\n",
            "26.984379980873445 % completed\n",
            "27.000318775900542 % completed\n",
            "27.01625757092764 % completed\n",
            "27.032196365954732 % completed\n",
            "27.04813516098183 % completed\n",
            "27.064073956008926 % completed\n",
            "27.080012751036023 % completed\n",
            "27.095951546063116 % completed\n",
            "27.111890341090213 % completed\n",
            "27.12782913611731 % completed\n",
            "27.143767931144406 % completed\n",
            "27.1597067261715 % completed\n",
            "27.175645521198597 % completed\n",
            "27.191584316225693 % completed\n",
            "27.20752311125279 % completed\n",
            "27.223461906279883 % completed\n",
            "27.23940070130698 % completed\n",
            "27.255339496334077 % completed\n",
            "27.271278291361174 % completed\n",
            "27.28721708638827 % completed\n",
            "27.303155881415364 % completed\n",
            "27.31909467644246 % completed\n",
            "27.335033471469558 % completed\n",
            "27.350972266496655 % completed\n",
            "27.366911061523748 % completed\n",
            "27.382849856550845 % completed\n",
            "27.39878865157794 % completed\n",
            "27.41472744660504 % completed\n",
            "27.43066624163213 % completed\n",
            "27.44660503665923 % completed\n",
            "27.462543831686325 % completed\n",
            "27.478482626713422 % completed\n",
            "27.494421421740515 % completed\n",
            "27.510360216767612 % completed\n",
            "27.52629901179471 % completed\n",
            "27.542237806821806 % completed\n",
            "27.5581766018489 % completed\n",
            "27.574115396875996 % completed\n",
            "27.590054191903093 % completed\n",
            "27.60599298693019 % completed\n",
            "27.621931781957283 % completed\n",
            "27.63787057698438 % completed\n",
            "27.653809372011477 % completed\n",
            "27.669748167038573 % completed\n",
            "27.685686962065667 % completed\n",
            "27.701625757092764 % completed\n",
            "27.71756455211986 % completed\n",
            "27.733503347146957 % completed\n",
            "27.74944214217405 % completed\n",
            "27.765380937201147 % completed\n",
            "27.781319732228244 % completed\n",
            "27.79725852725534 % completed\n",
            "27.813197322282434 % completed\n",
            "27.82913611730953 % completed\n",
            "27.845074912336628 % completed\n",
            "27.861013707363725 % completed\n",
            "27.876952502390818 % completed\n",
            "27.892891297417915 % completed\n",
            "27.90883009244501 % completed\n",
            "27.92476888747211 % completed\n",
            "27.940707682499202 % completed\n",
            "27.9566464775263 % completed\n",
            "27.972585272553395 % completed\n",
            "27.988524067580492 % completed\n",
            "28.004462862607586 % completed\n",
            "28.020401657634682 % completed\n",
            "28.03634045266178 % completed\n",
            "28.052279247688876 % completed\n",
            "28.06821804271597 % completed\n",
            "28.084156837743066 % completed\n",
            "28.100095632770163 % completed\n",
            "28.11603442779726 % completed\n",
            "28.131973222824353 % completed\n",
            "28.14791201785145 % completed\n",
            "28.163850812878547 % completed\n",
            "28.179789607905644 % completed\n",
            "28.195728402932737 % completed\n",
            "28.211667197959834 % completed\n",
            "28.22760599298693 % completed\n",
            "28.243544788014027 % completed\n",
            "28.25948358304112 % completed\n",
            "28.275422378068217 % completed\n",
            "28.291361173095314 % completed\n",
            "28.30729996812241 % completed\n",
            "28.323238763149504 % completed\n",
            "28.3391775581766 % completed\n",
            "28.355116353203698 % completed\n",
            "28.371055148230795 % completed\n",
            "28.386993943257888 % completed\n",
            "28.402932738284985 % completed\n",
            "28.418871533312082 % completed\n",
            "28.43481032833918 % completed\n",
            "28.450749123366272 % completed\n",
            "28.46668791839337 % completed\n",
            "28.482626713420466 % completed\n",
            "28.498565508447562 % completed\n",
            "28.514504303474656 % completed\n",
            "28.530443098501753 % completed\n",
            "28.54638189352885 % completed\n",
            "28.562320688555946 % completed\n",
            "28.57825948358304 % completed\n",
            "28.594198278610136 % completed\n",
            "28.610137073637233 % completed\n",
            "28.62607586866433 % completed\n",
            "28.642014663691423 % completed\n",
            "28.65795345871852 % completed\n",
            "28.673892253745617 % completed\n",
            "28.689831048772714 % completed\n",
            "28.705769843799807 % completed\n",
            "28.721708638826904 % completed\n",
            "28.737647433854 % completed\n",
            "28.753586228881097 % completed\n",
            "28.76952502390819 % completed\n",
            "28.785463818935288 % completed\n",
            "28.801402613962384 % completed\n",
            "28.81734140898948 % completed\n",
            "28.833280204016578 % completed\n",
            "28.84921899904367 % completed\n",
            "28.865157794070768 % completed\n",
            "28.881096589097865 % completed\n",
            "28.897035384124962 % completed\n",
            "28.912974179152055 % completed\n",
            "28.928912974179152 % completed\n",
            "28.94485176920625 % completed\n",
            "28.960790564233346 % completed\n",
            "28.97672935926044 % completed\n",
            "28.992668154287536 % completed\n",
            "29.008606949314633 % completed\n",
            "29.02454574434173 % completed\n",
            "29.040484539368823 % completed\n",
            "29.05642333439592 % completed\n",
            "29.072362129423016 % completed\n",
            "29.088300924450113 % completed\n",
            "29.104239719477206 % completed\n",
            "29.120178514504303 % completed\n",
            "29.1361173095314 % completed\n",
            "29.152056104558497 % completed\n",
            "29.16799489958559 % completed\n",
            "29.183933694612687 % completed\n",
            "29.199872489639784 % completed\n",
            "29.21581128466688 % completed\n",
            "29.231750079693974 % completed\n",
            "29.24768887472107 % completed\n",
            "29.263627669748168 % completed\n",
            "29.279566464775264 % completed\n",
            "29.295505259802358 % completed\n",
            "29.311444054829455 % completed\n",
            "29.32738284985655 % completed\n",
            "29.34332164488365 % completed\n",
            "29.35926043991074 % completed\n",
            "29.37519923493784 % completed\n",
            "29.391138029964935 % completed\n",
            "29.407076824992032 % completed\n",
            "29.423015620019125 % completed\n",
            "29.438954415046222 % completed\n",
            "29.45489321007332 % completed\n",
            "29.470832005100416 % completed\n",
            "29.48677080012751 % completed\n",
            "29.502709595154606 % completed\n",
            "29.518648390181703 % completed\n",
            "29.5345871852088 % completed\n",
            "29.550525980235893 % completed\n",
            "29.56646477526299 % completed\n",
            "29.582403570290086 % completed\n",
            "29.598342365317183 % completed\n",
            "29.614281160344277 % completed\n",
            "29.630219955371373 % completed\n",
            "29.64615875039847 % completed\n",
            "29.662097545425567 % completed\n",
            "29.67803634045266 % completed\n",
            "29.693975135479757 % completed\n",
            "29.709913930506854 % completed\n",
            "29.72585272553395 % completed\n",
            "29.741791520561044 % completed\n",
            "29.75773031558814 % completed\n",
            "29.773669110615238 % completed\n",
            "29.789607905642335 % completed\n",
            "29.805546700669428 % completed\n",
            "29.821485495696525 % completed\n",
            "29.83742429072362 % completed\n",
            "29.85336308575072 % completed\n",
            "29.86930188077781 % completed\n",
            "29.88524067580491 % completed\n",
            "29.901179470832005 % completed\n",
            "29.917118265859102 % completed\n",
            "29.933057060886195 % completed\n",
            "29.948995855913292 % completed\n",
            "29.96493465094039 % completed\n",
            "29.980873445967486 % completed\n",
            "29.99681224099458 % completed\n",
            "30.012751036021676 % completed\n",
            "30.028689831048773 % completed\n",
            "30.04462862607587 % completed\n",
            "30.060567421102963 % completed\n",
            "30.07650621613006 % completed\n",
            "30.092445011157157 % completed\n",
            "30.108383806184253 % completed\n",
            "30.124322601211347 % completed\n",
            "30.140261396238444 % completed\n",
            "30.15620019126554 % completed\n",
            "30.172138986292637 % completed\n",
            "30.18807778131973 % completed\n",
            "30.204016576346827 % completed\n",
            "30.219955371373924 % completed\n",
            "30.23589416640102 % completed\n",
            "30.251832961428114 % completed\n",
            "30.26777175645521 % completed\n",
            "30.283710551482308 % completed\n",
            "30.299649346509405 % completed\n",
            "30.3155881415365 % completed\n",
            "30.331526936563595 % completed\n",
            "30.34746573159069 % completed\n",
            "30.36340452661779 % completed\n",
            "30.379343321644885 % completed\n",
            "30.39528211667198 % completed\n",
            "30.411220911699075 % completed\n",
            "30.427159706726172 % completed\n",
            "30.44309850175327 % completed\n",
            "30.459037296780362 % completed\n",
            "30.47497609180746 % completed\n",
            "30.490914886834556 % completed\n",
            "30.506853681861653 % completed\n",
            "30.522792476888746 % completed\n",
            "30.538731271915843 % completed\n",
            "30.55467006694294 % completed\n",
            "30.570608861970037 % completed\n",
            "30.58654765699713 % completed\n",
            "30.602486452024227 % completed\n",
            "30.618425247051324 % completed\n",
            "30.63436404207842 % completed\n",
            "30.650302837105514 % completed\n",
            "30.66624163213261 % completed\n",
            "30.682180427159707 % completed\n",
            "30.698119222186804 % completed\n",
            "30.714058017213898 % completed\n",
            "30.729996812240994 % completed\n",
            "30.74593560726809 % completed\n",
            "30.761874402295188 % completed\n",
            "30.77781319732228 % completed\n",
            "30.793751992349378 % completed\n",
            "30.809690787376475 % completed\n",
            "30.82562958240357 % completed\n",
            "30.841568377430665 % completed\n",
            "30.857507172457762 % completed\n",
            "30.87344596748486 % completed\n",
            "30.889384762511956 % completed\n",
            "30.90532355753905 % completed\n",
            "30.921262352566146 % completed\n",
            "30.937201147593242 % completed\n",
            "30.95313994262034 % completed\n",
            "30.969078737647433 % completed\n",
            "30.98501753267453 % completed\n",
            "31.000956327701626 % completed\n",
            "31.016895122728723 % completed\n",
            "31.032833917755816 % completed\n",
            "31.048772712782913 % completed\n",
            "31.06471150781001 % completed\n",
            "31.080650302837107 % completed\n",
            "31.0965890978642 % completed\n",
            "31.112527892891297 % completed\n",
            "31.128466687918394 % completed\n",
            "31.14440548294549 % completed\n",
            "31.160344277972584 % completed\n",
            "31.17628307299968 % completed\n",
            "31.192221868026778 % completed\n",
            "31.208160663053874 % completed\n",
            "31.224099458080968 % completed\n",
            "31.240038253108064 % completed\n",
            "31.25597704813516 % completed\n",
            "31.271915843162258 % completed\n",
            "31.28785463818935 % completed\n",
            "31.30379343321645 % completed\n",
            "31.319732228243545 % completed\n",
            "31.335671023270642 % completed\n",
            "31.351609818297735 % completed\n",
            "31.367548613324832 % completed\n",
            "31.38348740835193 % completed\n",
            "31.399426203379026 % completed\n",
            "31.41536499840612 % completed\n",
            "31.431303793433216 % completed\n",
            "31.447242588460313 % completed\n",
            "31.46318138348741 % completed\n",
            "31.479120178514503 % completed\n",
            "31.4950589735416 % completed\n",
            "31.510997768568696 % completed\n",
            "31.526936563595793 % completed\n",
            "31.542875358622886 % completed\n",
            "31.558814153649983 % completed\n",
            "31.57475294867708 % completed\n",
            "31.590691743704177 % completed\n",
            "31.60663053873127 % completed\n",
            "31.622569333758367 % completed\n",
            "31.638508128785464 % completed\n",
            "31.65444692381256 % completed\n",
            "31.670385718839654 % completed\n",
            "31.68632451386675 % completed\n",
            "31.702263308893848 % completed\n",
            "31.718202103920945 % completed\n",
            "31.734140898948038 % completed\n",
            "31.750079693975135 % completed\n",
            "31.76601848900223 % completed\n",
            "31.78195728402933 % completed\n",
            "31.79789607905642 % completed\n",
            "31.81383487408352 % completed\n",
            "31.829773669110615 % completed\n",
            "31.845712464137712 % completed\n",
            "31.86165125916481 % completed\n",
            "31.877590054191902 % completed\n",
            "31.893528849219 % completed\n",
            "31.909467644246096 % completed\n",
            "31.925406439273193 % completed\n",
            "31.941345234300286 % completed\n",
            "31.957284029327383 % completed\n",
            "31.97322282435448 % completed\n",
            "31.989161619381576 % completed\n",
            "32.00510041440867 % completed\n",
            "32.02103920943577 % completed\n",
            "32.03697800446286 % completed\n",
            "32.05291679948996 % completed\n",
            "32.06885559451705 % completed\n",
            "32.08479438954415 % completed\n",
            "32.10073318457125 % completed\n",
            "32.116671979598344 % completed\n",
            "32.13261077462544 % completed\n",
            "32.14854956965254 % completed\n",
            "32.16448836467963 % completed\n",
            "32.180427159706724 % completed\n",
            "32.19636595473382 % completed\n",
            "32.21230474976092 % completed\n",
            "32.228243544788015 % completed\n",
            "32.24418233981511 % completed\n",
            "32.26012113484221 % completed\n",
            "32.276059929869305 % completed\n",
            "32.291998724896395 % completed\n",
            "32.30793751992349 % completed\n",
            "32.32387631495059 % completed\n",
            "32.339815109977685 % completed\n",
            "32.35575390500478 % completed\n",
            "32.37169270003188 % completed\n",
            "32.387631495058976 % completed\n",
            "32.40357029008607 % completed\n",
            "32.41950908511316 % completed\n",
            "32.43544788014026 % completed\n",
            "32.451386675167356 % completed\n",
            "32.46732547019445 % completed\n",
            "32.48326426522155 % completed\n",
            "32.49920306024865 % completed\n",
            "32.51514185527574 % completed\n",
            "32.53108065030284 % completed\n",
            "32.54701944532993 % completed\n",
            "32.56295824035703 % completed\n",
            "32.578897035384124 % completed\n",
            "32.59483583041122 % completed\n",
            "32.61077462543832 % completed\n",
            "32.626713420465414 % completed\n",
            "32.64265221549251 % completed\n",
            "32.65859101051961 % completed\n",
            "32.6745298055467 % completed\n",
            "32.690468600573794 % completed\n",
            "32.70640739560089 % completed\n",
            "32.72234619062799 % completed\n",
            "32.738284985655085 % completed\n",
            "32.75422378068218 % completed\n",
            "32.77016257570928 % completed\n",
            "32.786101370736375 % completed\n",
            "32.802040165763465 % completed\n",
            "32.81797896079056 % completed\n",
            "32.83391775581766 % completed\n",
            "32.849856550844756 % completed\n",
            "32.86579534587185 % completed\n",
            "32.88173414089895 % completed\n",
            "32.897672935926046 % completed\n",
            "32.91361173095314 % completed\n",
            "32.92955052598023 % completed\n",
            "32.94548932100733 % completed\n",
            "32.961428116034426 % completed\n",
            "32.97736691106152 % completed\n",
            "32.99330570608862 % completed\n",
            "33.00924450111572 % completed\n",
            "33.025183296142814 % completed\n",
            "33.04112209116991 % completed\n",
            "33.057060886197 % completed\n",
            "33.0729996812241 % completed\n",
            "33.088938476251194 % completed\n",
            "33.10487727127829 % completed\n",
            "33.12081606630539 % completed\n",
            "33.136754861332484 % completed\n",
            "33.15269365635958 % completed\n",
            "33.16863245138668 % completed\n",
            "33.18457124641377 % completed\n",
            "33.200510041440864 % completed\n",
            "33.21644883646796 % completed\n",
            "33.23238763149506 % completed\n",
            "33.248326426522155 % completed\n",
            "33.26426522154925 % completed\n",
            "33.28020401657635 % completed\n",
            "33.296142811603445 % completed\n",
            "33.312081606630535 % completed\n",
            "33.32802040165763 % completed\n",
            "33.34395919668473 % completed\n",
            "33.359897991711826 % completed\n",
            "33.37583678673892 % completed\n",
            "33.39177558176602 % completed\n",
            "33.407714376793116 % completed\n",
            "33.42365317182021 % completed\n",
            "33.43959196684731 % completed\n",
            "33.4555307618744 % completed\n",
            "33.471469556901496 % completed\n",
            "33.48740835192859 % completed\n",
            "33.50334714695569 % completed\n",
            "33.51928594198279 % completed\n",
            "33.535224737009884 % completed\n",
            "33.55116353203698 % completed\n",
            "33.56710232706408 % completed\n",
            "33.58304112209117 % completed\n",
            "33.598979917118264 % completed\n",
            "33.61491871214536 % completed\n",
            "33.63085750717246 % completed\n",
            "33.646796302199554 % completed\n",
            "33.66273509722665 % completed\n",
            "33.67867389225375 % completed\n",
            "33.694612687280845 % completed\n",
            "33.710551482307935 % completed\n",
            "33.72649027733503 % completed\n",
            "33.74242907236213 % completed\n",
            "33.758367867389225 % completed\n",
            "33.77430666241632 % completed\n",
            "33.79024545744342 % completed\n",
            "33.806184252470516 % completed\n",
            "33.82212304749761 % completed\n",
            "33.8380618425247 % completed\n",
            "33.8540006375518 % completed\n",
            "33.869939432578896 % completed\n",
            "33.88587822760599 % completed\n",
            "33.90181702263309 % completed\n",
            "33.917755817660186 % completed\n",
            "33.93369461268728 % completed\n",
            "33.94963340771438 % completed\n",
            "33.96557220274147 % completed\n",
            "33.98151099776857 % completed\n",
            "33.99744979279566 % completed\n",
            "34.01338858782276 % completed\n",
            "34.02932738284986 % completed\n",
            "34.045266177876954 % completed\n",
            "34.06120497290405 % completed\n",
            "34.07714376793115 % completed\n",
            "34.09308256295824 % completed\n",
            "34.109021357985334 % completed\n",
            "34.12496015301243 % completed\n",
            "34.14089894803953 % completed\n",
            "34.156837743066625 % completed\n",
            "34.17277653809372 % completed\n",
            "34.18871533312082 % completed\n",
            "34.204654128147915 % completed\n",
            "34.220592923175005 % completed\n",
            "34.2365317182021 % completed\n",
            "34.2524705132292 % completed\n",
            "34.268409308256295 % completed\n",
            "34.28434810328339 % completed\n",
            "34.30028689831049 % completed\n",
            "34.316225693337586 % completed\n",
            "34.33216448836468 % completed\n",
            "34.34810328339177 % completed\n",
            "34.36404207841887 % completed\n",
            "34.379980873445966 % completed\n",
            "34.39591966847306 % completed\n",
            "34.41185846350016 % completed\n",
            "34.42779725852726 % completed\n",
            "34.44373605355435 % completed\n",
            "34.45967484858145 % completed\n",
            "34.47561364360854 % completed\n",
            "34.49155243863564 % completed\n",
            "34.50749123366273 % completed\n",
            "34.52343002868983 % completed\n",
            "34.53936882371693 % completed\n",
            "34.555307618744024 % completed\n",
            "34.57124641377112 % completed\n",
            "34.58718520879822 % completed\n",
            "34.60312400382531 % completed\n",
            "34.619062798852404 % completed\n",
            "34.6350015938795 % completed\n",
            "34.6509403889066 % completed\n",
            "34.666879183933695 % completed\n",
            "34.68281797896079 % completed\n",
            "34.69875677398789 % completed\n",
            "34.714695569014985 % completed\n",
            "34.730634364042075 % completed\n",
            "34.74657315906917 % completed\n",
            "34.76251195409627 % completed\n",
            "34.778450749123365 % completed\n",
            "34.79438954415046 % completed\n",
            "34.81032833917756 % completed\n",
            "34.826267134204656 % completed\n",
            "34.84220592923175 % completed\n",
            "34.85814472425885 % completed\n",
            "34.87408351928594 % completed\n",
            "34.890022314313036 % completed\n",
            "34.90596110934013 % completed\n",
            "34.92189990436723 % completed\n",
            "34.93783869939433 % completed\n",
            "34.95377749442142 % completed\n",
            "34.96971628944852 % completed\n",
            "34.98565508447562 % completed\n",
            "35.00159387950271 % completed\n",
            "35.017532674529804 % completed\n",
            "35.0334714695569 % completed\n",
            "35.049410264584 % completed\n",
            "35.065349059611094 % completed\n",
            "35.08128785463819 % completed\n",
            "35.09722664966529 % completed\n",
            "35.113165444692385 % completed\n",
            "35.129104239719474 % completed\n",
            "35.14504303474657 % completed\n",
            "35.16098182977367 % completed\n",
            "35.176920624800765 % completed\n",
            "35.19285941982786 % completed\n",
            "35.20879821485496 % completed\n",
            "35.224737009882055 % completed\n",
            "35.24067580490915 % completed\n",
            "35.25661459993624 % completed\n",
            "35.27255339496334 % completed\n",
            "35.288492189990436 % completed\n",
            "35.30443098501753 % completed\n",
            "35.32036978004463 % completed\n",
            "35.336308575071726 % completed\n",
            "35.35224737009882 % completed\n",
            "35.36818616512592 % completed\n",
            "35.38412496015301 % completed\n",
            "35.400063755180106 % completed\n",
            "35.4160025502072 % completed\n",
            "35.4319413452343 % completed\n",
            "35.4478801402614 % completed\n",
            "35.463818935288494 % completed\n",
            "35.47975773031559 % completed\n",
            "35.49569652534269 % completed\n",
            "35.51163532036978 % completed\n",
            "35.527574115396874 % completed\n",
            "35.54351291042397 % completed\n",
            "35.55945170545107 % completed\n",
            "35.575390500478164 % completed\n",
            "35.59132929550526 % completed\n",
            "35.60726809053236 % completed\n",
            "35.623206885559455 % completed\n",
            "35.639145680586545 % completed\n",
            "35.65508447561364 % completed\n",
            "35.67102327064074 % completed\n",
            "35.686962065667835 % completed\n",
            "35.70290086069493 % completed\n",
            "35.71883965572203 % completed\n",
            "35.734778450749126 % completed\n",
            "35.75071724577622 % completed\n",
            "35.76665604080331 % completed\n",
            "35.78259483583041 % completed\n",
            "35.798533630857506 % completed\n",
            "35.8144724258846 % completed\n",
            "35.8304112209117 % completed\n",
            "35.846350015938796 % completed\n",
            "35.86228881096589 % completed\n",
            "35.87822760599299 % completed\n",
            "35.89416640102008 % completed\n",
            "35.910105196047176 % completed\n",
            "35.92604399107427 % completed\n",
            "35.94198278610137 % completed\n",
            "35.95792158112847 % completed\n",
            "35.973860376155564 % completed\n",
            "35.98979917118266 % completed\n",
            "36.00573796620976 % completed\n",
            "36.02167676123685 % completed\n",
            "36.037615556263944 % completed\n",
            "36.05355435129104 % completed\n",
            "36.06949314631814 % completed\n",
            "36.085431941345234 % completed\n",
            "36.10137073637233 % completed\n",
            "36.11730953139943 % completed\n",
            "36.133248326426525 % completed\n",
            "36.149187121453615 % completed\n",
            "36.16512591648071 % completed\n",
            "36.18106471150781 % completed\n",
            "36.197003506534905 % completed\n",
            "36.212942301562 % completed\n",
            "36.2288810965891 % completed\n",
            "36.244819891616196 % completed\n",
            "36.26075868664329 % completed\n",
            "36.27669748167038 % completed\n",
            "36.29263627669748 % completed\n",
            "36.308575071724576 % completed\n",
            "36.32451386675167 % completed\n",
            "36.34045266177877 % completed\n",
            "36.356391456805866 % completed\n",
            "36.37233025183296 % completed\n",
            "36.38826904686006 % completed\n",
            "36.40420784188716 % completed\n",
            "36.42014663691425 % completed\n",
            "36.43608543194134 % completed\n",
            "36.45202422696844 % completed\n",
            "36.46796302199554 % completed\n",
            "36.483901817022634 % completed\n",
            "36.49984061204973 % completed\n",
            "36.51577940707683 % completed\n",
            "36.531718202103924 % completed\n",
            "36.547656997131014 % completed\n",
            "36.56359579215811 % completed\n",
            "36.57953458718521 % completed\n",
            "36.595473382212305 % completed\n",
            "36.6114121772394 % completed\n",
            "36.6273509722665 % completed\n",
            "36.643289767293595 % completed\n",
            "36.65922856232069 % completed\n",
            "36.67516735734778 % completed\n",
            "36.69110615237488 % completed\n",
            "36.707044947401975 % completed\n",
            "36.72298374242907 % completed\n",
            "36.73892253745617 % completed\n",
            "36.754861332483266 % completed\n",
            "36.77080012751036 % completed\n",
            "36.78673892253746 % completed\n",
            "36.80267771756455 % completed\n",
            "36.818616512591646 % completed\n",
            "36.83455530761874 % completed\n",
            "36.85049410264584 % completed\n",
            "36.86643289767294 % completed\n",
            "36.88237169270003 % completed\n",
            "36.89831048772713 % completed\n",
            "36.91424928275423 % completed\n",
            "36.93018807778132 % completed\n",
            "36.946126872808414 % completed\n",
            "36.96206566783551 % completed\n",
            "36.97800446286261 % completed\n",
            "36.993943257889704 % completed\n",
            "37.0098820529168 % completed\n",
            "37.0258208479439 % completed\n",
            "37.041759642970995 % completed\n",
            "37.057698437998084 % completed\n",
            "37.07363723302518 % completed\n",
            "37.08957602805228 % completed\n",
            "37.105514823079375 % completed\n",
            "37.12145361810647 % completed\n",
            "37.13739241313357 % completed\n",
            "37.153331208160665 % completed\n",
            "37.16927000318776 % completed\n",
            "37.18520879821485 % completed\n",
            "37.20114759324195 % completed\n",
            "37.217086388269045 % completed\n",
            "37.23302518329614 % completed\n",
            "37.24896397832324 % completed\n",
            "37.264902773350336 % completed\n",
            "37.28084156837743 % completed\n",
            "37.29678036340453 % completed\n",
            "37.31271915843162 % completed\n",
            "37.328657953458716 % completed\n",
            "37.34459674848581 % completed\n",
            "37.36053554351291 % completed\n",
            "37.37647433854001 % completed\n",
            "37.3924131335671 % completed\n",
            "37.4083519285942 % completed\n",
            "37.4242907236213 % completed\n",
            "37.44022951864839 % completed\n",
            "37.456168313675484 % completed\n",
            "37.47210710870258 % completed\n",
            "37.48804590372968 % completed\n",
            "37.503984698756774 % completed\n",
            "37.51992349378387 % completed\n",
            "37.53586228881097 % completed\n",
            "37.551801083838065 % completed\n",
            "37.567739878865154 % completed\n",
            "37.58367867389225 % completed\n",
            "37.59961746891935 % completed\n",
            "37.615556263946445 % completed\n",
            "37.63149505897354 % completed\n",
            "37.64743385400064 % completed\n",
            "37.663372649027735 % completed\n",
            "37.67931144405483 % completed\n",
            "37.69525023908192 % completed\n",
            "37.71118903410902 % completed\n",
            "37.727127829136116 % completed\n",
            "37.74306662416321 % completed\n",
            "37.75900541919031 % completed\n",
            "37.774944214217406 % completed\n",
            "37.7908830092445 % completed\n",
            "37.8068218042716 % completed\n",
            "37.82276059929869 % completed\n",
            "37.838699394325786 % completed\n",
            "37.85463818935288 % completed\n",
            "37.87057698437998 % completed\n",
            "37.88651577940708 % completed\n",
            "37.902454574434174 % completed\n",
            "37.91839336946127 % completed\n",
            "37.93433216448837 % completed\n",
            "37.950270959515464 % completed\n",
            "37.966209754542554 % completed\n",
            "37.98214854956965 % completed\n",
            "37.99808734459675 % completed\n",
            "38.014026139623844 % completed\n",
            "38.02996493465094 % completed\n",
            "38.04590372967804 % completed\n",
            "38.061842524705135 % completed\n",
            "38.07778131973223 % completed\n",
            "38.09372011475932 % completed\n",
            "38.10965890978642 % completed\n",
            "38.125597704813515 % completed\n",
            "38.14153649984061 % completed\n",
            "38.15747529486771 % completed\n",
            "38.173414089894806 % completed\n",
            "38.1893528849219 % completed\n",
            "38.205291679949 % completed\n",
            "38.22123047497609 % completed\n",
            "38.237169270003186 % completed\n",
            "38.25310806503028 % completed\n",
            "38.26904686005738 % completed\n",
            "38.284985655084476 % completed\n",
            "38.30092445011157 % completed\n",
            "38.31686324513867 % completed\n",
            "38.33280204016577 % completed\n",
            "38.34874083519286 % completed\n",
            "38.36467963021995 % completed\n",
            "38.38061842524705 % completed\n",
            "38.39655722027415 % completed\n",
            "38.412496015301244 % completed\n",
            "38.42843481032834 % completed\n",
            "38.44437360535544 % completed\n",
            "38.460312400382534 % completed\n",
            "38.476251195409624 % completed\n",
            "38.49218999043672 % completed\n",
            "38.50812878546382 % completed\n",
            "38.524067580490915 % completed\n",
            "38.54000637551801 % completed\n",
            "38.55594517054511 % completed\n",
            "38.571883965572205 % completed\n",
            "38.5878227605993 % completed\n",
            "38.60376155562639 % completed\n",
            "38.61970035065349 % completed\n",
            "38.635639145680585 % completed\n",
            "38.65157794070768 % completed\n",
            "38.66751673573478 % completed\n",
            "38.683455530761876 % completed\n",
            "38.69939432578897 % completed\n",
            "38.71533312081607 % completed\n",
            "38.73127191584316 % completed\n",
            "38.747210710870256 % completed\n",
            "38.76314950589735 % completed\n",
            "38.77908830092445 % completed\n",
            "38.795027095951546 % completed\n",
            "38.81096589097864 % completed\n",
            "38.82690468600574 % completed\n",
            "38.84284348103284 % completed\n",
            "38.85878227605993 % completed\n",
            "38.87472107108702 % completed\n",
            "38.89065986611412 % completed\n",
            "38.90659866114122 % completed\n",
            "38.922537456168314 % completed\n",
            "38.93847625119541 % completed\n",
            "38.95441504622251 % completed\n",
            "38.970353841249604 % completed\n",
            "38.986292636276694 % completed\n",
            "39.00223143130379 % completed\n",
            "39.01817022633089 % completed\n",
            "39.034109021357985 % completed\n",
            "39.05004781638508 % completed\n",
            "39.06598661141218 % completed\n",
            "39.081925406439275 % completed\n",
            "39.09786420146637 % completed\n",
            "39.11380299649346 % completed\n",
            "39.12974179152056 % completed\n",
            "39.145680586547655 % completed\n",
            "39.16161938157475 % completed\n",
            "39.17755817660185 % completed\n",
            "39.193496971628946 % completed\n",
            "39.20943576665604 % completed\n",
            "39.22537456168314 % completed\n",
            "39.24131335671023 % completed\n",
            "39.257252151737326 % completed\n",
            "39.27319094676442 % completed\n",
            "39.28912974179152 % completed\n",
            "39.30506853681862 % completed\n",
            "39.32100733184571 % completed\n",
            "39.33694612687281 % completed\n",
            "39.35288492189991 % completed\n",
            "39.368823716927 % completed\n",
            "39.384762511954094 % completed\n",
            "39.40070130698119 % completed\n",
            "39.41664010200829 % completed\n",
            "39.432578897035384 % completed\n",
            "39.44851769206248 % completed\n",
            "39.46445648708958 % completed\n",
            "39.480395282116675 % completed\n",
            "39.49633407714377 % completed\n",
            "39.51227287217086 % completed\n",
            "39.52821166719796 % completed\n",
            "39.544150462225055 % completed\n",
            "39.56008925725215 % completed\n",
            "39.57602805227925 % completed\n",
            "39.591966847306345 % completed\n",
            "39.60790564233344 % completed\n",
            "39.62384443736054 % completed\n",
            "39.63978323238763 % completed\n",
            "39.655722027414726 % completed\n",
            "39.67166082244182 % completed\n",
            "39.68759961746892 % completed\n",
            "39.703538412496016 % completed\n",
            "39.71947720752311 % completed\n",
            "39.73541600255021 % completed\n",
            "39.75135479757731 % completed\n",
            "39.767293592604396 % completed\n",
            "39.78323238763149 % completed\n",
            "39.79917118265859 % completed\n",
            "39.81510997768569 % completed\n",
            "39.83104877271278 % completed\n",
            "39.84698756773988 % completed\n",
            "39.86292636276698 % completed\n",
            "39.878865157794074 % completed\n",
            "39.894803952821164 % completed\n",
            "39.91074274784826 % completed\n",
            "39.92668154287536 % completed\n",
            "39.942620337902454 % completed\n",
            "39.95855913292955 % completed\n",
            "39.97449792795665 % completed\n",
            "39.990436722983745 % completed\n",
            "40.00637551801084 % completed\n",
            "40.02231431303793 % completed\n",
            "40.03825310806503 % completed\n",
            "40.054191903092125 % completed\n",
            "40.07013069811922 % completed\n",
            "40.08606949314632 % completed\n",
            "40.102008288173415 % completed\n",
            "40.11794708320051 % completed\n",
            "40.13388587822761 % completed\n",
            "40.1498246732547 % completed\n",
            "40.165763468281796 % completed\n",
            "40.18170226330889 % completed\n",
            "40.19764105833599 % completed\n",
            "40.213579853363086 % completed\n",
            "40.22951864839018 % completed\n",
            "40.24545744341728 % completed\n",
            "40.26139623844438 % completed\n",
            "40.277335033471466 % completed\n",
            "40.29327382849856 % completed\n",
            "40.30921262352566 % completed\n",
            "40.32515141855276 % completed\n",
            "40.341090213579854 % completed\n",
            "40.35702900860695 % completed\n",
            "40.37296780363405 % completed\n",
            "40.388906598661144 % completed\n",
            "40.404845393688234 % completed\n",
            "40.42078418871533 % completed\n",
            "40.43672298374243 % completed\n",
            "40.452661778769524 % completed\n",
            "40.46860057379662 % completed\n",
            "40.48453936882372 % completed\n",
            "40.500478163850815 % completed\n",
            "40.51641695887791 % completed\n",
            "40.532355753905 % completed\n",
            "40.5482945489321 % completed\n",
            "40.564233343959195 % completed\n",
            "40.58017213898629 % completed\n",
            "40.59611093401339 % completed\n",
            "40.612049729040486 % completed\n",
            "40.62798852406758 % completed\n",
            "40.64392731909468 % completed\n",
            "40.65986611412177 % completed\n",
            "40.675804909148866 % completed\n",
            "40.69174370417596 % completed\n",
            "40.70768249920306 % completed\n",
            "40.723621294230156 % completed\n",
            "40.73956008925725 % completed\n",
            "40.75549888428435 % completed\n",
            "40.77143767931145 % completed\n",
            "40.78737647433854 % completed\n",
            "40.80331526936563 % completed\n",
            "40.81925406439273 % completed\n",
            "40.83519285941983 % completed\n",
            "40.851131654446924 % completed\n",
            "40.86707044947402 % completed\n",
            "40.88300924450112 % completed\n",
            "40.898948039528214 % completed\n",
            "40.91488683455531 % completed\n",
            "40.9308256295824 % completed\n",
            "40.9467644246095 % completed\n",
            "40.962703219636595 % completed\n",
            "40.97864201466369 % completed\n",
            "40.99458080969079 % completed\n",
            "41.010519604717885 % completed\n",
            "41.02645839974498 % completed\n",
            "41.04239719477208 % completed\n",
            "41.05833598979917 % completed\n",
            "41.074274784826265 % completed\n",
            "41.09021357985336 % completed\n",
            "41.10615237488046 % completed\n",
            "41.122091169907556 % completed\n",
            "41.13802996493465 % completed\n",
            "41.15396875996175 % completed\n",
            "41.169907554988846 % completed\n",
            "41.185846350015936 % completed\n",
            "41.20178514504303 % completed\n",
            "41.21772394007013 % completed\n",
            "41.23366273509723 % completed\n",
            "41.24960153012432 % completed\n",
            "41.26554032515142 % completed\n",
            "41.28147912017852 % completed\n",
            "41.297417915205614 % completed\n",
            "41.3133567102327 % completed\n",
            "41.3292955052598 % completed\n",
            "41.3452343002869 % completed\n",
            "41.361173095313994 % completed\n",
            "41.37711189034109 % completed\n",
            "41.39305068536819 % completed\n",
            "41.408989480395284 % completed\n",
            "41.42492827542238 % completed\n",
            "41.44086707044947 % completed\n",
            "41.45680586547657 % completed\n",
            "41.472744660503665 % completed\n",
            "41.48868345553076 % completed\n",
            "41.50462225055786 % completed\n",
            "41.520561045584955 % completed\n",
            "41.53649984061205 % completed\n",
            "41.55243863563915 % completed\n",
            "41.56837743066624 % completed\n",
            "41.584316225693335 % completed\n",
            "41.60025502072043 % completed\n",
            "41.61619381574753 % completed\n",
            "41.632132610774626 % completed\n",
            "41.64807140580172 % completed\n",
            "41.66401020082882 % completed\n",
            "41.679948995855916 % completed\n",
            "41.695887790883006 % completed\n",
            "41.7118265859101 % completed\n",
            "41.7277653809372 % completed\n",
            "41.7437041759643 % completed\n",
            "41.75964297099139 % completed\n",
            "41.77558176601849 % completed\n",
            "41.79152056104559 % completed\n",
            "41.807459356072684 % completed\n",
            "41.823398151099774 % completed\n",
            "41.83933694612687 % completed\n",
            "41.85527574115397 % completed\n",
            "41.871214536181064 % completed\n",
            "41.88715333120816 % completed\n",
            "41.90309212623526 % completed\n",
            "41.919030921262355 % completed\n",
            "41.93496971628945 % completed\n",
            "41.95090851131654 % completed\n",
            "41.96684730634364 % completed\n",
            "41.982786101370735 % completed\n",
            "41.99872489639783 % completed\n",
            "42.01466369142493 % completed\n",
            "42.030602486452025 % completed\n",
            "42.04654128147912 % completed\n",
            "42.06248007650622 % completed\n",
            "42.07841887153331 % completed\n",
            "42.094357666560406 % completed\n",
            "42.1102964615875 % completed\n",
            "42.1262352566146 % completed\n",
            "42.142174051641696 % completed\n",
            "42.15811284666879 % completed\n",
            "42.17405164169589 % completed\n",
            "42.18999043672299 % completed\n",
            "42.205929231750076 % completed\n",
            "42.22186802677717 % completed\n",
            "42.23780682180427 % completed\n",
            "42.25374561683137 % completed\n",
            "42.269684411858464 % completed\n",
            "42.28562320688556 % completed\n",
            "42.30156200191266 % completed\n",
            "42.317500796939754 % completed\n",
            "42.333439591966844 % completed\n",
            "42.34937838699394 % completed\n",
            "42.36531718202104 % completed\n",
            "42.381255977048134 % completed\n",
            "42.39719477207523 % completed\n",
            "42.41313356710233 % completed\n",
            "42.429072362129425 % completed\n",
            "42.44501115715652 % completed\n",
            "42.46094995218362 % completed\n",
            "42.47688874721071 % completed\n",
            "42.492827542237805 % completed\n",
            "42.5087663372649 % completed\n",
            "42.524705132292 % completed\n",
            "42.540643927319095 % completed\n",
            "42.55658272234619 % completed\n",
            "42.57252151737329 % completed\n",
            "42.588460312400386 % completed\n",
            "42.604399107427476 % completed\n",
            "42.62033790245457 % completed\n",
            "42.63627669748167 % completed\n",
            "42.652215492508766 % completed\n",
            "42.66815428753586 % completed\n",
            "42.68409308256296 % completed\n",
            "42.70003187759006 % completed\n",
            "42.71597067261715 % completed\n",
            "42.73190946764424 % completed\n",
            "42.74784826267134 % completed\n",
            "42.76378705769844 % completed\n",
            "42.779725852725534 % completed\n",
            "42.79566464775263 % completed\n",
            "42.81160344277973 % completed\n",
            "42.827542237806824 % completed\n",
            "42.84348103283392 % completed\n",
            "42.85941982786101 % completed\n",
            "42.87535862288811 % completed\n",
            "42.891297417915204 % completed\n",
            "42.9072362129423 % completed\n",
            "42.9231750079694 % completed\n",
            "42.939113802996495 % completed\n",
            "42.95505259802359 % completed\n",
            "42.97099139305069 % completed\n",
            "42.98693018807778 % completed\n",
            "43.002868983104875 % completed\n",
            "43.01880777813197 % completed\n",
            "43.03474657315907 % completed\n",
            "43.050685368186166 % completed\n",
            "43.06662416321326 % completed\n",
            "43.08256295824036 % completed\n",
            "43.098501753267456 % completed\n",
            "43.114440548294546 % completed\n",
            "43.13037934332164 % completed\n",
            "43.14631813834874 % completed\n",
            "43.162256933375836 % completed\n",
            "43.17819572840293 % completed\n",
            "43.19413452343003 % completed\n",
            "43.21007331845713 % completed\n",
            "43.226012113484224 % completed\n",
            "43.24195090851131 % completed\n",
            "43.25788970353841 % completed\n",
            "43.27382849856551 % completed\n",
            "43.289767293592604 % completed\n",
            "43.3057060886197 % completed\n",
            "43.3216448836468 % completed\n",
            "43.337583678673894 % completed\n",
            "43.35352247370099 % completed\n",
            "43.36946126872808 % completed\n",
            "43.38540006375518 % completed\n",
            "43.401338858782275 % completed\n",
            "43.41727765380937 % completed\n",
            "43.43321644883647 % completed\n",
            "43.449155243863565 % completed\n",
            "43.46509403889066 % completed\n",
            "43.48103283391776 % completed\n",
            "43.49697162894485 % completed\n",
            "43.512910423971945 % completed\n",
            "43.52884921899904 % completed\n",
            "43.54478801402614 % completed\n",
            "43.560726809053236 % completed\n",
            "43.57666560408033 % completed\n",
            "43.59260439910743 % completed\n",
            "43.608543194134526 % completed\n",
            "43.624481989161616 % completed\n",
            "43.64042078418871 % completed\n",
            "43.65635957921581 % completed\n",
            "43.67229837424291 % completed\n",
            "43.68823716927 % completed\n",
            "43.7041759642971 % completed\n",
            "43.7201147593242 % completed\n",
            "43.736053554351294 % completed\n",
            "43.75199234937838 % completed\n",
            "43.76793114440548 % completed\n",
            "43.78386993943258 % completed\n",
            "43.799808734459674 % completed\n",
            "43.81574752948677 % completed\n",
            "43.83168632451387 % completed\n",
            "43.847625119540965 % completed\n",
            "43.86356391456806 % completed\n",
            "43.87950270959515 % completed\n",
            "43.89544150462225 % completed\n",
            "43.911380299649345 % completed\n",
            "43.92731909467644 % completed\n",
            "43.94325788970354 % completed\n",
            "43.959196684730635 % completed\n",
            "43.97513547975773 % completed\n",
            "43.99107427478483 % completed\n",
            "44.007013069811926 % completed\n",
            "44.022951864839015 % completed\n",
            "44.03889065986611 % completed\n",
            "44.05482945489321 % completed\n",
            "44.070768249920306 % completed\n",
            "44.0867070449474 % completed\n",
            "44.1026458399745 % completed\n",
            "44.118584635001596 % completed\n",
            "44.13452343002869 % completed\n",
            "44.15046222505578 % completed\n",
            "44.16640102008288 % completed\n",
            "44.18233981510998 % completed\n",
            "44.19827861013707 % completed\n",
            "44.21421740516417 % completed\n",
            "44.23015620019127 % completed\n",
            "44.246094995218364 % completed\n",
            "44.26203379024546 % completed\n",
            "44.27797258527255 % completed\n",
            "44.29391138029965 % completed\n",
            "44.309850175326744 % completed\n",
            "44.32578897035384 % completed\n",
            "44.34172776538094 % completed\n",
            "44.357666560408035 % completed\n",
            "44.37360535543513 % completed\n",
            "44.38954415046223 % completed\n",
            "44.40548294548932 % completed\n",
            "44.421421740516415 % completed\n",
            "44.43736053554351 % completed\n",
            "44.45329933057061 % completed\n",
            "44.469238125597705 % completed\n",
            "44.4851769206248 % completed\n",
            "44.5011157156519 % completed\n",
            "44.517054510678996 % completed\n",
            "44.532993305706086 % completed\n",
            "44.54893210073318 % completed\n",
            "44.56487089576028 % completed\n",
            "44.580809690787376 % completed\n",
            "44.59674848581447 % completed\n",
            "44.61268728084157 % completed\n",
            "44.62862607586867 % completed\n",
            "44.64456487089576 % completed\n",
            "44.66050366592285 % completed\n",
            "44.67644246094995 % completed\n",
            "44.69238125597705 % completed\n",
            "44.708320051004144 % completed\n",
            "44.72425884603124 % completed\n",
            "44.74019764105834 % completed\n",
            "44.756136436085434 % completed\n",
            "44.77207523111253 % completed\n",
            "44.78801402613962 % completed\n",
            "44.80395282116672 % completed\n",
            "44.819891616193814 % completed\n",
            "44.83583041122091 % completed\n",
            "44.85176920624801 % completed\n",
            "44.867708001275105 % completed\n",
            "44.8836467963022 % completed\n",
            "44.8995855913293 % completed\n",
            "44.91552438635639 % completed\n",
            "44.931463181383485 % completed\n",
            "44.94740197641058 % completed\n",
            "44.96334077143768 % completed\n",
            "44.979279566464776 % completed\n",
            "44.99521836149187 % completed\n",
            "45.01115715651897 % completed\n",
            "45.027095951546066 % completed\n",
            "45.043034746573156 % completed\n",
            "45.05897354160025 % completed\n",
            "45.07491233662735 % completed\n",
            "45.090851131654446 % completed\n",
            "45.10678992668154 % completed\n",
            "45.12272872170864 % completed\n",
            "45.13866751673574 % completed\n",
            "45.154606311762834 % completed\n",
            "45.17054510678992 % completed\n",
            "45.18648390181702 % completed\n",
            "45.20242269684412 % completed\n",
            "45.218361491871214 % completed\n",
            "45.23430028689831 % completed\n",
            "45.25023908192541 % completed\n",
            "45.266177876952504 % completed\n",
            "45.2821166719796 % completed\n",
            "45.29805546700669 % completed\n",
            "45.31399426203379 % completed\n",
            "45.329933057060884 % completed\n",
            "45.34587185208798 % completed\n",
            "45.36181064711508 % completed\n",
            "45.377749442142175 % completed\n",
            "45.39368823716927 % completed\n",
            "45.40962703219637 % completed\n",
            "45.42556582722346 % completed\n",
            "45.441504622250555 % completed\n",
            "45.45744341727765 % completed\n",
            "45.47338221230475 % completed\n",
            "45.489321007331846 % completed\n",
            "45.50525980235894 % completed\n",
            "45.52119859738604 % completed\n",
            "45.537137392413136 % completed\n",
            "45.55307618744023 % completed\n",
            "45.56901498246732 % completed\n",
            "45.58495377749442 % completed\n",
            "45.600892572521516 % completed\n",
            "45.61683136754861 % completed\n",
            "45.63277016257571 % completed\n",
            "45.64870895760281 % completed\n",
            "45.664647752629904 % completed\n",
            "45.680586547657 % completed\n",
            "45.69652534268409 % completed\n",
            "45.71246413771119 % completed\n",
            "45.728402932738284 % completed\n",
            "45.74434172776538 % completed\n",
            "45.76028052279248 % completed\n",
            "45.776219317819574 % completed\n",
            "45.79215811284667 % completed\n",
            "45.80809690787377 % completed\n",
            "45.82403570290086 % completed\n",
            "45.839974497927955 % completed\n",
            "45.85591329295505 % completed\n",
            "45.87185208798215 % completed\n",
            "45.887790883009245 % completed\n",
            "45.90372967803634 % completed\n",
            "45.91966847306344 % completed\n",
            "45.935607268090536 % completed\n",
            "45.951546063117625 % completed\n",
            "45.96748485814472 % completed\n",
            "45.98342365317182 % completed\n",
            "45.999362448198916 % completed\n",
            "46.01530124322601 % completed\n",
            "46.03124003825311 % completed\n",
            "46.047178833280206 % completed\n",
            "46.0631176283073 % completed\n",
            "46.07905642333439 % completed\n",
            "46.09499521836149 % completed\n",
            "46.11093401338859 % completed\n",
            "46.12687280841568 % completed\n",
            "46.14281160344278 % completed\n",
            "46.15875039846988 % completed\n",
            "46.174689193496974 % completed\n",
            "46.19062798852407 % completed\n",
            "46.20656678355116 % completed\n",
            "46.22250557857826 % completed\n",
            "46.238444373605354 % completed\n",
            "46.25438316863245 % completed\n",
            "46.27032196365955 % completed\n",
            "46.286260758686645 % completed\n",
            "46.30219955371374 % completed\n",
            "46.31813834874084 % completed\n",
            "46.33407714376793 % completed\n",
            "46.350015938795025 % completed\n",
            "46.36595473382212 % completed\n",
            "46.38189352884922 % completed\n",
            "46.397832323876315 % completed\n",
            "46.41377111890341 % completed\n",
            "46.42970991393051 % completed\n",
            "46.445648708957606 % completed\n",
            "46.461587503984696 % completed\n",
            "46.47752629901179 % completed\n",
            "46.49346509403889 % completed\n",
            "46.509403889065986 % completed\n",
            "46.52534268409308 % completed\n",
            "46.54128147912018 % completed\n",
            "46.55722027414728 % completed\n",
            "46.57315906917437 % completed\n",
            "46.58909786420146 % completed\n",
            "46.60503665922856 % completed\n",
            "46.62097545425566 % completed\n",
            "46.63691424928275 % completed\n",
            "46.65285304430985 % completed\n",
            "46.66879183933695 % completed\n",
            "46.684730634364044 % completed\n",
            "46.70066942939114 % completed\n",
            "46.71660822441823 % completed\n",
            "46.73254701944533 % completed\n",
            "46.748485814472424 % completed\n",
            "46.76442460949952 % completed\n",
            "46.78036340452662 % completed\n",
            "46.796302199553715 % completed\n",
            "46.81224099458081 % completed\n",
            "46.82817978960791 % completed\n",
            "46.844118584635 % completed\n",
            "46.860057379662095 % completed\n",
            "46.87599617468919 % completed\n",
            "46.89193496971629 % completed\n",
            "46.907873764743385 % completed\n",
            "46.92381255977048 % completed\n",
            "46.93975135479758 % completed\n",
            "46.955690149824676 % completed\n",
            "46.97162894485177 % completed\n",
            "46.98756773987886 % completed\n",
            "47.00350653490596 % completed\n",
            "47.019445329933056 % completed\n",
            "47.03538412496015 % completed\n",
            "47.05132291998725 % completed\n",
            "47.06726171501435 % completed\n",
            "47.08320051004144 % completed\n",
            "47.09913930506854 % completed\n",
            "47.11507810009563 % completed\n",
            "47.13101689512273 % completed\n",
            "47.146955690149824 % completed\n",
            "47.16289448517692 % completed\n",
            "47.17883328020402 % completed\n",
            "47.194772075231114 % completed\n",
            "47.21071087025821 % completed\n",
            "47.22664966528531 % completed\n",
            "47.2425884603124 % completed\n",
            "47.258527255339494 % completed\n",
            "47.27446605036659 % completed\n",
            "47.29040484539369 % completed\n",
            "47.306343640420785 % completed\n",
            "47.32228243544788 % completed\n",
            "47.33822123047498 % completed\n",
            "47.354160025502075 % completed\n",
            "47.370098820529165 % completed\n",
            "47.38603761555626 % completed\n",
            "47.40197641058336 % completed\n",
            "47.417915205610456 % completed\n",
            "47.43385400063755 % completed\n",
            "47.44979279566465 % completed\n",
            "47.465731590691746 % completed\n",
            "47.48167038571884 % completed\n",
            "47.49760918074593 % completed\n",
            "47.51354797577303 % completed\n",
            "47.529486770800126 % completed\n",
            "47.54542556582722 % completed\n",
            "47.56136436085432 % completed\n",
            "47.57730315588142 % completed\n",
            "47.593241950908514 % completed\n",
            "47.60918074593561 % completed\n",
            "47.6251195409627 % completed\n",
            "47.6410583359898 % completed\n",
            "47.656997131016894 % completed\n",
            "47.67293592604399 % completed\n",
            "47.68887472107109 % completed\n",
            "47.704813516098184 % completed\n",
            "47.72075231112528 % completed\n",
            "47.73669110615238 % completed\n",
            "47.75262990117947 % completed\n",
            "47.768568696206565 % completed\n",
            "47.78450749123366 % completed\n",
            "47.80044628626076 % completed\n",
            "47.816385081287855 % completed\n",
            "47.83232387631495 % completed\n",
            "47.84826267134205 % completed\n",
            "47.864201466369146 % completed\n",
            "47.880140261396235 % completed\n",
            "47.89607905642333 % completed\n",
            "47.91201785145043 % completed\n",
            "47.927956646477526 % completed\n",
            "47.94389544150462 % completed\n",
            "47.95983423653172 % completed\n",
            "47.975773031558816 % completed\n",
            "47.99171182658591 % completed\n",
            "48.007650621613 % completed\n",
            "48.0235894166401 % completed\n",
            "48.039528211667196 % completed\n",
            "48.05546700669429 % completed\n",
            "48.07140580172139 % completed\n",
            "48.08734459674849 % completed\n",
            "48.103283391775584 % completed\n",
            "48.11922218680268 % completed\n",
            "48.13516098182977 % completed\n",
            "48.15109977685687 % completed\n",
            "48.167038571883964 % completed\n",
            "48.18297736691106 % completed\n",
            "48.19891616193816 % completed\n",
            "48.214854956965254 % completed\n",
            "48.23079375199235 % completed\n",
            "48.24673254701945 % completed\n",
            "48.26267134204654 % completed\n",
            "48.278610137073635 % completed\n",
            "48.29454893210073 % completed\n",
            "48.31048772712783 % completed\n",
            "48.326426522154925 % completed\n",
            "48.34236531718202 % completed\n",
            "48.35830411220912 % completed\n",
            "48.374242907236216 % completed\n",
            "48.390181702263305 % completed\n",
            "48.4061204972904 % completed\n",
            "48.4220592923175 % completed\n",
            "48.437998087344596 % completed\n",
            "48.45393688237169 % completed\n",
            "48.46987567739879 % completed\n",
            "48.485814472425886 % completed\n",
            "48.50175326745298 % completed\n",
            "48.51769206248008 % completed\n",
            "48.53363085750717 % completed\n",
            "48.54956965253427 % completed\n",
            "48.56550844756136 % completed\n",
            "48.58144724258846 % completed\n",
            "48.59738603761556 % completed\n",
            "48.613324832642654 % completed\n",
            "48.62926362766975 % completed\n",
            "48.64520242269685 % completed\n",
            "48.66114121772394 % completed\n",
            "48.677080012751034 % completed\n",
            "48.69301880777813 % completed\n",
            "48.70895760280523 % completed\n",
            "48.724896397832325 % completed\n",
            "48.74083519285942 % completed\n",
            "48.75677398788652 % completed\n",
            "48.772712782913615 % completed\n",
            "48.788651577940705 % completed\n",
            "48.8045903729678 % completed\n",
            "48.8205291679949 % completed\n",
            "48.836467963021995 % completed\n",
            "48.85240675804909 % completed\n",
            "48.86834555307619 % completed\n",
            "48.884284348103286 % completed\n",
            "48.90022314313038 % completed\n",
            "48.91616193815747 % completed\n",
            "48.93210073318457 % completed\n",
            "48.948039528211666 % completed\n",
            "48.96397832323876 % completed\n",
            "48.97991711826586 % completed\n",
            "48.99585591329296 % completed\n",
            "49.01179470832005 % completed\n",
            "49.02773350334715 % completed\n",
            "49.04367229837424 % completed\n",
            "49.05961109340134 % completed\n",
            "49.075549888428434 % completed\n",
            "49.09148868345553 % completed\n",
            "49.10742747848263 % completed\n",
            "49.123366273509724 % completed\n",
            "49.13930506853682 % completed\n",
            "49.15524386356392 % completed\n",
            "49.17118265859101 % completed\n",
            "49.187121453618104 % completed\n",
            "49.2030602486452 % completed\n",
            "49.2189990436723 % completed\n",
            "49.234937838699395 % completed\n",
            "49.25087663372649 % completed\n",
            "49.26681542875359 % completed\n",
            "49.282754223780685 % completed\n",
            "49.298693018807775 % completed\n",
            "49.31463181383487 % completed\n",
            "49.33057060886197 % completed\n",
            "49.346509403889065 % completed\n",
            "49.36244819891616 % completed\n",
            "49.37838699394326 % completed\n",
            "49.394325788970356 % completed\n",
            "49.41026458399745 % completed\n",
            "49.42620337902454 % completed\n",
            "49.44214217405164 % completed\n",
            "49.458080969078736 % completed\n",
            "49.47401976410583 % completed\n",
            "49.48995855913293 % completed\n",
            "49.50589735416003 % completed\n",
            "49.52183614918712 % completed\n",
            "49.53777494421422 % completed\n",
            "49.55371373924131 % completed\n",
            "49.56965253426841 % completed\n",
            "49.585591329295504 % completed\n",
            "49.6015301243226 % completed\n",
            "49.6174689193497 % completed\n",
            "49.633407714376794 % completed\n",
            "49.64934650940389 % completed\n",
            "49.66528530443099 % completed\n",
            "49.68122409945808 % completed\n",
            "49.697162894485174 % completed\n",
            "49.71310168951227 % completed\n",
            "49.72904048453937 % completed\n",
            "49.744979279566465 % completed\n",
            "49.76091807459356 % completed\n",
            "49.77685686962066 % completed\n",
            "49.792795664647755 % completed\n",
            "49.808734459674845 % completed\n",
            "49.82467325470194 % completed\n",
            "49.84061204972904 % completed\n",
            "49.856550844756136 % completed\n",
            "49.87248963978323 % completed\n",
            "49.88842843481033 % completed\n",
            "49.904367229837426 % completed\n",
            "49.92030602486452 % completed\n",
            "49.93624481989161 % completed\n",
            "49.95218361491871 % completed\n",
            "49.968122409945806 % completed\n",
            "49.9840612049729 % completed\n",
            "50.0 % completed\n",
            "50.0159387950271 % completed\n",
            "50.031877590054194 % completed\n",
            "50.04781638508129 % completed\n",
            "50.06375518010839 % completed\n",
            "50.07969397513548 % completed\n",
            "50.095632770162574 % completed\n",
            "50.11157156518967 % completed\n",
            "50.12751036021677 % completed\n",
            "50.143449155243864 % completed\n",
            "50.15938795027096 % completed\n",
            "50.17532674529806 % completed\n",
            "50.191265540325155 % completed\n",
            "50.207204335352245 % completed\n",
            "50.22314313037934 % completed\n",
            "50.23908192540644 % completed\n",
            "50.255020720433535 % completed\n",
            "50.27095951546063 % completed\n",
            "50.28689831048773 % completed\n",
            "50.302837105514826 % completed\n",
            "50.31877590054192 % completed\n",
            "50.33471469556901 % completed\n",
            "50.35065349059611 % completed\n",
            "50.366592285623206 % completed\n",
            "50.3825310806503 % completed\n",
            "50.3984698756774 % completed\n",
            "50.414408670704496 % completed\n",
            "50.43034746573159 % completed\n",
            "50.44628626075869 % completed\n",
            "50.46222505578578 % completed\n",
            "50.47816385081288 % completed\n",
            "50.49410264583997 % completed\n",
            "50.51004144086707 % completed\n",
            "50.52598023589417 % completed\n",
            "50.541919030921264 % completed\n",
            "50.55785782594836 % completed\n",
            "50.57379662097546 % completed\n",
            "50.58973541600255 % completed\n",
            "50.605674211029644 % completed\n",
            "50.62161300605674 % completed\n",
            "50.63755180108384 % completed\n",
            "50.653490596110935 % completed\n",
            "50.66942939113803 % completed\n",
            "50.68536818616513 % completed\n",
            "50.701306981192225 % completed\n",
            "50.717245776219315 % completed\n",
            "50.73318457124641 % completed\n",
            "50.74912336627351 % completed\n",
            "50.765062161300605 % completed\n",
            "50.7810009563277 % completed\n",
            "50.7969397513548 % completed\n",
            "50.812878546381896 % completed\n",
            "50.82881734140899 % completed\n",
            "50.84475613643608 % completed\n",
            "50.86069493146318 % completed\n",
            "50.876633726490276 % completed\n",
            "50.89257252151737 % completed\n",
            "50.90851131654447 % completed\n",
            "50.924450111571566 % completed\n",
            "50.94038890659866 % completed\n",
            "50.95632770162576 % completed\n",
            "50.97226649665285 % completed\n",
            "50.98820529167995 % completed\n",
            "51.00414408670704 % completed\n",
            "51.02008288173414 % completed\n",
            "51.03602167676124 % completed\n",
            "51.051960471788334 % completed\n",
            "51.06789926681543 % completed\n",
            "51.08383806184253 % completed\n",
            "51.09977685686962 % completed\n",
            "51.115715651896714 % completed\n",
            "51.13165444692381 % completed\n",
            "51.14759324195091 % completed\n",
            "51.163532036978005 % completed\n",
            "51.1794708320051 % completed\n",
            "51.1954096270322 % completed\n",
            "51.211348422059295 % completed\n",
            "51.227287217086385 % completed\n",
            "51.24322601211348 % completed\n",
            "51.25916480714058 % completed\n",
            "51.275103602167675 % completed\n",
            "51.29104239719477 % completed\n",
            "51.30698119222187 % completed\n",
            "51.322919987248966 % completed\n",
            "51.33885878227606 % completed\n",
            "51.35479757730315 % completed\n",
            "51.37073637233025 % completed\n",
            "51.386675167357346 % completed\n",
            "51.40261396238444 % completed\n",
            "51.41855275741154 % completed\n",
            "51.43449155243864 % completed\n",
            "51.45043034746573 % completed\n",
            "51.46636914249283 % completed\n",
            "51.48230793751992 % completed\n",
            "51.49824673254702 % completed\n",
            "51.514185527574114 % completed\n",
            "51.53012432260121 % completed\n",
            "51.54606311762831 % completed\n",
            "51.562001912655404 % completed\n",
            "51.5779407076825 % completed\n",
            "51.5938795027096 % completed\n",
            "51.609818297736695 % completed\n",
            "51.625757092763784 % completed\n",
            "51.64169588779088 % completed\n",
            "51.65763468281798 % completed\n",
            "51.673573477845075 % completed\n",
            "51.68951227287217 % completed\n",
            "51.70545106789927 % completed\n",
            "51.721389862926365 % completed\n",
            "51.73732865795346 % completed\n",
            "51.75326745298055 % completed\n",
            "51.76920624800765 % completed\n",
            "51.785145043034746 % completed\n",
            "51.80108383806184 % completed\n",
            "51.81702263308894 % completed\n",
            "51.832961428116036 % completed\n",
            "51.84890022314313 % completed\n",
            "51.86483901817023 % completed\n",
            "51.88077781319732 % completed\n",
            "51.896716608224416 % completed\n",
            "51.91265540325151 % completed\n",
            "51.92859419827861 % completed\n",
            "51.94453299330571 % completed\n",
            "51.960471788332804 % completed\n",
            "51.9764105833599 % completed\n",
            "51.992349378387 % completed\n",
            "52.00828817341409 % completed\n",
            "52.024226968441184 % completed\n",
            "52.04016576346828 % completed\n",
            "52.05610455849538 % completed\n",
            "52.072043353522474 % completed\n",
            "52.08798214854957 % completed\n",
            "52.10392094357667 % completed\n",
            "52.119859738603765 % completed\n",
            "52.135798533630854 % completed\n",
            "52.15173732865795 % completed\n",
            "52.16767612368505 % completed\n",
            "52.183614918712145 % completed\n",
            "52.19955371373924 % completed\n",
            "52.21549250876634 % completed\n",
            "52.231431303793435 % completed\n",
            "52.24737009882053 % completed\n",
            "52.26330889384762 % completed\n",
            "52.27924768887472 % completed\n",
            "52.295186483901816 % completed\n",
            "52.31112527892891 % completed\n",
            "52.32706407395601 % completed\n",
            "52.343002868983106 % completed\n",
            "52.3589416640102 % completed\n",
            "52.3748804590373 % completed\n",
            "52.39081925406439 % completed\n",
            "52.406758049091486 % completed\n",
            "52.42269684411858 % completed\n",
            "52.43863563914568 % completed\n",
            "52.45457443417278 % completed\n",
            "52.470513229199874 % completed\n",
            "52.48645202422697 % completed\n",
            "52.50239081925407 % completed\n",
            "52.51832961428116 % completed\n",
            "52.534268409308254 % completed\n",
            "52.55020720433535 % completed\n",
            "52.56614599936245 % completed\n",
            "52.582084794389544 % completed\n",
            "52.59802358941664 % completed\n",
            "52.61396238444374 % completed\n",
            "52.629901179470835 % completed\n",
            "52.645839974497925 % completed\n",
            "52.66177876952502 % completed\n",
            "52.67771756455212 % completed\n",
            "52.693656359579215 % completed\n",
            "52.70959515460631 % completed\n",
            "52.72553394963341 % completed\n",
            "52.741472744660506 % completed\n",
            "52.7574115396876 % completed\n",
            "52.77335033471469 % completed\n",
            "52.78928912974179 % completed\n",
            "52.805227924768886 % completed\n",
            "52.82116671979598 % completed\n",
            "52.83710551482308 % completed\n",
            "52.853044309850176 % completed\n",
            "52.86898310487727 % completed\n",
            "52.88492189990437 % completed\n",
            "52.90086069493146 % completed\n",
            "52.91679948995856 % completed\n",
            "52.93273828498565 % completed\n",
            "52.94867708001275 % completed\n",
            "52.96461587503985 % completed\n",
            "52.980554670066944 % completed\n",
            "52.99649346509404 % completed\n",
            "53.01243226012114 % completed\n",
            "53.02837105514823 % completed\n",
            "53.044309850175324 % completed\n",
            "53.06024864520242 % completed\n",
            "53.07618744022952 % completed\n",
            "53.092126235256615 % completed\n",
            "53.10806503028371 % completed\n",
            "53.12400382531081 % completed\n",
            "53.139942620337905 % completed\n",
            "53.155881415365 % completed\n",
            "53.17182021039209 % completed\n",
            "53.18775900541919 % completed\n",
            "53.203697800446285 % completed\n",
            "53.21963659547338 % completed\n",
            "53.23557539050048 % completed\n",
            "53.251514185527576 % completed\n",
            "53.26745298055467 % completed\n",
            "53.28339177558177 % completed\n",
            "53.29933057060886 % completed\n",
            "53.315269365635956 % completed\n",
            "53.33120816066305 % completed\n",
            "53.34714695569015 % completed\n",
            "53.36308575071725 % completed\n",
            "53.37902454574434 % completed\n",
            "53.39496334077144 % completed\n",
            "53.41090213579854 % completed\n",
            "53.42684093082563 % completed\n",
            "53.44277972585272 % completed\n",
            "53.45871852087982 % completed\n",
            "53.47465731590692 % completed\n",
            "53.490596110934014 % completed\n",
            "53.50653490596111 % completed\n",
            "53.52247370098821 % completed\n",
            "53.538412496015304 % completed\n",
            "53.554351291042394 % completed\n",
            "53.57029008606949 % completed\n",
            "53.58622888109659 % completed\n",
            "53.602167676123685 % completed\n",
            "53.61810647115078 % completed\n",
            "53.63404526617788 % completed\n",
            "53.649984061204975 % completed\n",
            "53.66592285623207 % completed\n",
            "53.68186165125916 % completed\n",
            "53.69780044628626 % completed\n",
            "53.713739241313355 % completed\n",
            "53.72967803634045 % completed\n",
            "53.74561683136755 % completed\n",
            "53.761555626394646 % completed\n",
            "53.77749442142174 % completed\n",
            "53.79343321644884 % completed\n",
            "53.80937201147593 % completed\n",
            "53.825310806503026 % completed\n",
            "53.84124960153012 % completed\n",
            "53.85718839655722 % completed\n",
            "53.87312719158432 % completed\n",
            "53.88906598661141 % completed\n",
            "53.90500478163851 % completed\n",
            "53.92094357666561 % completed\n",
            "53.9368823716927 % completed\n",
            "53.952821166719794 % completed\n",
            "53.96875996174689 % completed\n",
            "53.98469875677399 % completed\n",
            "54.000637551801084 % completed\n",
            "54.01657634682818 % completed\n",
            "54.03251514185528 % completed\n",
            "54.048453936882375 % completed\n",
            "54.064392731909464 % completed\n",
            "54.08033152693656 % completed\n",
            "54.09627032196366 % completed\n",
            "54.112209116990755 % completed\n",
            "54.12814791201785 % completed\n",
            "54.14408670704495 % completed\n",
            "54.160025502072045 % completed\n",
            "54.17596429709914 % completed\n",
            "54.19190309212623 % completed\n",
            "54.20784188715333 % completed\n",
            "54.223780682180426 % completed\n",
            "54.23971947720752 % completed\n",
            "54.25565827223462 % completed\n",
            "54.271597067261716 % completed\n",
            "54.28753586228881 % completed\n",
            "54.30347465731591 % completed\n",
            "54.319413452343 % completed\n",
            "54.335352247370096 % completed\n",
            "54.35129104239719 % completed\n",
            "54.36722983742429 % completed\n",
            "54.38316863245139 % completed\n",
            "54.399107427478484 % completed\n",
            "54.41504622250558 % completed\n",
            "54.43098501753268 % completed\n",
            "54.44692381255977 % completed\n",
            "54.462862607586864 % completed\n",
            "54.47880140261396 % completed\n",
            "54.49474019764106 % completed\n",
            "54.510678992668154 % completed\n",
            "54.52661778769525 % completed\n",
            "54.54255658272235 % completed\n",
            "54.558495377749445 % completed\n",
            "54.57443417277654 % completed\n",
            "54.59037296780363 % completed\n",
            "54.60631176283073 % completed\n",
            "54.622250557857825 % completed\n",
            "54.63818935288492 % completed\n",
            "54.65412814791202 % completed\n",
            "54.670066942939116 % completed\n",
            "54.68600573796621 % completed\n",
            "54.70194453299331 % completed\n",
            "54.7178833280204 % completed\n",
            "54.733822123047496 % completed\n",
            "54.74976091807459 % completed\n",
            "54.76569971310169 % completed\n",
            "54.781638508128786 % completed\n",
            "54.79757730315588 % completed\n",
            "54.81351609818298 % completed\n",
            "54.82945489321008 % completed\n",
            "54.845393688237166 % completed\n",
            "54.86133248326426 % completed\n",
            "54.87727127829136 % completed\n",
            "54.89321007331846 % completed\n",
            "54.909148868345554 % completed\n",
            "54.92508766337265 % completed\n",
            "54.94102645839975 % completed\n",
            "54.956965253426844 % completed\n",
            "54.972904048453934 % completed\n",
            "54.98884284348103 % completed\n",
            "55.00478163850813 % completed\n",
            "55.020720433535224 % completed\n",
            "55.03665922856232 % completed\n",
            "55.05259802358942 % completed\n",
            "55.068536818616515 % completed\n",
            "55.08447561364361 % completed\n",
            "55.1004144086707 % completed\n",
            "55.1163532036978 % completed\n",
            "55.132291998724895 % completed\n",
            "55.14823079375199 % completed\n",
            "55.16416958877909 % completed\n",
            "55.180108383806186 % completed\n",
            "55.19604717883328 % completed\n",
            "55.21198597386038 % completed\n",
            "55.22792476888747 % completed\n",
            "55.243863563914566 % completed\n",
            "55.25980235894166 % completed\n",
            "55.27574115396876 % completed\n",
            "55.291679948995856 % completed\n",
            "55.30761874402295 % completed\n",
            "55.32355753905005 % completed\n",
            "55.33949633407715 % completed\n",
            "55.35543512910424 % completed\n",
            "55.37137392413133 % completed\n",
            "55.38731271915843 % completed\n",
            "55.40325151418553 % completed\n",
            "55.419190309212624 % completed\n",
            "55.43512910423972 % completed\n",
            "55.45106789926682 % completed\n",
            "55.467006694293914 % completed\n",
            "55.482945489321004 % completed\n",
            "55.4988842843481 % completed\n",
            "55.5148230793752 % completed\n",
            "55.530761874402295 % completed\n",
            "55.54670066942939 % completed\n",
            "55.56263946445649 % completed\n",
            "55.578578259483585 % completed\n",
            "55.59451705451068 % completed\n",
            "55.61045584953777 % completed\n",
            "55.62639464456487 % completed\n",
            "55.642333439591965 % completed\n",
            "55.65827223461906 % completed\n",
            "55.67421102964616 % completed\n",
            "55.690149824673256 % completed\n",
            "55.70608861970035 % completed\n",
            "55.72202741472745 % completed\n",
            "55.73796620975454 % completed\n",
            "55.753905004781636 % completed\n",
            "55.76984379980873 % completed\n",
            "55.78578259483583 % completed\n",
            "55.80172138986293 % completed\n",
            "55.81766018489002 % completed\n",
            "55.83359897991712 % completed\n",
            "55.84953777494422 % completed\n",
            "55.86547656997131 % completed\n",
            "55.881415364998404 % completed\n",
            "55.8973541600255 % completed\n",
            "55.9132929550526 % completed\n",
            "55.929231750079694 % completed\n",
            "55.94517054510679 % completed\n",
            "55.96110934013389 % completed\n",
            "55.977048135160985 % completed\n",
            "55.992986930188074 % completed\n",
            "56.00892572521517 % completed\n",
            "56.02486452024227 % completed\n",
            "56.040803315269365 % completed\n",
            "56.05674211029646 % completed\n",
            "56.07268090532356 % completed\n",
            "56.088619700350655 % completed\n",
            "56.10455849537775 % completed\n",
            "56.12049729040485 % completed\n",
            "56.13643608543194 % completed\n",
            "56.152374880459035 % completed\n",
            "56.16831367548613 % completed\n",
            "56.18425247051323 % completed\n",
            "56.200191265540326 % completed\n",
            "56.21613006056742 % completed\n",
            "56.23206885559452 % completed\n",
            "56.24800765062162 % completed\n",
            "56.263946445648706 % completed\n",
            "56.2798852406758 % completed\n",
            "56.2958240357029 % completed\n",
            "56.31176283073 % completed\n",
            "56.32770162575709 % completed\n",
            "56.34364042078419 % completed\n",
            "56.35957921581129 % completed\n",
            "56.375518010838384 % completed\n",
            "56.391456805865474 % completed\n",
            "56.40739560089257 % completed\n",
            "56.42333439591967 % completed\n",
            "56.439273190946764 % completed\n",
            "56.45521198597386 % completed\n",
            "56.47115078100096 % completed\n",
            "56.487089576028055 % completed\n",
            "56.50302837105515 % completed\n",
            "56.51896716608224 % completed\n",
            "56.53490596110934 % completed\n",
            "56.550844756136435 % completed\n",
            "56.56678355116353 % completed\n",
            "56.58272234619063 % completed\n",
            "56.598661141217725 % completed\n",
            "56.61459993624482 % completed\n",
            "56.63053873127192 % completed\n",
            "56.64647752629901 % completed\n",
            "56.662416321326106 % completed\n",
            "56.6783551163532 % completed\n",
            "56.6942939113803 % completed\n",
            "56.710232706407396 % completed\n",
            "56.72617150143449 % completed\n",
            "56.74211029646159 % completed\n",
            "56.75804909148869 % completed\n",
            "56.773987886515776 % completed\n",
            "56.78992668154287 % completed\n",
            "56.80586547656997 % completed\n",
            "56.82180427159707 % completed\n",
            "56.837743066624164 % completed\n",
            "56.85368186165126 % completed\n",
            "56.86962065667836 % completed\n",
            "56.885559451705454 % completed\n",
            "56.901498246732544 % completed\n",
            "56.91743704175964 % completed\n",
            "56.93337583678674 % completed\n",
            "56.949314631813834 % completed\n",
            "56.96525342684093 % completed\n",
            "56.98119222186803 % completed\n",
            "56.997131016895125 % completed\n",
            "57.01306981192222 % completed\n",
            "57.02900860694931 % completed\n",
            "57.04494740197641 % completed\n",
            "57.060886197003505 % completed\n",
            "57.0768249920306 % completed\n",
            "57.0927637870577 % completed\n",
            "57.108702582084796 % completed\n",
            "57.12464137711189 % completed\n",
            "57.14058017213899 % completed\n",
            "57.15651896716608 % completed\n",
            "57.172457762193176 % completed\n",
            "57.18839655722027 % completed\n",
            "57.20433535224737 % completed\n",
            "57.220274147274466 % completed\n",
            "57.23621294230156 % completed\n",
            "57.25215173732866 % completed\n",
            "57.26809053235576 % completed\n",
            "57.28402932738285 % completed\n",
            "57.29996812240994 % completed\n",
            "57.31590691743704 % completed\n",
            "57.33184571246414 % completed\n",
            "57.347784507491234 % completed\n",
            "57.36372330251833 % completed\n",
            "57.37966209754543 % completed\n",
            "57.395600892572524 % completed\n",
            "57.411539687599614 % completed\n",
            "57.42747848262671 % completed\n",
            "57.44341727765381 % completed\n",
            "57.459356072680905 % completed\n",
            "57.475294867708 % completed\n",
            "57.4912336627351 % completed\n",
            "57.507172457762195 % completed\n",
            "57.52311125278929 % completed\n",
            "57.53905004781638 % completed\n",
            "57.55498884284348 % completed\n",
            "57.570927637870575 % completed\n",
            "57.58686643289767 % completed\n",
            "57.60280522792477 % completed\n",
            "57.618744022951866 % completed\n",
            "57.63468281797896 % completed\n",
            "57.65062161300606 % completed\n",
            "57.666560408033156 % completed\n",
            "57.682499203060246 % completed\n",
            "57.69843799808734 % completed\n",
            "57.71437679311444 % completed\n",
            "57.730315588141536 % completed\n",
            "57.74625438316863 % completed\n",
            "57.76219317819573 % completed\n",
            "57.77813197322283 % completed\n",
            "57.794070768249924 % completed\n",
            "57.81000956327701 % completed\n",
            "57.82594835830411 % completed\n",
            "57.84188715333121 % completed\n",
            "57.857825948358304 % completed\n",
            "57.8737647433854 % completed\n",
            "57.8897035384125 % completed\n",
            "57.905642333439594 % completed\n",
            "57.92158112846669 % completed\n",
            "57.93751992349378 % completed\n",
            "57.95345871852088 % completed\n",
            "57.969397513547975 % completed\n",
            "57.98533630857507 % completed\n",
            "58.00127510360217 % completed\n",
            "58.017213898629265 % completed\n",
            "58.03315269365636 % completed\n",
            "58.04909148868346 % completed\n",
            "58.06503028371055 % completed\n",
            "58.080969078737645 % completed\n",
            "58.09690787376474 % completed\n",
            "58.11284666879184 % completed\n",
            "58.128785463818936 % completed\n",
            "58.14472425884603 % completed\n",
            "58.16066305387313 % completed\n",
            "58.176601848900226 % completed\n",
            "58.192540643927316 % completed\n",
            "58.20847943895441 % completed\n",
            "58.22441823398151 % completed\n",
            "58.24035702900861 % completed\n",
            "58.2562958240357 % completed\n",
            "58.2722346190628 % completed\n",
            "58.2881734140899 % completed\n",
            "58.304112209116994 % completed\n",
            "58.320051004144084 % completed\n",
            "58.33598979917118 % completed\n",
            "58.35192859419828 % completed\n",
            "58.367867389225374 % completed\n",
            "58.38380618425247 % completed\n",
            "58.39974497927957 % completed\n",
            "58.415683774306665 % completed\n",
            "58.43162256933376 % completed\n",
            "58.44756136436085 % completed\n",
            "58.46350015938795 % completed\n",
            "58.479438954415045 % completed\n",
            "58.49537774944214 % completed\n",
            "58.51131654446924 % completed\n",
            "58.527255339496335 % completed\n",
            "58.54319413452343 % completed\n",
            "58.55913292955053 % completed\n",
            "58.57507172457762 % completed\n",
            "58.591010519604716 % completed\n",
            "58.60694931463181 % completed\n",
            "58.62288810965891 % completed\n",
            "58.638826904686006 % completed\n",
            "58.6547656997131 % completed\n",
            "58.6707044947402 % completed\n",
            "58.6866432897673 % completed\n",
            "58.702582084794386 % completed\n",
            "58.71852087982148 % completed\n",
            "58.73445967484858 % completed\n",
            "58.75039846987568 % completed\n",
            "58.76633726490277 % completed\n",
            "58.78227605992987 % completed\n",
            "58.79821485495697 % completed\n",
            "58.814153649984064 % completed\n",
            "58.830092445011154 % completed\n",
            "58.84603124003825 % completed\n",
            "58.86197003506535 % completed\n",
            "58.877908830092444 % completed\n",
            "58.89384762511954 % completed\n",
            "58.90978642014664 % completed\n",
            "58.925725215173735 % completed\n",
            "58.94166401020083 % completed\n",
            "58.95760280522792 % completed\n",
            "58.97354160025502 % completed\n",
            "58.989480395282115 % completed\n",
            "59.00541919030921 % completed\n",
            "59.02135798533631 % completed\n",
            "59.037296780363405 % completed\n",
            "59.0532355753905 % completed\n",
            "59.0691743704176 % completed\n",
            "59.08511316544469 % completed\n",
            "59.101051960471786 % completed\n",
            "59.11699075549888 % completed\n",
            "59.13292955052598 % completed\n",
            "59.148868345553076 % completed\n",
            "59.16480714058017 % completed\n",
            "59.18074593560727 % completed\n",
            "59.19668473063437 % completed\n",
            "59.21262352566146 % completed\n",
            "59.22856232068855 % completed\n",
            "59.24450111571565 % completed\n",
            "59.26043991074275 % completed\n",
            "59.276378705769844 % completed\n",
            "59.29231750079694 % completed\n",
            "59.30825629582404 % completed\n",
            "59.324195090851134 % completed\n",
            "59.34013388587823 % completed\n",
            "59.35607268090532 % completed\n",
            "59.37201147593242 % completed\n",
            "59.387950270959514 % completed\n",
            "59.40388906598661 % completed\n",
            "59.41982786101371 % completed\n",
            "59.435766656040805 % completed\n",
            "59.4517054510679 % completed\n",
            "59.467644246095 % completed\n",
            "59.48358304112209 % completed\n",
            "59.499521836149185 % completed\n",
            "59.51546063117628 % completed\n",
            "59.53139942620338 % completed\n",
            "59.547338221230476 % completed\n",
            "59.56327701625757 % completed\n",
            "59.57921581128467 % completed\n",
            "59.595154606311766 % completed\n",
            "59.611093401338856 % completed\n",
            "59.62703219636595 % completed\n",
            "59.64297099139305 % completed\n",
            "59.658909786420146 % completed\n",
            "59.67484858144724 % completed\n",
            "59.69078737647434 % completed\n",
            "59.70672617150144 % completed\n",
            "59.722664966528534 % completed\n",
            "59.73860376155562 % completed\n",
            "59.75454255658272 % completed\n",
            "59.77048135160982 % completed\n",
            "59.786420146636914 % completed\n",
            "59.80235894166401 % completed\n",
            "59.81829773669111 % completed\n",
            "59.834236531718204 % completed\n",
            "59.8501753267453 % completed\n",
            "59.86611412177239 % completed\n",
            "59.88205291679949 % completed\n",
            "59.897991711826585 % completed\n",
            "59.91393050685368 % completed\n",
            "59.92986930188078 % completed\n",
            "59.945808096907875 % completed\n",
            "59.96174689193497 % completed\n",
            "59.97768568696207 % completed\n",
            "59.99362448198916 % completed\n",
            "60.009563277016255 % completed\n",
            "60.02550207204335 % completed\n",
            "60.04144086707045 % completed\n",
            "60.057379662097546 % completed\n",
            "60.07331845712464 % completed\n",
            "60.08925725215174 % completed\n",
            "60.105196047178836 % completed\n",
            "60.121134842205926 % completed\n",
            "60.13707363723302 % completed\n",
            "60.15301243226012 % completed\n",
            "60.16895122728722 % completed\n",
            "60.18489002231431 % completed\n",
            "60.20082881734141 % completed\n",
            "60.21676761236851 % completed\n",
            "60.232706407395604 % completed\n",
            "60.24864520242269 % completed\n",
            "60.26458399744979 % completed\n",
            "60.28052279247689 % completed\n",
            "60.296461587503984 % completed\n",
            "60.31240038253108 % completed\n",
            "60.32833917755818 % completed\n",
            "60.344277972585274 % completed\n",
            "60.36021676761237 % completed\n",
            "60.37615556263946 % completed\n",
            "60.39209435766656 % completed\n",
            "60.408033152693655 % completed\n",
            "60.42397194772075 % completed\n",
            "60.43991074274785 % completed\n",
            "60.455849537774945 % completed\n",
            "60.47178833280204 % completed\n",
            "60.48772712782914 % completed\n",
            "60.50366592285623 % completed\n",
            "60.519604717883325 % completed\n",
            "60.53554351291042 % completed\n",
            "60.55148230793752 % completed\n",
            "60.567421102964616 % completed\n",
            "60.58335989799171 % completed\n",
            "60.59929869301881 % completed\n",
            "60.615237488045906 % completed\n",
            "60.631176283073 % completed\n",
            "60.64711507810009 % completed\n",
            "60.66305387312719 % completed\n",
            "60.67899266815429 % completed\n",
            "60.69493146318138 % completed\n",
            "60.71087025820848 % completed\n",
            "60.72680905323558 % completed\n",
            "60.742747848262674 % completed\n",
            "60.75868664328977 % completed\n",
            "60.77462543831686 % completed\n",
            "60.79056423334396 % completed\n",
            "60.806503028371054 % completed\n",
            "60.82244182339815 % completed\n",
            "60.83838061842525 % completed\n",
            "60.854319413452345 % completed\n",
            "60.87025820847944 % completed\n",
            "60.88619700350654 % completed\n",
            "60.90213579853363 % completed\n",
            "60.918074593560725 % completed\n",
            "60.93401338858782 % completed\n",
            "60.94995218361492 % completed\n",
            "60.965890978642015 % completed\n",
            "60.98182977366911 % completed\n",
            "60.99776856869621 % completed\n",
            "61.013707363723306 % completed\n",
            "61.029646158750396 % completed\n",
            "61.04558495377749 % completed\n",
            "61.06152374880459 % completed\n",
            "61.077462543831686 % completed\n",
            "61.09340133885878 % completed\n",
            "61.10934013388588 % completed\n",
            "61.12527892891298 % completed\n",
            "61.14121772394007 % completed\n",
            "61.15715651896716 % completed\n",
            "61.17309531399426 % completed\n",
            "61.18903410902136 % completed\n",
            "61.204972904048454 % completed\n",
            "61.22091169907555 % completed\n",
            "61.23685049410265 % completed\n",
            "61.252789289129744 % completed\n",
            "61.26872808415684 % completed\n",
            "61.28466687918393 % completed\n",
            "61.30060567421103 % completed\n",
            "61.316544469238124 % completed\n",
            "61.33248326426522 % completed\n",
            "61.34842205929232 % completed\n",
            "61.364360854319415 % completed\n",
            "61.38029964934651 % completed\n",
            "61.39623844437361 % completed\n",
            "61.4121772394007 % completed\n",
            "61.428116034427795 % completed\n",
            "61.44405482945489 % completed\n",
            "61.45999362448199 % completed\n",
            "61.475932419509085 % completed\n",
            "61.49187121453618 % completed\n",
            "61.50781000956328 % completed\n",
            "61.523748804590376 % completed\n",
            "61.539687599617466 % completed\n",
            "61.55562639464456 % completed\n",
            "61.57156518967166 % completed\n",
            "61.587503984698756 % completed\n",
            "61.60344277972585 % completed\n",
            "61.61938157475295 % completed\n",
            "61.63532036978005 % completed\n",
            "61.65125916480714 % completed\n",
            "61.66719795983423 % completed\n",
            "61.68313675486133 % completed\n",
            "61.69907554988843 % completed\n",
            "61.715014344915524 % completed\n",
            "61.73095313994262 % completed\n",
            "61.74689193496972 % completed\n",
            "61.762830729996814 % completed\n",
            "61.77876952502391 % completed\n",
            "61.794708320051 % completed\n",
            "61.8106471150781 % completed\n",
            "61.826585910105194 % completed\n",
            "61.84252470513229 % completed\n",
            "61.85846350015939 % completed\n",
            "61.874402295186485 % completed\n",
            "61.89034109021358 % completed\n",
            "61.90627988524068 % completed\n",
            "61.92221868026777 % completed\n",
            "61.938157475294865 % completed\n",
            "61.95409627032196 % completed\n",
            "61.97003506534906 % completed\n",
            "61.985973860376156 % completed\n",
            "62.00191265540325 % completed\n",
            "62.01785145043035 % completed\n",
            "62.033790245457446 % completed\n",
            "62.049729040484536 % completed\n",
            "62.06566783551163 % completed\n",
            "62.08160663053873 % completed\n",
            "62.097545425565826 % completed\n",
            "62.11348422059292 % completed\n",
            "62.12942301562002 % completed\n",
            "62.14536181064712 % completed\n",
            "62.161300605674214 % completed\n",
            "62.17723940070131 % completed\n",
            "62.1931781957284 % completed\n",
            "62.2091169907555 % completed\n",
            "62.225055785782594 % completed\n",
            "62.24099458080969 % completed\n",
            "62.25693337583679 % completed\n",
            "62.272872170863884 % completed\n",
            "62.28881096589098 % completed\n",
            "62.30474976091808 % completed\n",
            "62.32068855594517 % completed\n",
            "62.336627350972265 % completed\n",
            "62.35256614599936 % completed\n",
            "62.36850494102646 % completed\n",
            "62.384443736053555 % completed\n",
            "62.40038253108065 % completed\n",
            "62.41632132610775 % completed\n",
            "62.432260121134846 % completed\n",
            "62.448198916161935 % completed\n",
            "62.46413771118903 % completed\n",
            "62.48007650621613 % completed\n",
            "62.496015301243226 % completed\n",
            "62.51195409627032 % completed\n",
            "62.52789289129742 % completed\n",
            "62.543831686324516 % completed\n",
            "62.55977048135161 % completed\n",
            "62.5757092763787 % completed\n",
            "62.5916480714058 % completed\n",
            "62.6075868664329 % completed\n",
            "62.62352566145999 % completed\n",
            "62.63946445648709 % completed\n",
            "62.65540325151419 % completed\n",
            "62.671342046541284 % completed\n",
            "62.68728084156838 % completed\n",
            "62.70321963659547 % completed\n",
            "62.71915843162257 % completed\n",
            "62.735097226649664 % completed\n",
            "62.75103602167676 % completed\n",
            "62.76697481670386 % completed\n",
            "62.782913611730955 % completed\n",
            "62.79885240675805 % completed\n",
            "62.81479120178515 % completed\n",
            "62.83072999681224 % completed\n",
            "62.846668791839335 % completed\n",
            "62.86260758686643 % completed\n",
            "62.87854638189353 % completed\n",
            "62.894485176920625 % completed\n",
            "62.91042397194772 % completed\n",
            "62.92636276697482 % completed\n",
            "62.942301562001916 % completed\n",
            "62.958240357029005 % completed\n",
            "62.9741791520561 % completed\n",
            "62.9901179470832 % completed\n",
            "63.006056742110296 % completed\n",
            "63.02199553713739 % completed\n",
            "63.03793433216449 % completed\n",
            "63.053873127191586 % completed\n",
            "63.06981192221868 % completed\n",
            "63.08575071724577 % completed\n",
            "63.10168951227287 % completed\n",
            "63.11762830729997 % completed\n",
            "63.13356710232706 % completed\n",
            "63.14950589735416 % completed\n",
            "63.16544469238126 % completed\n",
            "63.181383487408354 % completed\n",
            "63.19732228243545 % completed\n",
            "63.21326107746254 % completed\n",
            "63.22919987248964 % completed\n",
            "63.245138667516734 % completed\n",
            "63.26107746254383 % completed\n",
            "63.27701625757093 % completed\n",
            "63.292955052598025 % completed\n",
            "63.30889384762512 % completed\n",
            "63.32483264265222 % completed\n",
            "63.34077143767931 % completed\n",
            "63.356710232706405 % completed\n",
            "63.3726490277335 % completed\n",
            "63.3885878227606 % completed\n",
            "63.404526617787695 % completed\n",
            "63.42046541281479 % completed\n",
            "63.43640420784189 % completed\n",
            "63.452343002868986 % completed\n",
            "63.468281797896076 % completed\n",
            "63.48422059292317 % completed\n",
            "63.50015938795027 % completed\n",
            "63.516098182977366 % completed\n",
            "63.53203697800446 % completed\n",
            "63.54797577303156 % completed\n",
            "63.56391456805866 % completed\n",
            "63.57985336308575 % completed\n",
            "63.59579215811284 % completed\n",
            "63.61173095313994 % completed\n",
            "63.62766974816704 % completed\n",
            "63.643608543194134 % completed\n",
            "63.65954733822123 % completed\n",
            "63.67548613324833 % completed\n",
            "63.691424928275424 % completed\n",
            "63.70736372330252 % completed\n",
            "63.72330251832962 % completed\n",
            "63.73924131335671 % completed\n",
            "63.755180108383804 % completed\n",
            "63.7711189034109 % completed\n",
            "63.787057698438 % completed\n",
            "63.802996493465095 % completed\n",
            "63.81893528849219 % completed\n",
            "63.83487408351929 % completed\n",
            "63.850812878546385 % completed\n",
            "63.866751673573475 % completed\n",
            "63.88269046860057 % completed\n",
            "63.89862926362767 % completed\n",
            "63.914568058654766 % completed\n",
            "63.93050685368186 % completed\n",
            "63.94644564870896 % completed\n",
            "63.962384443736056 % completed\n",
            "63.97832323876315 % completed\n",
            "63.99426203379024 % completed\n",
            "64.01020082881735 % completed\n",
            "64.02613962384444 % completed\n",
            "64.04207841887154 % completed\n",
            "64.05801721389862 % completed\n",
            "64.07395600892572 % completed\n",
            "64.08989480395282 % completed\n",
            "64.10583359897991 % completed\n",
            "64.12177239400701 % completed\n",
            "64.1377111890341 % completed\n",
            "64.1536499840612 % completed\n",
            "64.1695887790883 % completed\n",
            "64.1855275741154 % completed\n",
            "64.2014663691425 % completed\n",
            "64.21740516416959 % completed\n",
            "64.23334395919669 % completed\n",
            "64.24928275422378 % completed\n",
            "64.26522154925088 % completed\n",
            "64.28116034427798 % completed\n",
            "64.29709913930508 % completed\n",
            "64.31303793433216 % completed\n",
            "64.32897672935925 % completed\n",
            "64.34491552438635 % completed\n",
            "64.36085431941345 % completed\n",
            "64.37679311444055 % completed\n",
            "64.39273190946764 % completed\n",
            "64.40867070449474 % completed\n",
            "64.42460949952184 % completed\n",
            "64.44054829454893 % completed\n",
            "64.45648708957603 % completed\n",
            "64.47242588460313 % completed\n",
            "64.48836467963022 % completed\n",
            "64.50430347465732 % completed\n",
            "64.52024226968442 % completed\n",
            "64.53618106471151 % completed\n",
            "64.55211985973861 % completed\n",
            "64.5680586547657 % completed\n",
            "64.58399744979279 % completed\n",
            "64.59993624481989 % completed\n",
            "64.61587503984698 % completed\n",
            "64.63181383487408 % completed\n",
            "64.64775262990118 % completed\n",
            "64.66369142492827 % completed\n",
            "64.67963021995537 % completed\n",
            "64.69556901498247 % completed\n",
            "64.71150781000956 % completed\n",
            "64.72744660503666 % completed\n",
            "64.74338540006376 % completed\n",
            "64.75932419509085 % completed\n",
            "64.77526299011795 % completed\n",
            "64.79120178514505 % completed\n",
            "64.80714058017215 % completed\n",
            "64.82307937519923 % completed\n",
            "64.83901817022632 % completed\n",
            "64.85495696525342 % completed\n",
            "64.87089576028052 % completed\n",
            "64.88683455530762 % completed\n",
            "64.90277335033471 % completed\n",
            "64.91871214536181 % completed\n",
            "64.9346509403889 % completed\n",
            "64.950589735416 % completed\n",
            "64.9665285304431 % completed\n",
            "64.9824673254702 % completed\n",
            "64.9984061204973 % completed\n",
            "65.01434491552439 % completed\n",
            "65.03028371055149 % completed\n",
            "65.04622250557858 % completed\n",
            "65.06216130060568 % completed\n",
            "65.07810009563276 % completed\n",
            "65.09403889065986 % completed\n",
            "65.10997768568696 % completed\n",
            "65.12591648071405 % completed\n",
            "65.14185527574115 % completed\n",
            "65.15779407076825 % completed\n",
            "65.17373286579534 % completed\n",
            "65.18967166082244 % completed\n",
            "65.20561045584954 % completed\n",
            "65.22154925087663 % completed\n",
            "65.23748804590373 % completed\n",
            "65.25342684093083 % completed\n",
            "65.26936563595793 % completed\n",
            "65.28530443098502 % completed\n",
            "65.30124322601212 % completed\n",
            "65.31718202103922 % completed\n",
            "65.33312081606631 % completed\n",
            "65.3490596110934 % completed\n",
            "65.36499840612049 % completed\n",
            "65.38093720114759 % completed\n",
            "65.39687599617469 % completed\n",
            "65.41281479120178 % completed\n",
            "65.42875358622888 % completed\n",
            "65.44469238125598 % completed\n",
            "65.46063117628307 % completed\n",
            "65.47656997131017 % completed\n",
            "65.49250876633727 % completed\n",
            "65.50844756136436 % completed\n",
            "65.52438635639146 % completed\n",
            "65.54032515141856 % completed\n",
            "65.55626394644565 % completed\n",
            "65.57220274147275 % completed\n",
            "65.58814153649985 % completed\n",
            "65.60408033152693 % completed\n",
            "65.62001912655403 % completed\n",
            "65.63595792158112 % completed\n",
            "65.65189671660822 % completed\n",
            "65.66783551163532 % completed\n",
            "65.68377430666241 % completed\n",
            "65.69971310168951 % completed\n",
            "65.71565189671661 % completed\n",
            "65.7315906917437 % completed\n",
            "65.7475294867708 % completed\n",
            "65.7634682817979 % completed\n",
            "65.779407076825 % completed\n",
            "65.79534587185209 % completed\n",
            "65.81128466687919 % completed\n",
            "65.82722346190629 % completed\n",
            "65.84316225693338 % completed\n",
            "65.85910105196047 % completed\n",
            "65.87503984698756 % completed\n",
            "65.89097864201466 % completed\n",
            "65.90691743704176 % completed\n",
            "65.92285623206885 % completed\n",
            "65.93879502709595 % completed\n",
            "65.95473382212305 % completed\n",
            "65.97067261715014 % completed\n",
            "65.98661141217724 % completed\n",
            "66.00255020720434 % completed\n",
            "66.01848900223143 % completed\n",
            "66.03442779725853 % completed\n",
            "66.05036659228563 % completed\n",
            "66.06630538731272 % completed\n",
            "66.08224418233982 % completed\n",
            "66.09818297736692 % completed\n",
            "66.114121772394 % completed\n",
            "66.1300605674211 % completed\n",
            "66.1459993624482 % completed\n",
            "66.16193815747529 % completed\n",
            "66.17787695250239 % completed\n",
            "66.19381574752948 % completed\n",
            "66.20975454255658 % completed\n",
            "66.22569333758368 % completed\n",
            "66.24163213261077 % completed\n",
            "66.25757092763787 % completed\n",
            "66.27350972266497 % completed\n",
            "66.28944851769207 % completed\n",
            "66.30538731271916 % completed\n",
            "66.32132610774626 % completed\n",
            "66.33726490277336 % completed\n",
            "66.35320369780045 % completed\n",
            "66.36914249282754 % completed\n",
            "66.38508128785463 % completed\n",
            "66.40102008288173 % completed\n",
            "66.41695887790883 % completed\n",
            "66.43289767293592 % completed\n",
            "66.44883646796302 % completed\n",
            "66.46477526299012 % completed\n",
            "66.48071405801721 % completed\n",
            "66.49665285304431 % completed\n",
            "66.5125916480714 % completed\n",
            "66.5285304430985 % completed\n",
            "66.5444692381256 % completed\n",
            "66.5604080331527 % completed\n",
            "66.5763468281798 % completed\n",
            "66.59228562320689 % completed\n",
            "66.60822441823399 % completed\n",
            "66.62416321326107 % completed\n",
            "66.64010200828817 % completed\n",
            "66.65604080331526 % completed\n",
            "66.67197959834236 % completed\n",
            "66.68791839336946 % completed\n",
            "66.70385718839655 % completed\n",
            "66.71979598342365 % completed\n",
            "66.73573477845075 % completed\n",
            "66.75167357347785 % completed\n",
            "66.76761236850494 % completed\n",
            "66.78355116353204 % completed\n",
            "66.79948995855914 % completed\n",
            "66.81542875358623 % completed\n",
            "66.83136754861333 % completed\n",
            "66.84730634364043 % completed\n",
            "66.86324513866752 % completed\n",
            "66.87918393369462 % completed\n",
            "66.8951227287217 % completed\n",
            "66.9110615237488 % completed\n",
            "66.9270003187759 % completed\n",
            "66.94293911380299 % completed\n",
            "66.95887790883009 % completed\n",
            "66.97481670385719 % completed\n",
            "66.99075549888428 % completed\n",
            "67.00669429391138 % completed\n",
            "67.02263308893848 % completed\n",
            "67.03857188396557 % completed\n",
            "67.05451067899267 % completed\n",
            "67.07044947401977 % completed\n",
            "67.08638826904686 % completed\n",
            "67.10232706407396 % completed\n",
            "67.11826585910106 % completed\n",
            "67.13420465412815 % completed\n",
            "67.15014344915524 % completed\n",
            "67.16608224418233 % completed\n",
            "67.18202103920943 % completed\n",
            "67.19795983423653 % completed\n",
            "67.21389862926362 % completed\n",
            "67.22983742429072 % completed\n",
            "67.24577621931782 % completed\n",
            "67.26171501434492 % completed\n",
            "67.27765380937201 % completed\n",
            "67.29359260439911 % completed\n",
            "67.3095313994262 % completed\n",
            "67.3254701944533 % completed\n",
            "67.3414089894804 % completed\n",
            "67.3573477845075 % completed\n",
            "67.3732865795346 % completed\n",
            "67.38922537456169 % completed\n",
            "67.40516416958877 % completed\n",
            "67.42110296461587 % completed\n",
            "67.43704175964297 % completed\n",
            "67.45298055467006 % completed\n",
            "67.46891934969716 % completed\n",
            "67.48485814472426 % completed\n",
            "67.50079693975135 % completed\n",
            "67.51673573477845 % completed\n",
            "67.53267452980555 % completed\n",
            "67.54861332483264 % completed\n",
            "67.56455211985974 % completed\n",
            "67.58049091488684 % completed\n",
            "67.59642970991393 % completed\n",
            "67.61236850494103 % completed\n",
            "67.62830729996813 % completed\n",
            "67.64424609499522 % completed\n",
            "67.66018489002231 % completed\n",
            "67.6761236850494 % completed\n",
            "67.6920624800765 % completed\n",
            "67.7080012751036 % completed\n",
            "67.7239400701307 % completed\n",
            "67.73987886515779 % completed\n",
            "67.75581766018489 % completed\n",
            "67.77175645521199 % completed\n",
            "67.78769525023908 % completed\n",
            "67.80363404526618 % completed\n",
            "67.81957284029328 % completed\n",
            "67.83551163532037 % completed\n",
            "67.85145043034747 % completed\n",
            "67.86738922537457 % completed\n",
            "67.88332802040166 % completed\n",
            "67.89926681542876 % completed\n",
            "67.91520561045584 % completed\n",
            "67.93114440548294 % completed\n",
            "67.94708320051004 % completed\n",
            "67.96302199553713 % completed\n",
            "67.97896079056423 % completed\n",
            "67.99489958559133 % completed\n",
            "68.01083838061842 % completed\n",
            "68.02677717564552 % completed\n",
            "68.04271597067262 % completed\n",
            "68.05865476569971 % completed\n",
            "68.07459356072681 % completed\n",
            "68.09053235575391 % completed\n",
            "68.106471150781 % completed\n",
            "68.1224099458081 % completed\n",
            "68.1383487408352 % completed\n",
            "68.1542875358623 % completed\n",
            "68.17022633088938 % completed\n",
            "68.18616512591647 % completed\n",
            "68.20210392094357 % completed\n",
            "68.21804271597067 % completed\n",
            "68.23398151099776 % completed\n",
            "68.24992030602486 % completed\n",
            "68.26585910105196 % completed\n",
            "68.28179789607906 % completed\n",
            "68.29773669110615 % completed\n",
            "68.31367548613325 % completed\n",
            "68.32961428116035 % completed\n",
            "68.34555307618744 % completed\n",
            "68.36149187121454 % completed\n",
            "68.37743066624164 % completed\n",
            "68.39336946126873 % completed\n",
            "68.40930825629583 % completed\n",
            "68.42524705132293 % completed\n",
            "68.44118584635001 % completed\n",
            "68.4571246413771 % completed\n",
            "68.4730634364042 % completed\n",
            "68.4890022314313 % completed\n",
            "68.5049410264584 % completed\n",
            "68.5208798214855 % completed\n",
            "68.53681861651259 % completed\n",
            "68.55275741153969 % completed\n",
            "68.56869620656678 % completed\n",
            "68.58463500159388 % completed\n",
            "68.60057379662098 % completed\n",
            "68.61651259164807 % completed\n",
            "68.63245138667517 % completed\n",
            "68.64839018170227 % completed\n",
            "68.66432897672937 % completed\n",
            "68.68026777175646 % completed\n",
            "68.69620656678354 % completed\n",
            "68.71214536181064 % completed\n",
            "68.72808415683774 % completed\n",
            "68.74402295186484 % completed\n",
            "68.75996174689193 % completed\n",
            "68.77590054191903 % completed\n",
            "68.79183933694613 % completed\n",
            "68.80777813197322 % completed\n",
            "68.82371692700032 % completed\n",
            "68.83965572202742 % completed\n",
            "68.85559451705451 % completed\n",
            "68.87153331208161 % completed\n",
            "68.8874721071087 % completed\n",
            "68.9034109021358 % completed\n",
            "68.9193496971629 % completed\n",
            "68.93528849219 % completed\n",
            "68.95122728721708 % completed\n",
            "68.96716608224418 % completed\n",
            "68.98310487727127 % completed\n",
            "68.99904367229837 % completed\n",
            "69.01498246732547 % completed\n",
            "69.03092126235256 % completed\n",
            "69.04686005737966 % completed\n",
            "69.06279885240676 % completed\n",
            "69.07873764743385 % completed\n",
            "69.09467644246095 % completed\n",
            "69.11061523748805 % completed\n",
            "69.12655403251514 % completed\n",
            "69.14249282754224 % completed\n",
            "69.15843162256934 % completed\n",
            "69.17437041759644 % completed\n",
            "69.19030921262353 % completed\n",
            "69.20624800765061 % completed\n",
            "69.22218680267771 % completed\n",
            "69.23812559770481 % completed\n",
            "69.2540643927319 % completed\n",
            "69.270003187759 % completed\n",
            "69.2859419827861 % completed\n",
            "69.3018807778132 % completed\n",
            "69.31781957284029 % completed\n",
            "69.33375836786739 % completed\n",
            "69.34969716289449 % completed\n",
            "69.36563595792158 % completed\n",
            "69.38157475294868 % completed\n",
            "69.39751354797578 % completed\n",
            "69.41345234300287 % completed\n",
            "69.42939113802997 % completed\n",
            "69.44532993305707 % completed\n",
            "69.46126872808415 % completed\n",
            "69.47720752311125 % completed\n",
            "69.49314631813834 % completed\n",
            "69.50908511316544 % completed\n",
            "69.52502390819254 % completed\n",
            "69.54096270321963 % completed\n",
            "69.55690149824673 % completed\n",
            "69.57284029327383 % completed\n",
            "69.58877908830092 % completed\n",
            "69.60471788332802 % completed\n",
            "69.62065667835512 % completed\n",
            "69.63659547338222 % completed\n",
            "69.65253426840931 % completed\n",
            "69.66847306343641 % completed\n",
            "69.6844118584635 % completed\n",
            "69.7003506534906 % completed\n",
            "69.7162894485177 % completed\n",
            "69.73222824354478 % completed\n",
            "69.74816703857188 % completed\n",
            "69.76410583359898 % completed\n",
            "69.78004462862607 % completed\n",
            "69.79598342365317 % completed\n",
            "69.81192221868027 % completed\n",
            "69.82786101370736 % completed\n",
            "69.84379980873446 % completed\n",
            "69.85973860376156 % completed\n",
            "69.87567739878865 % completed\n",
            "69.89161619381575 % completed\n",
            "69.90755498884285 % completed\n",
            "69.92349378386994 % completed\n",
            "69.93943257889704 % completed\n",
            "69.95537137392414 % completed\n",
            "69.97131016895123 % completed\n",
            "69.98724896397832 % completed\n",
            "70.00318775900541 % completed\n",
            "70.01912655403251 % completed\n",
            "70.03506534905961 % completed\n",
            "70.0510041440867 % completed\n",
            "70.0669429391138 % completed\n",
            "70.0828817341409 % completed\n",
            "70.098820529168 % completed\n",
            "70.11475932419509 % completed\n",
            "70.13069811922219 % completed\n",
            "70.14663691424929 % completed\n",
            "70.16257570927638 % completed\n",
            "70.17851450430348 % completed\n",
            "70.19445329933058 % completed\n",
            "70.21039209435767 % completed\n",
            "70.22633088938477 % completed\n",
            "70.24226968441185 % completed\n",
            "70.25820847943895 % completed\n",
            "70.27414727446605 % completed\n",
            "70.29008606949314 % completed\n",
            "70.30602486452024 % completed\n",
            "70.32196365954734 % completed\n",
            "70.33790245457443 % completed\n",
            "70.35384124960153 % completed\n",
            "70.36978004462863 % completed\n",
            "70.38571883965572 % completed\n",
            "70.40165763468282 % completed\n",
            "70.41759642970992 % completed\n",
            "70.43353522473701 % completed\n",
            "70.44947401976411 % completed\n",
            "70.46541281479121 % completed\n",
            "70.4813516098183 % completed\n",
            "70.49729040484539 % completed\n",
            "70.51322919987248 % completed\n",
            "70.52916799489958 % completed\n",
            "70.54510678992668 % completed\n",
            "70.56104558495377 % completed\n",
            "70.57698437998087 % completed\n",
            "70.59292317500797 % completed\n",
            "70.60886197003506 % completed\n",
            "70.62480076506216 % completed\n",
            "70.64073956008926 % completed\n",
            "70.65667835511636 % completed\n",
            "70.67261715014345 % completed\n",
            "70.68855594517055 % completed\n",
            "70.70449474019765 % completed\n",
            "70.72043353522474 % completed\n",
            "70.73637233025184 % completed\n",
            "70.75231112527892 % completed\n",
            "70.76824992030602 % completed\n",
            "70.78418871533312 % completed\n",
            "70.80012751036021 % completed\n",
            "70.81606630538731 % completed\n",
            "70.8320051004144 % completed\n",
            "70.8479438954415 % completed\n",
            "70.8638826904686 % completed\n",
            "70.8798214854957 % completed\n",
            "70.8957602805228 % completed\n",
            "70.91169907554989 % completed\n",
            "70.92763787057699 % completed\n",
            "70.94357666560408 % completed\n",
            "70.95951546063118 % completed\n",
            "70.97545425565828 % completed\n",
            "70.99139305068537 % completed\n",
            "71.00733184571246 % completed\n",
            "71.02327064073955 % completed\n",
            "71.03920943576665 % completed\n",
            "71.05514823079375 % completed\n",
            "71.07108702582084 % completed\n",
            "71.08702582084794 % completed\n",
            "71.10296461587504 % completed\n",
            "71.11890341090213 % completed\n",
            "71.13484220592923 % completed\n",
            "71.15078100095633 % completed\n",
            "71.16671979598343 % completed\n",
            "71.18265859101052 % completed\n",
            "71.19859738603762 % completed\n",
            "71.21453618106472 % completed\n",
            "71.23047497609181 % completed\n",
            "71.24641377111891 % completed\n",
            "71.262352566146 % completed\n",
            "71.27829136117309 % completed\n",
            "71.29423015620019 % completed\n",
            "71.31016895122728 % completed\n",
            "71.32610774625438 % completed\n",
            "71.34204654128148 % completed\n",
            "71.35798533630857 % completed\n",
            "71.37392413133567 % completed\n",
            "71.38986292636277 % completed\n",
            "71.40580172138986 % completed\n",
            "71.42174051641696 % completed\n",
            "71.43767931144406 % completed\n",
            "71.45361810647115 % completed\n",
            "71.46955690149825 % completed\n",
            "71.48549569652535 % completed\n",
            "71.50143449155244 % completed\n",
            "71.51737328657954 % completed\n",
            "71.53331208160662 % completed\n",
            "71.54925087663372 % completed\n",
            "71.56518967166082 % completed\n",
            "71.58112846668791 % completed\n",
            "71.59706726171501 % completed\n",
            "71.61300605674211 % completed\n",
            "71.6289448517692 % completed\n",
            "71.6448836467963 % completed\n",
            "71.6608224418234 % completed\n",
            "71.6767612368505 % completed\n",
            "71.69270003187759 % completed\n",
            "71.70863882690469 % completed\n",
            "71.72457762193179 % completed\n",
            "71.74051641695888 % completed\n",
            "71.75645521198598 % completed\n",
            "71.77239400701308 % completed\n",
            "71.78833280204016 % completed\n",
            "71.80427159706726 % completed\n",
            "71.82021039209435 % completed\n",
            "71.83614918712145 % completed\n",
            "71.85208798214855 % completed\n",
            "71.86802677717564 % completed\n",
            "71.88396557220274 % completed\n",
            "71.89990436722984 % completed\n",
            "71.91584316225693 % completed\n",
            "71.93178195728403 % completed\n",
            "71.94772075231113 % completed\n",
            "71.96365954733822 % completed\n",
            "71.97959834236532 % completed\n",
            "71.99553713739242 % completed\n",
            "72.01147593241951 % completed\n",
            "72.02741472744661 % completed\n",
            "72.0433535224737 % completed\n",
            "72.05929231750079 % completed\n",
            "72.07523111252789 % completed\n",
            "72.09116990755498 % completed\n",
            "72.10710870258208 % completed\n",
            "72.12304749760918 % completed\n",
            "72.13898629263628 % completed\n",
            "72.15492508766337 % completed\n",
            "72.17086388269047 % completed\n",
            "72.18680267771757 % completed\n",
            "72.20274147274466 % completed\n",
            "72.21868026777176 % completed\n",
            "72.23461906279886 % completed\n",
            "72.25055785782595 % completed\n",
            "72.26649665285305 % completed\n",
            "72.28243544788015 % completed\n",
            "72.29837424290723 % completed\n",
            "72.31431303793433 % completed\n",
            "72.33025183296142 % completed\n",
            "72.34619062798852 % completed\n",
            "72.36212942301562 % completed\n",
            "72.37806821804271 % completed\n",
            "72.39400701306981 % completed\n",
            "72.40994580809691 % completed\n",
            "72.425884603124 % completed\n",
            "72.4418233981511 % completed\n",
            "72.4577621931782 % completed\n",
            "72.4737009882053 % completed\n",
            "72.48963978323239 % completed\n",
            "72.50557857825949 % completed\n",
            "72.52151737328658 % completed\n",
            "72.53745616831368 % completed\n",
            "72.55339496334076 % completed\n",
            "72.56933375836786 % completed\n",
            "72.58527255339496 % completed\n",
            "72.60121134842205 % completed\n",
            "72.61715014344915 % completed\n",
            "72.63308893847625 % completed\n",
            "72.64902773350335 % completed\n",
            "72.66496652853044 % completed\n",
            "72.68090532355754 % completed\n",
            "72.69684411858464 % completed\n",
            "72.71278291361173 % completed\n",
            "72.72872170863883 % completed\n",
            "72.74466050366593 % completed\n",
            "72.76059929869302 % completed\n",
            "72.77653809372012 % completed\n",
            "72.79247688874722 % completed\n",
            "72.80841568377431 % completed\n",
            "72.8243544788014 % completed\n",
            "72.8402932738285 % completed\n",
            "72.85623206885559 % completed\n",
            "72.87217086388269 % completed\n",
            "72.88810965890978 % completed\n",
            "72.90404845393688 % completed\n",
            "72.91998724896398 % completed\n",
            "72.93592604399107 % completed\n",
            "72.95186483901817 % completed\n",
            "72.96780363404527 % completed\n",
            "72.98374242907236 % completed\n",
            "72.99968122409946 % completed\n",
            "73.01562001912656 % completed\n",
            "73.03155881415366 % completed\n",
            "73.04749760918075 % completed\n",
            "73.06343640420785 % completed\n",
            "73.07937519923493 % completed\n",
            "73.09531399426203 % completed\n",
            "73.11125278928913 % completed\n",
            "73.12719158431622 % completed\n",
            "73.14313037934332 % completed\n",
            "73.15906917437042 % completed\n",
            "73.17500796939751 % completed\n",
            "73.19094676442461 % completed\n",
            "73.2068855594517 % completed\n",
            "73.2228243544788 % completed\n",
            "73.2387631495059 % completed\n",
            "73.254701944533 % completed\n",
            "73.2706407395601 % completed\n",
            "73.28657953458719 % completed\n",
            "73.30251832961429 % completed\n",
            "73.31845712464138 % completed\n",
            "73.33439591966847 % completed\n",
            "73.35033471469556 % completed\n",
            "73.36627350972266 % completed\n",
            "73.38221230474976 % completed\n",
            "73.39815109977685 % completed\n",
            "73.41408989480395 % completed\n",
            "73.43002868983105 % completed\n",
            "73.44596748485814 % completed\n",
            "73.46190627988524 % completed\n",
            "73.47784507491234 % completed\n",
            "73.49378386993943 % completed\n",
            "73.50972266496653 % completed\n",
            "73.52566145999363 % completed\n",
            "73.54160025502073 % completed\n",
            "73.55753905004782 % completed\n",
            "73.57347784507492 % completed\n",
            "73.589416640102 % completed\n",
            "73.6053554351291 % completed\n",
            "73.6212942301562 % completed\n",
            "73.63723302518329 % completed\n",
            "73.65317182021039 % completed\n",
            "73.66911061523749 % completed\n",
            "73.68504941026458 % completed\n",
            "73.70098820529168 % completed\n",
            "73.71692700031878 % completed\n",
            "73.73286579534587 % completed\n",
            "73.74880459037297 % completed\n",
            "73.76474338540007 % completed\n",
            "73.78068218042716 % completed\n",
            "73.79662097545426 % completed\n",
            "73.81255977048136 % completed\n",
            "73.82849856550845 % completed\n",
            "73.84443736053554 % completed\n",
            "73.86037615556263 % completed\n",
            "73.87631495058973 % completed\n",
            "73.89225374561683 % completed\n",
            "73.90819254064392 % completed\n",
            "73.92413133567102 % completed\n",
            "73.94007013069812 % completed\n",
            "73.95600892572521 % completed\n",
            "73.97194772075231 % completed\n",
            "73.98788651577941 % completed\n",
            "74.0038253108065 % completed\n",
            "74.0197641058336 % completed\n",
            "74.0357029008607 % completed\n",
            "74.0516416958878 % completed\n",
            "74.06758049091489 % completed\n",
            "74.08351928594199 % completed\n",
            "74.09945808096907 % completed\n",
            "74.11539687599617 % completed\n",
            "74.13133567102327 % completed\n",
            "74.14727446605036 % completed\n",
            "74.16321326107746 % completed\n",
            "74.17915205610456 % completed\n",
            "74.19509085113165 % completed\n",
            "74.21102964615875 % completed\n",
            "74.22696844118585 % completed\n",
            "74.24290723621294 % completed\n",
            "74.25884603124004 % completed\n",
            "74.27478482626714 % completed\n",
            "74.29072362129423 % completed\n",
            "74.30666241632133 % completed\n",
            "74.32260121134843 % completed\n",
            "74.33854000637552 % completed\n",
            "74.35447880140262 % completed\n",
            "74.3704175964297 % completed\n",
            "74.3863563914568 % completed\n",
            "74.4022951864839 % completed\n",
            "74.418233981511 % completed\n",
            "74.43417277653809 % completed\n",
            "74.45011157156519 % completed\n",
            "74.46605036659228 % completed\n",
            "74.48198916161938 % completed\n",
            "74.49792795664648 % completed\n",
            "74.51386675167358 % completed\n",
            "74.52980554670067 % completed\n",
            "74.54574434172777 % completed\n",
            "74.56168313675487 % completed\n",
            "74.57762193178196 % completed\n",
            "74.59356072680906 % completed\n",
            "74.60949952183616 % completed\n",
            "74.62543831686324 % completed\n",
            "74.64137711189034 % completed\n",
            "74.65731590691743 % completed\n",
            "74.67325470194453 % completed\n",
            "74.68919349697163 % completed\n",
            "74.70513229199872 % completed\n",
            "74.72107108702582 % completed\n",
            "74.73700988205292 % completed\n",
            "74.75294867708001 % completed\n",
            "74.76888747210711 % completed\n",
            "74.7848262671342 % completed\n",
            "74.8007650621613 % completed\n",
            "74.8167038571884 % completed\n",
            "74.8326426522155 % completed\n",
            "74.8485814472426 % completed\n",
            "74.86452024226969 % completed\n",
            "74.88045903729677 % completed\n",
            "74.89639783232387 % completed\n",
            "74.91233662735097 % completed\n",
            "74.92827542237806 % completed\n",
            "74.94421421740516 % completed\n",
            "74.96015301243226 % completed\n",
            "74.97609180745935 % completed\n",
            "74.99203060248645 % completed\n",
            "75.00796939751355 % completed\n",
            "75.02390819254065 % completed\n",
            "75.03984698756774 % completed\n",
            "75.05578578259484 % completed\n",
            "75.07172457762194 % completed\n",
            "75.08766337264903 % completed\n",
            "75.10360216767613 % completed\n",
            "75.11954096270323 % completed\n",
            "75.13547975773031 % completed\n",
            "75.1514185527574 % completed\n",
            "75.1673573477845 % completed\n",
            "75.1832961428116 % completed\n",
            "75.1992349378387 % completed\n",
            "75.2151737328658 % completed\n",
            "75.23111252789289 % completed\n",
            "75.24705132291999 % completed\n",
            "75.26299011794708 % completed\n",
            "75.27892891297418 % completed\n",
            "75.29486770800128 % completed\n",
            "75.31080650302837 % completed\n",
            "75.32674529805547 % completed\n",
            "75.34268409308257 % completed\n",
            "75.35862288810966 % completed\n",
            "75.37456168313676 % completed\n",
            "75.39050047816384 % completed\n",
            "75.40643927319094 % completed\n",
            "75.42237806821804 % completed\n",
            "75.43831686324513 % completed\n",
            "75.45425565827223 % completed\n",
            "75.47019445329933 % completed\n",
            "75.48613324832642 % completed\n",
            "75.50207204335352 % completed\n",
            "75.51801083838062 % completed\n",
            "75.53394963340772 % completed\n",
            "75.54988842843481 % completed\n",
            "75.56582722346191 % completed\n",
            "75.581766018489 % completed\n",
            "75.5977048135161 % completed\n",
            "75.6136436085432 % completed\n",
            "75.6295824035703 % completed\n",
            "75.64552119859738 % completed\n",
            "75.66145999362448 % completed\n",
            "75.67739878865157 % completed\n",
            "75.69333758367867 % completed\n",
            "75.70927637870577 % completed\n",
            "75.72521517373286 % completed\n",
            "75.74115396875996 % completed\n",
            "75.75709276378706 % completed\n",
            "75.77303155881415 % completed\n",
            "75.78897035384125 % completed\n",
            "75.80490914886835 % completed\n",
            "75.82084794389544 % completed\n",
            "75.83678673892254 % completed\n",
            "75.85272553394964 % completed\n",
            "75.86866432897673 % completed\n",
            "75.88460312400383 % completed\n",
            "75.90054191903093 % completed\n",
            "75.91648071405801 % completed\n",
            "75.93241950908511 % completed\n",
            "75.9483583041122 % completed\n",
            "75.9642970991393 % completed\n",
            "75.9802358941664 % completed\n",
            "75.9961746891935 % completed\n",
            "76.01211348422059 % completed\n",
            "76.02805227924769 % completed\n",
            "76.04399107427479 % completed\n",
            "76.05992986930188 % completed\n",
            "76.07586866432898 % completed\n",
            "76.09180745935608 % completed\n",
            "76.10774625438317 % completed\n",
            "76.12368504941027 % completed\n",
            "76.13962384443737 % completed\n",
            "76.15556263946446 % completed\n",
            "76.17150143449155 % completed\n",
            "76.18744022951864 % completed\n",
            "76.20337902454574 % completed\n",
            "76.21931781957284 % completed\n",
            "76.23525661459993 % completed\n",
            "76.25119540962703 % completed\n",
            "76.26713420465413 % completed\n",
            "76.28307299968122 % completed\n",
            "76.29901179470832 % completed\n",
            "76.31495058973542 % completed\n",
            "76.33088938476251 % completed\n",
            "76.34682817978961 % completed\n",
            "76.36276697481671 % completed\n",
            "76.3787057698438 % completed\n",
            "76.3946445648709 % completed\n",
            "76.410583359898 % completed\n",
            "76.42652215492508 % completed\n",
            "76.44246094995218 % completed\n",
            "76.45839974497927 % completed\n",
            "76.47433854000637 % completed\n",
            "76.49027733503347 % completed\n",
            "76.50621613006057 % completed\n",
            "76.52215492508766 % completed\n",
            "76.53809372011476 % completed\n",
            "76.55403251514186 % completed\n",
            "76.56997131016895 % completed\n",
            "76.58591010519605 % completed\n",
            "76.60184890022315 % completed\n",
            "76.61778769525024 % completed\n",
            "76.63372649027734 % completed\n",
            "76.64966528530444 % completed\n",
            "76.66560408033153 % completed\n",
            "76.68154287535862 % completed\n",
            "76.69748167038571 % completed\n",
            "76.71342046541281 % completed\n",
            "76.7293592604399 % completed\n",
            "76.745298055467 % completed\n",
            "76.7612368504941 % completed\n",
            "76.7771756455212 % completed\n",
            "76.7931144405483 % completed\n",
            "76.80905323557539 % completed\n",
            "76.82499203060249 % completed\n",
            "76.84093082562958 % completed\n",
            "76.85686962065668 % completed\n",
            "76.87280841568378 % completed\n",
            "76.88874721071087 % completed\n",
            "76.90468600573797 % completed\n",
            "76.92062480076507 % completed\n",
            "76.93656359579215 % completed\n",
            "76.95250239081925 % completed\n",
            "76.96844118584634 % completed\n",
            "76.98437998087344 % completed\n",
            "77.00031877590054 % completed\n",
            "77.01625757092764 % completed\n",
            "77.03219636595473 % completed\n",
            "77.04813516098183 % completed\n",
            "77.06407395600893 % completed\n",
            "77.08001275103602 % completed\n",
            "77.09595154606312 % completed\n",
            "77.11189034109022 % completed\n",
            "77.12782913611731 % completed\n",
            "77.14376793114441 % completed\n",
            "77.1597067261715 % completed\n",
            "77.1756455211986 % completed\n",
            "77.19158431622569 % completed\n",
            "77.20752311125278 % completed\n",
            "77.22346190627988 % completed\n",
            "77.23940070130698 % completed\n",
            "77.25533949633407 % completed\n",
            "77.27127829136117 % completed\n",
            "77.28721708638827 % completed\n",
            "77.30315588141536 % completed\n",
            "77.31909467644246 % completed\n",
            "77.33503347146956 % completed\n",
            "77.35097226649665 % completed\n",
            "77.36691106152375 % completed\n",
            "77.38284985655085 % completed\n",
            "77.39878865157795 % completed\n",
            "77.41472744660504 % completed\n",
            "77.43066624163214 % completed\n",
            "77.44660503665924 % completed\n",
            "77.46254383168632 % completed\n",
            "77.47848262671342 % completed\n",
            "77.49442142174051 % completed\n",
            "77.51036021676761 % completed\n",
            "77.5262990117947 % completed\n",
            "77.5422378068218 % completed\n",
            "77.5581766018489 % completed\n",
            "77.574115396876 % completed\n",
            "77.59005419190309 % completed\n",
            "77.60599298693019 % completed\n",
            "77.62193178195729 % completed\n",
            "77.63787057698438 % completed\n",
            "77.65380937201148 % completed\n",
            "77.66974816703858 % completed\n",
            "77.68568696206567 % completed\n",
            "77.70162575709277 % completed\n",
            "77.71756455211985 % completed\n",
            "77.73350334714695 % completed\n",
            "77.74944214217405 % completed\n",
            "77.76538093720114 % completed\n",
            "77.78131973222824 % completed\n",
            "77.79725852725534 % completed\n",
            "77.81319732228243 % completed\n",
            "77.82913611730953 % completed\n",
            "77.84507491233663 % completed\n",
            "77.86101370736372 % completed\n",
            "77.87695250239082 % completed\n",
            "77.89289129741792 % completed\n",
            "77.90883009244502 % completed\n",
            "77.92476888747211 % completed\n",
            "77.94070768249921 % completed\n",
            "77.9566464775263 % completed\n",
            "77.97258527255339 % completed\n",
            "77.98852406758049 % completed\n",
            "78.00446286260758 % completed\n",
            "78.02040165763468 % completed\n",
            "78.03634045266178 % completed\n",
            "78.05227924768887 % completed\n",
            "78.06821804271597 % completed\n",
            "78.08415683774307 % completed\n",
            "78.10009563277016 % completed\n",
            "78.11603442779726 % completed\n",
            "78.13197322282436 % completed\n",
            "78.14791201785145 % completed\n",
            "78.16385081287855 % completed\n",
            "78.17978960790565 % completed\n",
            "78.19572840293274 % completed\n",
            "78.21166719795984 % completed\n",
            "78.22760599298692 % completed\n",
            "78.24354478801402 % completed\n",
            "78.25948358304112 % completed\n",
            "78.27542237806821 % completed\n",
            "78.29136117309531 % completed\n",
            "78.30729996812241 % completed\n",
            "78.3232387631495 % completed\n",
            "78.3391775581766 % completed\n",
            "78.3551163532037 % completed\n",
            "78.3710551482308 % completed\n",
            "78.38699394325789 % completed\n",
            "78.40293273828499 % completed\n",
            "78.41887153331209 % completed\n",
            "78.43481032833918 % completed\n",
            "78.45074912336628 % completed\n",
            "78.46668791839338 % completed\n",
            "78.48262671342046 % completed\n",
            "78.49856550844756 % completed\n",
            "78.51450430347465 % completed\n",
            "78.53044309850175 % completed\n",
            "78.54638189352885 % completed\n",
            "78.56232068855594 % completed\n",
            "78.57825948358304 % completed\n",
            "78.59419827861014 % completed\n",
            "78.61013707363723 % completed\n",
            "78.62607586866433 % completed\n",
            "78.64201466369143 % completed\n",
            "78.65795345871852 % completed\n",
            "78.67389225374562 % completed\n",
            "78.68983104877272 % completed\n",
            "78.70576984379981 % completed\n",
            "78.72170863882691 % completed\n",
            "78.737647433854 % completed\n",
            "78.75358622888109 % completed\n",
            "78.76952502390819 % completed\n",
            "78.78546381893528 % completed\n",
            "78.80140261396238 % completed\n",
            "78.81734140898948 % completed\n",
            "78.83328020401657 % completed\n",
            "78.84921899904367 % completed\n",
            "78.86515779407077 % completed\n",
            "78.88109658909787 % completed\n",
            "78.89703538412496 % completed\n",
            "78.91297417915206 % completed\n",
            "78.92891297417916 % completed\n",
            "78.94485176920625 % completed\n",
            "78.96079056423335 % completed\n",
            "78.97672935926045 % completed\n",
            "78.99266815428754 % completed\n",
            "79.00860694931463 % completed\n",
            "79.02454574434172 % completed\n",
            "79.04048453936882 % completed\n",
            "79.05642333439592 % completed\n",
            "79.07236212942301 % completed\n",
            "79.08830092445011 % completed\n",
            "79.1042397194772 % completed\n",
            "79.1201785145043 % completed\n",
            "79.1361173095314 % completed\n",
            "79.1520561045585 % completed\n",
            "79.1679948995856 % completed\n",
            "79.18393369461269 % completed\n",
            "79.19987248963979 % completed\n",
            "79.21581128466688 % completed\n",
            "79.23175007969398 % completed\n",
            "79.24768887472108 % completed\n",
            "79.26362766974816 % completed\n",
            "79.27956646477526 % completed\n",
            "79.29550525980235 % completed\n",
            "79.31144405482945 % completed\n",
            "79.32738284985655 % completed\n",
            "79.34332164488364 % completed\n",
            "79.35926043991074 % completed\n",
            "79.37519923493784 % completed\n",
            "79.39113802996494 % completed\n",
            "79.40707682499203 % completed\n",
            "79.42301562001913 % completed\n",
            "79.43895441504623 % completed\n",
            "79.45489321007332 % completed\n",
            "79.47083200510042 % completed\n",
            "79.48677080012752 % completed\n",
            "79.50270959515461 % completed\n",
            "79.5186483901817 % completed\n",
            "79.53458718520879 % completed\n",
            "79.55052598023589 % completed\n",
            "79.56646477526299 % completed\n",
            "79.58240357029008 % completed\n",
            "79.59834236531718 % completed\n",
            "79.61428116034428 % completed\n",
            "79.63021995537137 % completed\n",
            "79.64615875039847 % completed\n",
            "79.66209754542557 % completed\n",
            "79.67803634045266 % completed\n",
            "79.69397513547976 % completed\n",
            "79.70991393050686 % completed\n",
            "79.72585272553395 % completed\n",
            "79.74179152056105 % completed\n",
            "79.75773031558815 % completed\n",
            "79.77366911061523 % completed\n",
            "79.78960790564233 % completed\n",
            "79.80554670066942 % completed\n",
            "79.82148549569652 % completed\n",
            "79.83742429072362 % completed\n",
            "79.85336308575071 % completed\n",
            "79.86930188077781 % completed\n",
            "79.88524067580491 % completed\n",
            "79.901179470832 % completed\n",
            "79.9171182658591 % completed\n",
            "79.9330570608862 % completed\n",
            "79.9489958559133 % completed\n",
            "79.96493465094039 % completed\n",
            "79.98087344596749 % completed\n",
            "79.99681224099459 % completed\n",
            "80.01275103602168 % completed\n",
            "80.02868983104877 % completed\n",
            "80.04462862607586 % completed\n",
            "80.06056742110296 % completed\n",
            "80.07650621613006 % completed\n",
            "80.09244501115715 % completed\n",
            "80.10838380618425 % completed\n",
            "80.12432260121135 % completed\n",
            "80.14026139623844 % completed\n",
            "80.15620019126554 % completed\n",
            "80.17213898629264 % completed\n",
            "80.18807778131973 % completed\n",
            "80.20401657634683 % completed\n",
            "80.21995537137393 % completed\n",
            "80.23589416640102 % completed\n",
            "80.25183296142812 % completed\n",
            "80.26777175645522 % completed\n",
            "80.2837105514823 % completed\n",
            "80.2996493465094 % completed\n",
            "80.3155881415365 % completed\n",
            "80.33152693656359 % completed\n",
            "80.34746573159069 % completed\n",
            "80.36340452661778 % completed\n",
            "80.37934332164488 % completed\n",
            "80.39528211667198 % completed\n",
            "80.41122091169908 % completed\n",
            "80.42715970672617 % completed\n",
            "80.44309850175327 % completed\n",
            "80.45903729678037 % completed\n",
            "80.47497609180746 % completed\n",
            "80.49091488683456 % completed\n",
            "80.50685368186166 % completed\n",
            "80.52279247688875 % completed\n",
            "80.53873127191585 % completed\n",
            "80.55467006694293 % completed\n",
            "80.57060886197003 % completed\n",
            "80.58654765699713 % completed\n",
            "80.60248645202422 % completed\n",
            "80.61842524705132 % completed\n",
            "80.63436404207842 % completed\n",
            "80.65030283710551 % completed\n",
            "80.66624163213261 % completed\n",
            "80.68218042715971 % completed\n",
            "80.6981192221868 % completed\n",
            "80.7140580172139 % completed\n",
            "80.729996812241 % completed\n",
            "80.7459356072681 % completed\n",
            "80.76187440229519 % completed\n",
            "80.77781319732229 % completed\n",
            "80.79375199234939 % completed\n",
            "80.80969078737647 % completed\n",
            "80.82562958240356 % completed\n",
            "80.84156837743066 % completed\n",
            "80.85750717245776 % completed\n",
            "80.87344596748486 % completed\n",
            "80.88938476251195 % completed\n",
            "80.90532355753905 % completed\n",
            "80.92126235256615 % completed\n",
            "80.93720114759324 % completed\n",
            "80.95313994262034 % completed\n",
            "80.96907873764744 % completed\n",
            "80.98501753267453 % completed\n",
            "81.00095632770163 % completed\n",
            "81.01689512272873 % completed\n",
            "81.03283391775582 % completed\n",
            "81.04877271278292 % completed\n",
            "81.06471150781 % completed\n",
            "81.0806503028371 % completed\n",
            "81.0965890978642 % completed\n",
            "81.1125278928913 % completed\n",
            "81.12846668791839 % completed\n",
            "81.14440548294549 % completed\n",
            "81.16034427797258 % completed\n",
            "81.17628307299968 % completed\n",
            "81.19222186802678 % completed\n",
            "81.20816066305387 % completed\n",
            "81.22409945808097 % completed\n",
            "81.24003825310807 % completed\n",
            "81.25597704813516 % completed\n",
            "81.27191584316226 % completed\n",
            "81.28785463818936 % completed\n",
            "81.30379343321646 % completed\n",
            "81.31973222824354 % completed\n",
            "81.33567102327063 % completed\n",
            "81.35160981829773 % completed\n",
            "81.36754861332483 % completed\n",
            "81.38348740835193 % completed\n",
            "81.39942620337902 % completed\n",
            "81.41536499840612 % completed\n",
            "81.43130379343322 % completed\n",
            "81.44724258846031 % completed\n",
            "81.46318138348741 % completed\n",
            "81.4791201785145 % completed\n",
            "81.4950589735416 % completed\n",
            "81.5109977685687 % completed\n",
            "81.5269365635958 % completed\n",
            "81.5428753586229 % completed\n",
            "81.55881415364999 % completed\n",
            "81.57475294867707 % completed\n",
            "81.59069174370417 % completed\n",
            "81.60663053873127 % completed\n",
            "81.62256933375836 % completed\n",
            "81.63850812878546 % completed\n",
            "81.65444692381256 % completed\n",
            "81.67038571883965 % completed\n",
            "81.68632451386675 % completed\n",
            "81.70226330889385 % completed\n",
            "81.71820210392094 % completed\n",
            "81.73414089894804 % completed\n",
            "81.75007969397514 % completed\n",
            "81.76601848900224 % completed\n",
            "81.78195728402933 % completed\n",
            "81.79789607905643 % completed\n",
            "81.81383487408353 % completed\n",
            "81.82977366911062 % completed\n",
            "81.8457124641377 % completed\n",
            "81.8616512591648 % completed\n",
            "81.8775900541919 % completed\n",
            "81.893528849219 % completed\n",
            "81.90946764424609 % completed\n",
            "81.92540643927319 % completed\n",
            "81.94134523430029 % completed\n",
            "81.95728402932738 % completed\n",
            "81.97322282435448 % completed\n",
            "81.98916161938158 % completed\n",
            "82.00510041440867 % completed\n",
            "82.02103920943577 % completed\n",
            "82.03697800446287 % completed\n",
            "82.05291679948996 % completed\n",
            "82.06885559451706 % completed\n",
            "82.08479438954416 % completed\n",
            "82.10073318457124 % completed\n",
            "82.11667197959834 % completed\n",
            "82.13261077462543 % completed\n",
            "82.14854956965253 % completed\n",
            "82.16448836467963 % completed\n",
            "82.18042715970672 % completed\n",
            "82.19636595473382 % completed\n",
            "82.21230474976092 % completed\n",
            "82.22824354478801 % completed\n",
            "82.24418233981511 % completed\n",
            "82.26012113484221 % completed\n",
            "82.2760599298693 % completed\n",
            "82.2919987248964 % completed\n",
            "82.3079375199235 % completed\n",
            "82.3238763149506 % completed\n",
            "82.33981510997769 % completed\n",
            "82.35575390500478 % completed\n",
            "82.37169270003187 % completed\n",
            "82.38763149505897 % completed\n",
            "82.40357029008607 % completed\n",
            "82.41950908511316 % completed\n",
            "82.43544788014026 % completed\n",
            "82.45138667516736 % completed\n",
            "82.46732547019445 % completed\n",
            "82.48326426522155 % completed\n",
            "82.49920306024865 % completed\n",
            "82.51514185527574 % completed\n",
            "82.53108065030284 % completed\n",
            "82.54701944532994 % completed\n",
            "82.56295824035703 % completed\n",
            "82.57889703538413 % completed\n",
            "82.59483583041123 % completed\n",
            "82.61077462543831 % completed\n",
            "82.6267134204654 % completed\n",
            "82.6426522154925 % completed\n",
            "82.6585910105196 % completed\n",
            "82.6745298055467 % completed\n",
            "82.6904686005738 % completed\n",
            "82.70640739560089 % completed\n",
            "82.72234619062799 % completed\n",
            "82.73828498565508 % completed\n",
            "82.75422378068218 % completed\n",
            "82.77016257570928 % completed\n",
            "82.78610137073638 % completed\n",
            "82.80204016576347 % completed\n",
            "82.81797896079057 % completed\n",
            "82.83391775581767 % completed\n",
            "82.84985655084476 % completed\n",
            "82.86579534587185 % completed\n",
            "82.88173414089894 % completed\n",
            "82.89767293592604 % completed\n",
            "82.91361173095314 % completed\n",
            "82.92955052598023 % completed\n",
            "82.94548932100733 % completed\n",
            "82.96142811603443 % completed\n",
            "82.97736691106152 % completed\n",
            "82.99330570608862 % completed\n",
            "83.00924450111572 % completed\n",
            "83.02518329614281 % completed\n",
            "83.04112209116991 % completed\n",
            "83.05706088619701 % completed\n",
            "83.0729996812241 % completed\n",
            "83.0889384762512 % completed\n",
            "83.1048772712783 % completed\n",
            "83.12081606630538 % completed\n",
            "83.13675486133248 % completed\n",
            "83.15269365635957 % completed\n",
            "83.16863245138667 % completed\n",
            "83.18457124641377 % completed\n",
            "83.20051004144086 % completed\n",
            "83.21644883646796 % completed\n",
            "83.23238763149506 % completed\n",
            "83.24832642652215 % completed\n",
            "83.26426522154925 % completed\n",
            "83.28020401657635 % completed\n",
            "83.29614281160345 % completed\n",
            "83.31208160663054 % completed\n",
            "83.32802040165764 % completed\n",
            "83.34395919668474 % completed\n",
            "83.35989799171183 % completed\n",
            "83.37583678673893 % completed\n",
            "83.39177558176601 % completed\n",
            "83.40771437679311 % completed\n",
            "83.4236531718202 % completed\n",
            "83.4395919668473 % completed\n",
            "83.4555307618744 % completed\n",
            "83.4714695569015 % completed\n",
            "83.4874083519286 % completed\n",
            "83.50334714695569 % completed\n",
            "83.51928594198279 % completed\n",
            "83.53522473700988 % completed\n",
            "83.55116353203698 % completed\n",
            "83.56710232706408 % completed\n",
            "83.58304112209117 % completed\n",
            "83.59897991711827 % completed\n",
            "83.61491871214537 % completed\n",
            "83.63085750717246 % completed\n",
            "83.64679630219955 % completed\n",
            "83.66273509722664 % completed\n",
            "83.67867389225374 % completed\n",
            "83.69461268728084 % completed\n",
            "83.71055148230793 % completed\n",
            "83.72649027733503 % completed\n",
            "83.74242907236213 % completed\n",
            "83.75836786738923 % completed\n",
            "83.77430666241632 % completed\n",
            "83.79024545744342 % completed\n",
            "83.80618425247052 % completed\n",
            "83.82212304749761 % completed\n",
            "83.83806184252471 % completed\n",
            "83.8540006375518 % completed\n",
            "83.8699394325789 % completed\n",
            "83.885878227606 % completed\n",
            "83.90181702263308 % completed\n",
            "83.91775581766018 % completed\n",
            "83.93369461268728 % completed\n",
            "83.94963340771437 % completed\n",
            "83.96557220274147 % completed\n",
            "83.98151099776857 % completed\n",
            "83.99744979279566 % completed\n",
            "84.01338858782276 % completed\n",
            "84.02932738284986 % completed\n",
            "84.04526617787695 % completed\n",
            "84.06120497290405 % completed\n",
            "84.07714376793115 % completed\n",
            "84.09308256295824 % completed\n",
            "84.10902135798534 % completed\n",
            "84.12496015301244 % completed\n",
            "84.14089894803953 % completed\n",
            "84.15683774306662 % completed\n",
            "84.17277653809371 % completed\n",
            "84.18871533312081 % completed\n",
            "84.20465412814791 % completed\n",
            "84.220592923175 % completed\n",
            "84.2365317182021 % completed\n",
            "84.2524705132292 % completed\n",
            "84.2684093082563 % completed\n",
            "84.28434810328339 % completed\n",
            "84.30028689831049 % completed\n",
            "84.31622569333759 % completed\n",
            "84.33216448836468 % completed\n",
            "84.34810328339178 % completed\n",
            "84.36404207841888 % completed\n",
            "84.37998087344597 % completed\n",
            "84.39591966847307 % completed\n",
            "84.41185846350015 % completed\n",
            "84.42779725852725 % completed\n",
            "84.44373605355435 % completed\n",
            "84.45967484858144 % completed\n",
            "84.47561364360854 % completed\n",
            "84.49155243863564 % completed\n",
            "84.50749123366273 % completed\n",
            "84.52343002868983 % completed\n",
            "84.53936882371693 % completed\n",
            "84.55530761874402 % completed\n",
            "84.57124641377112 % completed\n",
            "84.58718520879822 % completed\n",
            "84.60312400382531 % completed\n",
            "84.61906279885241 % completed\n",
            "84.63500159387951 % completed\n",
            "84.6509403889066 % completed\n",
            "84.66687918393369 % completed\n",
            "84.68281797896078 % completed\n",
            "84.69875677398788 % completed\n",
            "84.71469556901498 % completed\n",
            "84.73063436404207 % completed\n",
            "84.74657315906917 % completed\n",
            "84.76251195409627 % completed\n",
            "84.77845074912337 % completed\n",
            "84.79438954415046 % completed\n",
            "84.81032833917756 % completed\n",
            "84.82626713420466 % completed\n",
            "84.84220592923175 % completed\n",
            "84.85814472425885 % completed\n",
            "84.87408351928595 % completed\n",
            "84.89002231431304 % completed\n",
            "84.90596110934014 % completed\n",
            "84.92189990436724 % completed\n",
            "84.93783869939432 % completed\n",
            "84.95377749442142 % completed\n",
            "84.96971628944851 % completed\n",
            "84.98565508447561 % completed\n",
            "85.0015938795027 % completed\n",
            "85.0175326745298 % completed\n",
            "85.0334714695569 % completed\n",
            "85.049410264584 % completed\n",
            "85.0653490596111 % completed\n",
            "85.08128785463819 % completed\n",
            "85.09722664966529 % completed\n",
            "85.11316544469238 % completed\n",
            "85.12910423971948 % completed\n",
            "85.14504303474658 % completed\n",
            "85.16098182977368 % completed\n",
            "85.17692062480077 % completed\n",
            "85.19285941982785 % completed\n",
            "85.20879821485495 % completed\n",
            "85.22473700988205 % completed\n",
            "85.24067580490915 % completed\n",
            "85.25661459993624 % completed\n",
            "85.27255339496334 % completed\n",
            "85.28849218999044 % completed\n",
            "85.30443098501753 % completed\n",
            "85.32036978004463 % completed\n",
            "85.33630857507173 % completed\n",
            "85.35224737009882 % completed\n",
            "85.36818616512592 % completed\n",
            "85.38412496015302 % completed\n",
            "85.40006375518011 % completed\n",
            "85.41600255020721 % completed\n",
            "85.4319413452343 % completed\n",
            "85.44788014026139 % completed\n",
            "85.46381893528849 % completed\n",
            "85.47975773031558 % completed\n",
            "85.49569652534268 % completed\n",
            "85.51163532036978 % completed\n",
            "85.52757411539687 % completed\n",
            "85.54351291042397 % completed\n",
            "85.55945170545107 % completed\n",
            "85.57539050047816 % completed\n",
            "85.59132929550526 % completed\n",
            "85.60726809053236 % completed\n",
            "85.62320688555945 % completed\n",
            "85.63914568058655 % completed\n",
            "85.65508447561365 % completed\n",
            "85.67102327064075 % completed\n",
            "85.68696206566784 % completed\n",
            "85.70290086069492 % completed\n",
            "85.71883965572202 % completed\n",
            "85.73477845074912 % completed\n",
            "85.75071724577622 % completed\n",
            "85.76665604080331 % completed\n",
            "85.78259483583041 % completed\n",
            "85.7985336308575 % completed\n",
            "85.8144724258846 % completed\n",
            "85.8304112209117 % completed\n",
            "85.8463500159388 % completed\n",
            "85.8622888109659 % completed\n",
            "85.87822760599299 % completed\n",
            "85.89416640102009 % completed\n",
            "85.91010519604718 % completed\n",
            "85.92604399107428 % completed\n",
            "85.94198278610138 % completed\n",
            "85.95792158112846 % completed\n",
            "85.97386037615556 % completed\n",
            "85.98979917118265 % completed\n",
            "86.00573796620975 % completed\n",
            "86.02167676123685 % completed\n",
            "86.03761555626394 % completed\n",
            "86.05355435129104 % completed\n",
            "86.06949314631814 % completed\n",
            "86.08543194134523 % completed\n",
            "86.10137073637233 % completed\n",
            "86.11730953139943 % completed\n",
            "86.13324832642652 % completed\n",
            "86.14918712145362 % completed\n",
            "86.16512591648072 % completed\n",
            "86.18106471150782 % completed\n",
            "86.19700350653491 % completed\n",
            "86.212942301562 % completed\n",
            "86.22888109658909 % completed\n",
            "86.24481989161619 % completed\n",
            "86.26075868664329 % completed\n",
            "86.27669748167038 % completed\n",
            "86.29263627669748 % completed\n",
            "86.30857507172458 % completed\n",
            "86.32451386675167 % completed\n",
            "86.34045266177877 % completed\n",
            "86.35639145680587 % completed\n",
            "86.37233025183296 % completed\n",
            "86.38826904686006 % completed\n",
            "86.40420784188716 % completed\n",
            "86.42014663691425 % completed\n",
            "86.43608543194135 % completed\n",
            "86.45202422696845 % completed\n",
            "86.46796302199554 % completed\n",
            "86.48390181702263 % completed\n",
            "86.49984061204972 % completed\n",
            "86.51577940707682 % completed\n",
            "86.53171820210392 % completed\n",
            "86.54765699713101 % completed\n",
            "86.56359579215811 % completed\n",
            "86.57953458718521 % completed\n",
            "86.5954733822123 % completed\n",
            "86.6114121772394 % completed\n",
            "86.6273509722665 % completed\n",
            "86.6432897672936 % completed\n",
            "86.65922856232069 % completed\n",
            "86.67516735734779 % completed\n",
            "86.69110615237489 % completed\n",
            "86.70704494740198 % completed\n",
            "86.72298374242908 % completed\n",
            "86.73892253745616 % completed\n",
            "86.75486133248326 % completed\n",
            "86.77080012751036 % completed\n",
            "86.78673892253745 % completed\n",
            "86.80267771756455 % completed\n",
            "86.81861651259165 % completed\n",
            "86.83455530761874 % completed\n",
            "86.85049410264584 % completed\n",
            "86.86643289767294 % completed\n",
            "86.88237169270003 % completed\n",
            "86.89831048772713 % completed\n",
            "86.91424928275423 % completed\n",
            "86.93018807778132 % completed\n",
            "86.94612687280842 % completed\n",
            "86.96206566783552 % completed\n",
            "86.97800446286261 % completed\n",
            "86.9939432578897 % completed\n",
            "87.0098820529168 % completed\n",
            "87.02582084794389 % completed\n",
            "87.04175964297099 % completed\n",
            "87.05769843799808 % completed\n",
            "87.07363723302518 % completed\n",
            "87.08957602805228 % completed\n",
            "87.10551482307937 % completed\n",
            "87.12145361810647 % completed\n",
            "87.13739241313357 % completed\n",
            "87.15333120816067 % completed\n",
            "87.16927000318776 % completed\n",
            "87.18520879821486 % completed\n",
            "87.20114759324196 % completed\n",
            "87.21708638826905 % completed\n",
            "87.23302518329615 % completed\n",
            "87.24896397832323 % completed\n",
            "87.26490277335033 % completed\n",
            "87.28084156837743 % completed\n",
            "87.29678036340452 % completed\n",
            "87.31271915843162 % completed\n",
            "87.32865795345872 % completed\n",
            "87.34459674848581 % completed\n",
            "87.36053554351291 % completed\n",
            "87.37647433854 % completed\n",
            "87.3924131335671 % completed\n",
            "87.4083519285942 % completed\n",
            "87.4242907236213 % completed\n",
            "87.4402295186484 % completed\n",
            "87.45616831367549 % completed\n",
            "87.47210710870259 % completed\n",
            "87.48804590372968 % completed\n",
            "87.50398469875677 % completed\n",
            "87.51992349378386 % completed\n",
            "87.53586228881096 % completed\n",
            "87.55180108383806 % completed\n",
            "87.56773987886515 % completed\n",
            "87.58367867389225 % completed\n",
            "87.59961746891935 % completed\n",
            "87.61555626394644 % completed\n",
            "87.63149505897354 % completed\n",
            "87.64743385400064 % completed\n",
            "87.66337264902774 % completed\n",
            "87.67931144405483 % completed\n",
            "87.69525023908193 % completed\n",
            "87.71118903410903 % completed\n",
            "87.72712782913612 % completed\n",
            "87.74306662416322 % completed\n",
            "87.7590054191903 % completed\n",
            "87.7749442142174 % completed\n",
            "87.7908830092445 % completed\n",
            "87.80682180427159 % completed\n",
            "87.82276059929869 % completed\n",
            "87.83869939432579 % completed\n",
            "87.85463818935288 % completed\n",
            "87.87057698437998 % completed\n",
            "87.88651577940708 % completed\n",
            "87.90245457443417 % completed\n",
            "87.91839336946127 % completed\n",
            "87.93433216448837 % completed\n",
            "87.95027095951546 % completed\n",
            "87.96620975454256 % completed\n",
            "87.98214854956966 % completed\n",
            "87.99808734459675 % completed\n",
            "88.01402613962385 % completed\n",
            "88.02996493465093 % completed\n",
            "88.04590372967803 % completed\n",
            "88.06184252470513 % completed\n",
            "88.07778131973222 % completed\n",
            "88.09372011475932 % completed\n",
            "88.10965890978642 % completed\n",
            "88.12559770481352 % completed\n",
            "88.14153649984061 % completed\n",
            "88.15747529486771 % completed\n",
            "88.1734140898948 % completed\n",
            "88.1893528849219 % completed\n",
            "88.205291679949 % completed\n",
            "88.2212304749761 % completed\n",
            "88.23716927000319 % completed\n",
            "88.25310806503029 % completed\n",
            "88.26904686005739 % completed\n",
            "88.28498565508447 % completed\n",
            "88.30092445011157 % completed\n",
            "88.31686324513866 % completed\n",
            "88.33280204016576 % completed\n",
            "88.34874083519286 % completed\n",
            "88.36467963021995 % completed\n",
            "88.38061842524705 % completed\n",
            "88.39655722027415 % completed\n",
            "88.41249601530124 % completed\n",
            "88.42843481032834 % completed\n",
            "88.44437360535544 % completed\n",
            "88.46031240038253 % completed\n",
            "88.47625119540963 % completed\n",
            "88.49218999043673 % completed\n",
            "88.50812878546382 % completed\n",
            "88.52406758049092 % completed\n",
            "88.540006375518 % completed\n",
            "88.5559451705451 % completed\n",
            "88.5718839655722 % completed\n",
            "88.5878227605993 % completed\n",
            "88.60376155562639 % completed\n",
            "88.61970035065349 % completed\n",
            "88.63563914568059 % completed\n",
            "88.65157794070768 % completed\n",
            "88.66751673573478 % completed\n",
            "88.68345553076188 % completed\n",
            "88.69939432578897 % completed\n",
            "88.71533312081607 % completed\n",
            "88.73127191584317 % completed\n",
            "88.74721071087026 % completed\n",
            "88.76314950589736 % completed\n",
            "88.77908830092446 % completed\n",
            "88.79502709595154 % completed\n",
            "88.81096589097864 % completed\n",
            "88.82690468600573 % completed\n",
            "88.84284348103283 % completed\n",
            "88.85878227605993 % completed\n",
            "88.87472107108702 % completed\n",
            "88.89065986611412 % completed\n",
            "88.90659866114122 % completed\n",
            "88.92253745616831 % completed\n",
            "88.93847625119541 % completed\n",
            "88.95441504622251 % completed\n",
            "88.9703538412496 % completed\n",
            "88.9862926362767 % completed\n",
            "89.0022314313038 % completed\n",
            "89.0181702263309 % completed\n",
            "89.03410902135799 % completed\n",
            "89.05004781638507 % completed\n",
            "89.06598661141217 % completed\n",
            "89.08192540643927 % completed\n",
            "89.09786420146636 % completed\n",
            "89.11380299649346 % completed\n",
            "89.12974179152056 % completed\n",
            "89.14568058654766 % completed\n",
            "89.16161938157475 % completed\n",
            "89.17755817660185 % completed\n",
            "89.19349697162895 % completed\n",
            "89.20943576665604 % completed\n",
            "89.22537456168314 % completed\n",
            "89.24131335671024 % completed\n",
            "89.25725215173733 % completed\n",
            "89.27319094676443 % completed\n",
            "89.28912974179153 % completed\n",
            "89.30506853681861 % completed\n",
            "89.3210073318457 % completed\n",
            "89.3369461268728 % completed\n",
            "89.3528849218999 % completed\n",
            "89.368823716927 % completed\n",
            "89.3847625119541 % completed\n",
            "89.40070130698119 % completed\n",
            "89.41664010200829 % completed\n",
            "89.43257889703538 % completed\n",
            "89.44851769206248 % completed\n",
            "89.46445648708958 % completed\n",
            "89.48039528211667 % completed\n",
            "89.49633407714377 % completed\n",
            "89.51227287217087 % completed\n",
            "89.52821166719797 % completed\n",
            "89.54415046222506 % completed\n",
            "89.56008925725216 % completed\n",
            "89.57602805227924 % completed\n",
            "89.59196684730634 % completed\n",
            "89.60790564233344 % completed\n",
            "89.62384443736053 % completed\n",
            "89.63978323238763 % completed\n",
            "89.65572202741473 % completed\n",
            "89.67166082244182 % completed\n",
            "89.68759961746892 % completed\n",
            "89.70353841249602 % completed\n",
            "89.71947720752311 % completed\n",
            "89.73541600255021 % completed\n",
            "89.7513547975773 % completed\n",
            "89.7672935926044 % completed\n",
            "89.7832323876315 % completed\n",
            "89.7991711826586 % completed\n",
            "89.8151099776857 % completed\n",
            "89.83104877271278 % completed\n",
            "89.84698756773987 % completed\n",
            "89.86292636276697 % completed\n",
            "89.87886515779407 % completed\n",
            "89.89480395282116 % completed\n",
            "89.91074274784826 % completed\n",
            "89.92668154287536 % completed\n",
            "89.94262033790245 % completed\n",
            "89.95855913292955 % completed\n",
            "89.97449792795665 % completed\n",
            "89.99043672298374 % completed\n",
            "90.00637551801084 % completed\n",
            "90.02231431303794 % completed\n",
            "90.03825310806504 % completed\n",
            "90.05419190309213 % completed\n",
            "90.07013069811923 % completed\n",
            "90.08606949314631 % completed\n",
            "90.10200828817341 % completed\n",
            "90.1179470832005 % completed\n",
            "90.1338858782276 % completed\n",
            "90.1498246732547 % completed\n",
            "90.1657634682818 % completed\n",
            "90.18170226330889 % completed\n",
            "90.19764105833599 % completed\n",
            "90.21357985336309 % completed\n",
            "90.22951864839018 % completed\n",
            "90.24545744341728 % completed\n",
            "90.26139623844438 % completed\n",
            "90.27733503347147 % completed\n",
            "90.29327382849857 % completed\n",
            "90.30921262352567 % completed\n",
            "90.32515141855276 % completed\n",
            "90.34109021357985 % completed\n",
            "90.35702900860694 % completed\n",
            "90.37296780363404 % completed\n",
            "90.38890659866114 % completed\n",
            "90.40484539368823 % completed\n",
            "90.42078418871533 % completed\n",
            "90.43672298374243 % completed\n",
            "90.45266177876952 % completed\n",
            "90.46860057379662 % completed\n",
            "90.48453936882372 % completed\n",
            "90.50047816385081 % completed\n",
            "90.51641695887791 % completed\n",
            "90.53235575390501 % completed\n",
            "90.5482945489321 % completed\n",
            "90.5642333439592 % completed\n",
            "90.5801721389863 % completed\n",
            "90.59611093401338 % completed\n",
            "90.61204972904048 % completed\n",
            "90.62798852406758 % completed\n",
            "90.64392731909467 % completed\n",
            "90.65986611412177 % completed\n",
            "90.67580490914887 % completed\n",
            "90.69174370417596 % completed\n",
            "90.70768249920306 % completed\n",
            "90.72362129423016 % completed\n",
            "90.73956008925725 % completed\n",
            "90.75549888428435 % completed\n",
            "90.77143767931145 % completed\n",
            "90.78737647433854 % completed\n",
            "90.80331526936564 % completed\n",
            "90.81925406439274 % completed\n",
            "90.83519285941983 % completed\n",
            "90.85113165444692 % completed\n",
            "90.86707044947401 % completed\n",
            "90.88300924450111 % completed\n",
            "90.89894803952821 % completed\n",
            "90.9148868345553 % completed\n",
            "90.9308256295824 % completed\n",
            "90.9467644246095 % completed\n",
            "90.9627032196366 % completed\n",
            "90.97864201466369 % completed\n",
            "90.99458080969079 % completed\n",
            "91.01051960471789 % completed\n",
            "91.02645839974498 % completed\n",
            "91.04239719477208 % completed\n",
            "91.05833598979918 % completed\n",
            "91.07427478482627 % completed\n",
            "91.09021357985337 % completed\n",
            "91.10615237488047 % completed\n",
            "91.12209116990755 % completed\n",
            "91.13802996493465 % completed\n",
            "91.15396875996174 % completed\n",
            "91.16990755498884 % completed\n",
            "91.18584635001594 % completed\n",
            "91.20178514504303 % completed\n",
            "91.21772394007013 % completed\n",
            "91.23366273509723 % completed\n",
            "91.24960153012432 % completed\n",
            "91.26554032515142 % completed\n",
            "91.28147912017852 % completed\n",
            "91.29741791520561 % completed\n",
            "91.31335671023271 % completed\n",
            "91.32929550525981 % completed\n",
            "91.3452343002869 % completed\n",
            "91.361173095314 % completed\n",
            "91.37711189034108 % completed\n",
            "91.39305068536818 % completed\n",
            "91.40898948039528 % completed\n",
            "91.42492827542237 % completed\n",
            "91.44086707044947 % completed\n",
            "91.45680586547657 % completed\n",
            "91.47274466050366 % completed\n",
            "91.48868345553076 % completed\n",
            "91.50462225055786 % completed\n",
            "91.52056104558496 % completed\n",
            "91.53649984061205 % completed\n",
            "91.55243863563915 % completed\n",
            "91.56837743066625 % completed\n",
            "91.58431622569334 % completed\n",
            "91.60025502072044 % completed\n",
            "91.61619381574754 % completed\n",
            "91.63213261077462 % completed\n",
            "91.64807140580172 % completed\n",
            "91.66401020082881 % completed\n",
            "91.67994899585591 % completed\n",
            "91.695887790883 % completed\n",
            "91.7118265859101 % completed\n",
            "91.7277653809372 % completed\n",
            "91.7437041759643 % completed\n",
            "91.7596429709914 % completed\n",
            "91.77558176601849 % completed\n",
            "91.79152056104559 % completed\n",
            "91.80745935607268 % completed\n",
            "91.82339815109978 % completed\n",
            "91.83933694612688 % completed\n",
            "91.85527574115397 % completed\n",
            "91.87121453618107 % completed\n",
            "91.88715333120815 % completed\n",
            "91.90309212623525 % completed\n",
            "91.91903092126235 % completed\n",
            "91.93496971628944 % completed\n",
            "91.95090851131654 % completed\n",
            "91.96684730634364 % completed\n",
            "91.98278610137073 % completed\n",
            "91.99872489639783 % completed\n",
            "92.01466369142493 % completed\n",
            "92.03060248645203 % completed\n",
            "92.04654128147912 % completed\n",
            "92.06248007650622 % completed\n",
            "92.07841887153332 % completed\n",
            "92.09435766656041 % completed\n",
            "92.11029646158751 % completed\n",
            "92.1262352566146 % completed\n",
            "92.14217405164169 % completed\n",
            "92.15811284666879 % completed\n",
            "92.17405164169588 % completed\n",
            "92.18999043672298 % completed\n",
            "92.20592923175008 % completed\n",
            "92.22186802677717 % completed\n",
            "92.23780682180427 % completed\n",
            "92.25374561683137 % completed\n",
            "92.26968441185846 % completed\n",
            "92.28562320688556 % completed\n",
            "92.30156200191266 % completed\n",
            "92.31750079693975 % completed\n",
            "92.33343959196685 % completed\n",
            "92.34937838699395 % completed\n",
            "92.36531718202104 % completed\n",
            "92.38125597704814 % completed\n",
            "92.39719477207522 % completed\n",
            "92.41313356710232 % completed\n",
            "92.42907236212942 % completed\n",
            "92.44501115715651 % completed\n",
            "92.46094995218361 % completed\n",
            "92.47688874721071 % completed\n",
            "92.4928275422378 % completed\n",
            "92.5087663372649 % completed\n",
            "92.524705132292 % completed\n",
            "92.5406439273191 % completed\n",
            "92.55658272234619 % completed\n",
            "92.57252151737329 % completed\n",
            "92.58846031240039 % completed\n",
            "92.60439910742748 % completed\n",
            "92.62033790245458 % completed\n",
            "92.63627669748168 % completed\n",
            "92.65221549250877 % completed\n",
            "92.66815428753586 % completed\n",
            "92.68409308256295 % completed\n",
            "92.70003187759005 % completed\n",
            "92.71597067261715 % completed\n",
            "92.73190946764424 % completed\n",
            "92.74784826267134 % completed\n",
            "92.76378705769844 % completed\n",
            "92.77972585272553 % completed\n",
            "92.79566464775263 % completed\n",
            "92.81160344277973 % completed\n",
            "92.82754223780682 % completed\n",
            "92.84348103283392 % completed\n",
            "92.85941982786102 % completed\n",
            "92.87535862288811 % completed\n",
            "92.89129741791521 % completed\n",
            "92.90723621294231 % completed\n",
            "92.92317500796939 % completed\n",
            "92.93911380299649 % completed\n",
            "92.95505259802358 % completed\n",
            "92.97099139305068 % completed\n",
            "92.98693018807778 % completed\n",
            "93.00286898310488 % completed\n",
            "93.01880777813197 % completed\n",
            "93.03474657315907 % completed\n",
            "93.05068536818617 % completed\n",
            "93.06662416321326 % completed\n",
            "93.08256295824036 % completed\n",
            "93.09850175326746 % completed\n",
            "93.11444054829455 % completed\n",
            "93.13037934332165 % completed\n",
            "93.14631813834875 % completed\n",
            "93.16225693337584 % completed\n",
            "93.17819572840293 % completed\n",
            "93.19413452343002 % completed\n",
            "93.21007331845712 % completed\n",
            "93.22601211348422 % completed\n",
            "93.24195090851131 % completed\n",
            "93.25788970353841 % completed\n",
            "93.2738284985655 % completed\n",
            "93.2897672935926 % completed\n",
            "93.3057060886197 % completed\n",
            "93.3216448836468 % completed\n",
            "93.3375836786739 % completed\n",
            "93.35352247370099 % completed\n",
            "93.36946126872809 % completed\n",
            "93.38540006375518 % completed\n",
            "93.40133885878228 % completed\n",
            "93.41727765380938 % completed\n",
            "93.43321644883646 % completed\n",
            "93.44915524386356 % completed\n",
            "93.46509403889065 % completed\n",
            "93.48103283391775 % completed\n",
            "93.49697162894485 % completed\n",
            "93.51291042397195 % completed\n",
            "93.52884921899904 % completed\n",
            "93.54478801402614 % completed\n",
            "93.56072680905324 % completed\n",
            "93.57666560408033 % completed\n",
            "93.59260439910743 % completed\n",
            "93.60854319413453 % completed\n",
            "93.62448198916162 % completed\n",
            "93.64042078418872 % completed\n",
            "93.65635957921582 % completed\n",
            "93.67229837424291 % completed\n",
            "93.68823716927 % completed\n",
            "93.7041759642971 % completed\n",
            "93.72011475932419 % completed\n",
            "93.73605355435129 % completed\n",
            "93.75199234937838 % completed\n",
            "93.76793114440548 % completed\n",
            "93.78386993943258 % completed\n",
            "93.79980873445967 % completed\n",
            "93.81574752948677 % completed\n",
            "93.83168632451387 % completed\n",
            "93.84762511954096 % completed\n",
            "93.86356391456806 % completed\n",
            "93.87950270959516 % completed\n",
            "93.89544150462226 % completed\n",
            "93.91138029964935 % completed\n",
            "93.92731909467645 % completed\n",
            "93.94325788970355 % completed\n",
            "93.95919668473063 % completed\n",
            "93.97513547975772 % completed\n",
            "93.99107427478482 % completed\n",
            "94.00701306981192 % completed\n",
            "94.02295186483902 % completed\n",
            "94.03889065986611 % completed\n",
            "94.05482945489321 % completed\n",
            "94.0707682499203 % completed\n",
            "94.0867070449474 % completed\n",
            "94.1026458399745 % completed\n",
            "94.1185846350016 % completed\n",
            "94.1345234300287 % completed\n",
            "94.15046222505579 % completed\n",
            "94.16640102008289 % completed\n",
            "94.18233981510998 % completed\n",
            "94.19827861013708 % completed\n",
            "94.21421740516416 % completed\n",
            "94.23015620019126 % completed\n",
            "94.24609499521836 % completed\n",
            "94.26203379024545 % completed\n",
            "94.27797258527255 % completed\n",
            "94.29391138029965 % completed\n",
            "94.30985017532674 % completed\n",
            "94.32578897035384 % completed\n",
            "94.34172776538094 % completed\n",
            "94.35766656040803 % completed\n",
            "94.37360535543513 % completed\n",
            "94.38954415046223 % completed\n",
            "94.40548294548933 % completed\n",
            "94.42142174051642 % completed\n",
            "94.43736053554352 % completed\n",
            "94.45329933057062 % completed\n",
            "94.4692381255977 % completed\n",
            "94.4851769206248 % completed\n",
            "94.50111571565189 % completed\n",
            "94.51705451067899 % completed\n",
            "94.53299330570609 % completed\n",
            "94.54893210073318 % completed\n",
            "94.56487089576028 % completed\n",
            "94.58080969078738 % completed\n",
            "94.59674848581447 % completed\n",
            "94.61268728084157 % completed\n",
            "94.62862607586867 % completed\n",
            "94.64456487089576 % completed\n",
            "94.66050366592286 % completed\n",
            "94.67644246094996 % completed\n",
            "94.69238125597705 % completed\n",
            "94.70832005100415 % completed\n",
            "94.72425884603123 % completed\n",
            "94.74019764105833 % completed\n",
            "94.75613643608543 % completed\n",
            "94.77207523111252 % completed\n",
            "94.78801402613962 % completed\n",
            "94.80395282116672 % completed\n",
            "94.81989161619381 % completed\n",
            "94.83583041122091 % completed\n",
            "94.85176920624801 % completed\n",
            "94.8677080012751 % completed\n",
            "94.8836467963022 % completed\n",
            "94.8995855913293 % completed\n",
            "94.9155243863564 % completed\n",
            "94.93146318138349 % completed\n",
            "94.94740197641059 % completed\n",
            "94.96334077143769 % completed\n",
            "94.97927956646477 % completed\n",
            "94.99521836149187 % completed\n",
            "95.01115715651896 % completed\n",
            "95.02709595154606 % completed\n",
            "95.04303474657316 % completed\n",
            "95.05897354160025 % completed\n",
            "95.07491233662735 % completed\n",
            "95.09085113165445 % completed\n",
            "95.10678992668154 % completed\n",
            "95.12272872170864 % completed\n",
            "95.13866751673574 % completed\n",
            "95.15460631176283 % completed\n",
            "95.17054510678993 % completed\n",
            "95.18648390181703 % completed\n",
            "95.20242269684412 % completed\n",
            "95.21836149187122 % completed\n",
            "95.2343002868983 % completed\n",
            "95.2502390819254 % completed\n",
            "95.2661778769525 % completed\n",
            "95.2821166719796 % completed\n",
            "95.29805546700669 % completed\n",
            "95.31399426203379 % completed\n",
            "95.32993305706088 % completed\n",
            "95.34587185208798 % completed\n",
            "95.36181064711508 % completed\n",
            "95.37774944214217 % completed\n",
            "95.39368823716927 % completed\n",
            "95.40962703219637 % completed\n",
            "95.42556582722347 % completed\n",
            "95.44150462225056 % completed\n",
            "95.45744341727766 % completed\n",
            "95.47338221230476 % completed\n",
            "95.48932100733185 % completed\n",
            "95.50525980235894 % completed\n",
            "95.52119859738603 % completed\n",
            "95.53713739241313 % completed\n",
            "95.55307618744023 % completed\n",
            "95.56901498246732 % completed\n",
            "95.58495377749442 % completed\n",
            "95.60089257252152 % completed\n",
            "95.61683136754861 % completed\n",
            "95.63277016257571 % completed\n",
            "95.6487089576028 % completed\n",
            "95.6646477526299 % completed\n",
            "95.680586547657 % completed\n",
            "95.6965253426841 % completed\n",
            "95.7124641377112 % completed\n",
            "95.72840293273829 % completed\n",
            "95.74434172776539 % completed\n",
            "95.76028052279247 % completed\n",
            "95.77621931781957 % completed\n",
            "95.79215811284666 % completed\n",
            "95.80809690787376 % completed\n",
            "95.82403570290086 % completed\n",
            "95.83997449792795 % completed\n",
            "95.85591329295505 % completed\n",
            "95.87185208798215 % completed\n",
            "95.88779088300925 % completed\n",
            "95.90372967803634 % completed\n",
            "95.91966847306344 % completed\n",
            "95.93560726809054 % completed\n",
            "95.95154606311763 % completed\n",
            "95.96748485814473 % completed\n",
            "95.98342365317183 % completed\n",
            "95.99936244819892 % completed\n",
            "96.015301243226 % completed\n",
            "96.0312400382531 % completed\n",
            "96.0471788332802 % completed\n",
            "96.0631176283073 % completed\n",
            "96.07905642333439 % completed\n",
            "96.09499521836149 % completed\n",
            "96.11093401338859 % completed\n",
            "96.12687280841568 % completed\n",
            "96.14281160344278 % completed\n",
            "96.15875039846988 % completed\n",
            "96.17468919349697 % completed\n",
            "96.19062798852407 % completed\n",
            "96.20656678355117 % completed\n",
            "96.22250557857826 % completed\n",
            "96.23844437360536 % completed\n",
            "96.25438316863246 % completed\n",
            "96.27032196365954 % completed\n",
            "96.28626075868664 % completed\n",
            "96.30219955371373 % completed\n",
            "96.31813834874083 % completed\n",
            "96.33407714376793 % completed\n",
            "96.35001593879502 % completed\n",
            "96.36595473382212 % completed\n",
            "96.38189352884922 % completed\n",
            "96.39783232387632 % completed\n",
            "96.41377111890341 % completed\n",
            "96.42970991393051 % completed\n",
            "96.4456487089576 % completed\n",
            "96.4615875039847 % completed\n",
            "96.4775262990118 % completed\n",
            "96.4934650940389 % completed\n",
            "96.509403889066 % completed\n",
            "96.52534268409308 % completed\n",
            "96.54128147912017 % completed\n",
            "96.55722027414727 % completed\n",
            "96.57315906917437 % completed\n",
            "96.58909786420146 % completed\n",
            "96.60503665922856 % completed\n",
            "96.62097545425566 % completed\n",
            "96.63691424928275 % completed\n",
            "96.65285304430985 % completed\n",
            "96.66879183933695 % completed\n",
            "96.68473063436404 % completed\n",
            "96.70066942939114 % completed\n",
            "96.71660822441824 % completed\n",
            "96.73254701944533 % completed\n",
            "96.74848581447243 % completed\n",
            "96.76442460949953 % completed\n",
            "96.78036340452661 % completed\n",
            "96.79630219955371 % completed\n",
            "96.8122409945808 % completed\n",
            "96.8281797896079 % completed\n",
            "96.844118584635 % completed\n",
            "96.8600573796621 % completed\n",
            "96.87599617468919 % completed\n",
            "96.89193496971629 % completed\n",
            "96.90787376474339 % completed\n",
            "96.92381255977048 % completed\n",
            "96.93975135479758 % completed\n",
            "96.95569014982468 % completed\n",
            "96.97162894485177 % completed\n",
            "96.98756773987887 % completed\n",
            "97.00350653490597 % completed\n",
            "97.01944532993306 % completed\n",
            "97.03538412496016 % completed\n",
            "97.05132291998724 % completed\n",
            "97.06726171501434 % completed\n",
            "97.08320051004144 % completed\n",
            "97.09913930506853 % completed\n",
            "97.11507810009563 % completed\n",
            "97.13101689512273 % completed\n",
            "97.14695569014982 % completed\n",
            "97.16289448517692 % completed\n",
            "97.17883328020402 % completed\n",
            "97.19477207523111 % completed\n",
            "97.21071087025821 % completed\n",
            "97.22664966528531 % completed\n",
            "97.2425884603124 % completed\n",
            "97.2585272553395 % completed\n",
            "97.2744660503666 % completed\n",
            "97.2904048453937 % completed\n",
            "97.30634364042078 % completed\n",
            "97.32228243544787 % completed\n",
            "97.33822123047497 % completed\n",
            "97.35416002550207 % completed\n",
            "97.37009882052917 % completed\n",
            "97.38603761555626 % completed\n",
            "97.40197641058336 % completed\n",
            "97.41791520561046 % completed\n",
            "97.43385400063755 % completed\n",
            "97.44979279566465 % completed\n",
            "97.46573159069175 % completed\n",
            "97.48167038571884 % completed\n",
            "97.49760918074594 % completed\n",
            "97.51354797577304 % completed\n",
            "97.52948677080013 % completed\n",
            "97.54542556582723 % completed\n",
            "97.56136436085431 % completed\n",
            "97.57730315588141 % completed\n",
            "97.5932419509085 % completed\n",
            "97.6091807459356 % completed\n",
            "97.6251195409627 % completed\n",
            "97.6410583359898 % completed\n",
            "97.6569971310169 % completed\n",
            "97.67293592604399 % completed\n",
            "97.68887472107109 % completed\n",
            "97.70481351609818 % completed\n",
            "97.72075231112528 % completed\n",
            "97.73669110615238 % completed\n",
            "97.75262990117947 % completed\n",
            "97.76856869620657 % completed\n",
            "97.78450749123367 % completed\n",
            "97.80044628626077 % completed\n",
            "97.81638508128785 % completed\n",
            "97.83232387631494 % completed\n",
            "97.84826267134204 % completed\n",
            "97.86420146636914 % completed\n",
            "97.88014026139624 % completed\n",
            "97.89607905642333 % completed\n",
            "97.91201785145043 % completed\n",
            "97.92795664647753 % completed\n",
            "97.94389544150462 % completed\n",
            "97.95983423653172 % completed\n",
            "97.97577303155882 % completed\n",
            "97.99171182658591 % completed\n",
            "98.00765062161301 % completed\n",
            "98.0235894166401 % completed\n",
            "98.0395282116672 % completed\n",
            "98.0554670066943 % completed\n",
            "98.07140580172138 % completed\n",
            "98.08734459674848 % completed\n",
            "98.10328339177558 % completed\n",
            "98.11922218680267 % completed\n",
            "98.13516098182977 % completed\n",
            "98.15109977685687 % completed\n",
            "98.16703857188396 % completed\n",
            "98.18297736691106 % completed\n",
            "98.19891616193816 % completed\n",
            "98.21485495696525 % completed\n",
            "98.23079375199235 % completed\n",
            "98.24673254701945 % completed\n",
            "98.26267134204654 % completed\n",
            "98.27861013707364 % completed\n",
            "98.29454893210074 % completed\n",
            "98.31048772712784 % completed\n",
            "98.32642652215492 % completed\n",
            "98.34236531718201 % completed\n",
            "98.35830411220911 % completed\n",
            "98.37424290723621 % completed\n",
            "98.3901817022633 % completed\n",
            "98.4061204972904 % completed\n",
            "98.4220592923175 % completed\n",
            "98.4379980873446 % completed\n",
            "98.45393688237169 % completed\n",
            "98.46987567739879 % completed\n",
            "98.48581447242589 % completed\n",
            "98.50175326745298 % completed\n",
            "98.51769206248008 % completed\n",
            "98.53363085750718 % completed\n",
            "98.54956965253427 % completed\n",
            "98.56550844756137 % completed\n",
            "98.58144724258847 % completed\n",
            "98.59738603761555 % completed\n",
            "98.61332483264265 % completed\n",
            "98.62926362766974 % completed\n",
            "98.64520242269684 % completed\n",
            "98.66114121772394 % completed\n",
            "98.67708001275103 % completed\n",
            "98.69301880777813 % completed\n",
            "98.70895760280523 % completed\n",
            "98.72489639783232 % completed\n",
            "98.74083519285942 % completed\n",
            "98.75677398788652 % completed\n",
            "98.77271278291362 % completed\n",
            "98.78865157794071 % completed\n",
            "98.80459037296781 % completed\n",
            "98.8205291679949 % completed\n",
            "98.836467963022 % completed\n",
            "98.85240675804909 % completed\n",
            "98.86834555307618 % completed\n",
            "98.88428434810328 % completed\n",
            "98.90022314313038 % completed\n",
            "98.91616193815747 % completed\n",
            "98.93210073318457 % completed\n",
            "98.94803952821167 % completed\n",
            "98.96397832323876 % completed\n",
            "98.97991711826586 % completed\n",
            "98.99585591329296 % completed\n",
            "99.01179470832005 % completed\n",
            "99.02773350334715 % completed\n",
            "99.04367229837425 % completed\n",
            "99.05961109340134 % completed\n",
            "99.07554988842844 % completed\n",
            "99.09148868345554 % completed\n",
            "99.10742747848262 % completed\n",
            "99.12336627350972 % completed\n",
            "99.13930506853681 % completed\n",
            "99.15524386356391 % completed\n",
            "99.17118265859101 % completed\n",
            "99.1871214536181 % completed\n",
            "99.2030602486452 % completed\n",
            "99.2189990436723 % completed\n",
            "99.2349378386994 % completed\n",
            "99.25087663372649 % completed\n",
            "99.26681542875359 % completed\n",
            "99.28275422378069 % completed\n",
            "99.29869301880778 % completed\n",
            "99.31463181383488 % completed\n",
            "99.33057060886198 % completed\n",
            "99.34650940388907 % completed\n",
            "99.36244819891616 % completed\n",
            "99.37838699394325 % completed\n",
            "99.39432578897035 % completed\n",
            "99.41026458399745 % completed\n",
            "99.42620337902454 % completed\n",
            "99.44214217405164 % completed\n",
            "99.45808096907874 % completed\n",
            "99.47401976410583 % completed\n",
            "99.48995855913293 % completed\n",
            "99.50589735416003 % completed\n",
            "99.52183614918712 % completed\n",
            "99.53777494421422 % completed\n",
            "99.55371373924132 % completed\n",
            "99.56965253426841 % completed\n",
            "99.58559132929551 % completed\n",
            "99.60153012432261 % completed\n",
            "99.61746891934969 % completed\n",
            "99.63340771437679 % completed\n",
            "99.64934650940388 % completed\n",
            "99.66528530443098 % completed\n",
            "99.68122409945808 % completed\n",
            "99.69716289448517 % completed\n",
            "99.71310168951227 % completed\n",
            "99.72904048453937 % completed\n",
            "99.74497927956646 % completed\n",
            "99.76091807459356 % completed\n",
            "99.77685686962066 % completed\n",
            "99.79279566464776 % completed\n",
            "99.80873445967485 % completed\n",
            "99.82467325470195 % completed\n",
            "99.84061204972905 % completed\n",
            "99.85655084475614 % completed\n",
            "99.87248963978323 % completed\n",
            "99.88842843481032 % completed\n",
            "99.90436722983742 % completed\n",
            "99.92030602486452 % completed\n",
            "99.93624481989161 % completed\n",
            "99.95218361491871 % completed\n",
            "99.9681224099458 % completed\n",
            "99.9840612049729 % completed\n",
            "44.54545454545455\n",
            "88.125\n",
            "0.0013073882832918976\n",
            "{'ौ', 'એ', 'ધ', 'ં', 'હ', 'આ', 'ચ', 'ઈ', 'મ', 'ડ', 'ज', 'િ', 'થ', 'ૈ', 'ર', 'ા', 'झ', 'र', 'ત', 'ो', 'ક', 'ય', 'ન', 'ુ', 'ી'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfxI8hKjWXp-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "b575521f-0245-4636-8fee-aa3e88c05527"
      },
      "source": [
        "mismatch_pair"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'અ', 'આ'},\n",
              " {'ડ', 'દ'},\n",
              " {'ચ', 'ય'},\n",
              " {'ઢ', 'ધ'},\n",
              " {'િ', 'ી'},\n",
              " {'ં', 'ક'},\n",
              " {'ક', '્'},\n",
              " {'િ', 'ી'},\n",
              " {'ઇ', 'ૈ'},\n",
              " {'ઠ', 'થ'},\n",
              " {'ज', 'જ'},\n",
              " {'झ', 'હ'},\n",
              " {'र', 'ર'},\n",
              " {'ચ', 'ય'},\n",
              " {'ौ', 'ૌ'},\n",
              " {'ુ', 'ૂ'},\n",
              " {'ક', 'ખ'},\n",
              " {'ो', 'ો'},\n",
              " {'િ', 'ી'},\n",
              " {'ઇ', 'ઈ'},\n",
              " {'ક', 'ખ'},\n",
              " {'ઍ', 'એ'},\n",
              " {'અ', 'આ'},\n",
              " {'ં', 'હ'},\n",
              " {'મ', 'હ'},\n",
              " {'મ', 'ા'},\n",
              " {'ર', 'ા'},\n",
              " {'ર', 'ા'},\n",
              " {'ત', '્'},\n",
              " {'ત', 'ા'},\n",
              " {'હ', 'ા'},\n",
              " {'હ', 'ા'},\n",
              " {'ઈ', 'ૈ'},\n",
              " {'ર', 'ા'},\n",
              " {'ર', 'ા'},\n",
              " {'ડ', 'દ'},\n",
              " {'િ', 'ી'},\n",
              " {'ણ', 'ન'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RqQ1fIsLwkGE"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this tutorial, you learned about positional encoding, multi-head attention, the importance of masking and how to create a transformer.\n",
        "\n",
        "Try using a different dataset to train the transformer. You can also create the base transformer or transformer XL by changing the hyperparameters above. You can also use the layers defined here to create [BERT](https://arxiv.org/abs/1810.04805) and train state of the art models. Futhermore, you can implement beam search to get better predictions."
      ]
    }
  ]
}