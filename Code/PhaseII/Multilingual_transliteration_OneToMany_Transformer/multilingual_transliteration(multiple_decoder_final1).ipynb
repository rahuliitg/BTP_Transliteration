{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multilingual_transliteration(multiple_decoder_final1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s_qNSzzyaCbD"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "jmjh290raIky",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In3atWTB_TFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "# Transformer model for language understanding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AOpGoE2T-YXS"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/text/transformer\">\n",
        "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
        "    View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/text/transformer.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M-f8TnGpE_ex"
      },
      "source": [
        "This tutorial trains a <a href=\"https://arxiv.org/abs/1706.03762\" class=\"external\">Transformer model</a> to translate Portuguese to English. This is an advanced example that assumes knowledge of [text generation](text_generation.ipynb) and [attention](nmt_with_attention.ipynb).\n",
        "\n",
        "The core idea behind the Transformer model is *self-attention*—the ability to attend to different positions of the input sequence to compute a representation of that sequence. Transformer creates stacks of self-attention layers and is explained below in the sections *Scaled dot product attention* and *Multi-head attention*.\n",
        "\n",
        "A transformer model handles variable-sized input using stacks of self-attention layers instead of [RNNs](text_classification_rnn.ipynb) or [CNNs](../images/intro_to_cnns.ipynb). This general architecture has a number of advantages:\n",
        "\n",
        "* It make no assumptions about the temporal/spatial relationships across the data. This is ideal for processing a set of objects (for example, [StarCraft units](https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/#block-8)).\n",
        "* Layer outputs can be calculated in parallel, instead of a series like an RNN.\n",
        "* Distant items can affect each other's output without passing through many RNN-steps, or convolution layers (see [Scene Memory Transformer](https://arxiv.org/pdf/1903.03878.pdf) for example).\n",
        "* It can learn long-range dependencies. This is a challenge in many sequence tasks.\n",
        "\n",
        "The downsides of this architecture are:\n",
        "\n",
        "* For a time-series, the output for a time-step is calculated from the *entire history* instead of only the inputs and current hidden-state. This _may_ be less efficient.   \n",
        "* If the input *does* have a  temporal/spatial relationship, like text, some positional encoding must be added or the model will effectively see a bag of words. \n",
        "\n",
        "After training the model in this notebook, you will be able to input a Portuguese sentence and return the English translation.\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/attention_map_portuguese.png\" width=\"800\" alt=\"Attention heatmap\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JjJJyJTZYebt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "37410957-be39-4e25-87ea-74204c4ec8a3"
      },
      "source": [
        "!pip install tf-nightly\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/97/9b00d0c08e2b84ab261931d5474e4bc3af05a8b2a2706e14fe5d9ea708b4/tf_nightly-2.2.0.dev20200508-cp36-cp36m-manylinux2010_x86_64.whl (521.9MB)\n",
            "\u001b[K     |████████████████████████████████| 521.9MB 38kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.3.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.28.1)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.4.1)\n",
            "Collecting tb-nightly<2.4.0a0,>=2.3.0a0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/2d/436a8addb5b16877281565bec361dae58bc62c30a0279f020532ff81753a/tb_nightly-2.3.0a20200511-py3-none-any.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 39.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.10.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.34.2)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.18.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.0)\n",
            "Collecting tf-estimator-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/4c/6c7fb51e50b44cce25df56926046be37b5303e7d0270b376ddb880cd10a7/tf_estimator_nightly-2.3.0.dev2020051201-py2.py3-none-any.whl (456kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 36.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.2.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tf-nightly) (46.1.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.2.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.6.0.post3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.7.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.4.8)\n",
            "Installing collected packages: tb-nightly, tf-estimator-nightly, tf-nightly\n",
            "Successfully installed tb-nightly-2.3.0a20200511 tf-estimator-nightly-2.3.0.dev2020051201 tf-nightly-2.2.0.dev20200508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bsj_rfWL1AVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fd1NWMxjfsDd"
      },
      "source": [
        "## Setup input pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_yvkorBxWW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BECywymNFZ_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getdata(link):\n",
        "  fluff, id = link.split('=')\n",
        "  downloaded = drive.CreateFile({'id':id}) \n",
        "  downloaded.GetContentFile('Filename.txt')  \n",
        "  df = open('Filename.txt', 'rb').read().decode(encoding='utf-8')\n",
        "  df = df.split('\\n')\n",
        "  df2 = []\n",
        "  for line in df:\n",
        "    if line != '':\n",
        "      g = line.split(\"\\t\")\n",
        "      df2.append(g[0])\n",
        "      df2.append(g[1])\n",
        "  return df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIE97c-pFpg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_bangla_trn = getdata('https://drive.google.com/open?id=1sTCskB7TMC5V6tnygw9GhYCvF7tggnqO')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmFhroN_GX0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_bangla_dev = getdata('https://drive.google.com/open?id=1r6oDvbBD16mcbpolSJi5uZ6bsxdz-moT')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aar70T8XGbEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_hindi_trn = getdata('https://drive.google.com/open?id=1VGrFZznZR4wtfiKDMLINuVKNPkuFBg8k')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsO_ScphGb_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_hindi_dev = getdata('https://drive.google.com/open?id=1-i5kHiZNkI75E_DaRuduIZ6PBYi9bgL_')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4TQIJwyOweP",
        "colab_type": "text"
      },
      "source": [
        " **Cleaning the data** (removing extra spaces, punctuations)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9V2Xf0LoacO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwr3eg42p_tm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extra_str = '0123456789'\n",
        "chars = set(extra_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCHtZmvUG_YT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cleandata(data):\n",
        "  g = []\n",
        "  sz = 0\n",
        "  for s in data:\n",
        "    q = s.translate(str.maketrans('', '', string.punctuation))\n",
        "    q = q.translate(str.maketrans('','',extra_str))\n",
        "    q = q.translate(str.maketrans('', '', '\\u200d'))\n",
        "    g.append(q)\n",
        "    if len(q) != s:\n",
        "      sz= sz+1\n",
        "  print(sz)\n",
        "  return g"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4MmAJ7sO7kv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d8df43fe-fed0-499c-d3b7-8310c915ee65"
      },
      "source": [
        "df_hindi_trn = cleandata(df_hindi_trn)\n",
        "df_hindi_dev = cleandata(df_hindi_dev)\n",
        "df_bangla_trn = cleandata(df_bangla_trn)\n",
        "df_bangla_dev = cleandata(df_bangla_dev)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25874\n",
            "2000\n",
            "27246\n",
            "2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxvuLuyF-6k6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataf = []\n",
        "special_words =[]\n",
        "dataf.append(df_hindi_trn)\n",
        "dataf.append(df_bangla_trn)\n",
        "special_words.append('$')\n",
        "special_words.append('%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihP5VkYTIJ7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataf_test = []\n",
        "dataf_test.append(df_hindi_dev)\n",
        "dataf_test.append(df_bangla_dev)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMCZxP6kyzBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessWord(list,start):\n",
        "  modifList = []\n",
        "  for w in list:\n",
        "    w = start+w.lower()+\"@\"\n",
        "    modifList.append(w)\n",
        "  return modifList\n",
        "\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_texts_test = []\n",
        "target_texts_test = []\n",
        "\n",
        "for d1,d2,s in zip(dataf,dataf_test,special_words):\n",
        "  input_texts.append(preprocessWord(d1[0::2],s))\n",
        "  target_texts.append(preprocessWord(d1[1::2],s))\n",
        "  input_texts_test.append(preprocessWord(d2[0::2],s))\n",
        "  target_texts_test.append(preprocessWord(d2[1::2],s))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eW-3JcGwLe5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lang_size_tst = []\n",
        "for x in input_texts_test:\n",
        "  lang_size_tst.append(len(x))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KD4zAKO95MX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mergeinput(input_texts,target_texts):\n",
        "  input_temp = []\n",
        "  target_temp = []\n",
        "  lang_size_trn = []\n",
        "\n",
        "  for input_text,target_text in zip(input_texts,target_texts):\n",
        "    sz = 0\n",
        "    for i in range(len(input_text)):\n",
        "      no_of_spaces = 0\n",
        "      for w in input_text[i]:\n",
        "        if(w == ' '):\n",
        "          no_of_spaces += 1\n",
        "      for w in target_text[i]:\n",
        "        if(w == ' '):\n",
        "          no_of_spaces -= 1\n",
        "      if(no_of_spaces != 0 ):\n",
        "        print(input_text[i] +\" -> \"+target_text[i])\n",
        "      elif(len(input_text[i]) <= 25 and len(target_text[i]) <= 30):\n",
        "          input_temp.append(input_text[i])\n",
        "          target_temp.append(target_text[i])\n",
        "          sz += 1\n",
        "    lang_size_trn.append(sz)\n",
        "\n",
        "  iptxt = input_texts\n",
        "  trgtxt = target_texts\n",
        "  input_text = input_temp\n",
        "  target_text = target_temp\n",
        "  return input_text,target_text,lang_size_trn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOeZDloOUDnd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b9e303f8-8967-4f70-e950-5062d27077cc"
      },
      "source": [
        "def shuffle_in_unison(a, b):\n",
        "    rng_state = np.random.get_state()\n",
        "    np.random.shuffle(a)\n",
        "    np.random.set_state(rng_state)\n",
        "    np.random.shuffle(b)\n",
        "# no. of languages  = 2 (hindi, bangla)\n",
        "shuffle_in_unison(input_texts[0], target_texts[0])\n",
        "shuffle_in_unison(input_texts[1], target_texts[1])\n",
        "input_text,target_text,lang_size_trn = mergeinput(input_texts,target_texts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "$vaparaiso church of christ@ -> $व्हापरासिओ@\n",
            "$changez khan@ -> $चंगेज़ खानचंगेज़ खान@\n",
            "$envoy communications group@ -> $एन्वॉय कम्युनिकेशंस@\n",
            "$south arlington church of christ@ -> $साउथ अर्लिंग्टन@\n",
            "$order of vasa@ -> $ऑडर ऑफ़ द वासा@\n",
            "$retalix@ -> $रेटालिक्स लि@\n",
            "$srisailam@ -> $श्री शैलम@\n",
            "$rama lingeshwara@ -> $रामालिंगेश्वर@\n",
            "$sea of the hebrides@ -> $सी ऑफ हरब्रिड्स@\n",
            "$wind river@ -> $विंडरिवर@\n",
            "$paris charles de gaulle@ -> $पेरिस रॉसे चार्ल्स डे ग्यूले@\n",
            "$theodore roosevelt@ -> $थियोडोर रूजवेल्टथीओडोर रूज़वेल्ट@\n",
            "$walter scott@ -> $वॉल्टरस्कॉट@\n",
            "$rediffcom india limited@ -> $रेडिफ़ डॉट कॉम इंडिया लिमिटेड@\n",
            "$ramcoind@ -> $राम्को इंड@\n",
            "$gothenburg landvetter@ -> $गॉथेनबर्गलेंडवेटर@\n",
            "$ronald reagan@ -> $रॉनाल्ड रेगनरोनाल्ड रीगन@\n",
            "$king edward vii@ -> $किंग एडवर्ड@\n",
            "$ray illingworth@ -> $रे इलिंगवर्थरे इलिंगवॉर्थ@\n",
            "$saint john the baptist high schoolthane@ -> $सेंट जॉन द बैप्टिस्ट हाई स्कूल ठाणे@\n",
            "$state bnk tr@ -> $स्टेट बैंक ऑफ त्रावणकोर@\n",
            "$westminster presbyterian@ -> $वेस्टमिनस्टर प्रेसबिटेरियनवेस्टमिनस्टर प्रेस्बिटेरियन@\n",
            "$mauna loa@ -> $मौनालोआ@\n",
            "$salman rushdie@ -> $सलमान रश्दीसायबिल शेफ़र्ड@\n",
            "$jahan aara@ -> $जहाँआरा@\n",
            "$fakhrun nisa@ -> $फखरुन्निसा@\n",
            "$bal krishna@ -> $बालकृष्णा@\n",
            "$bacardimartini india@ -> $बैकार्डी मार्टिनी इंडिया@\n",
            "$mass mutual life@ -> $मास म्युच्युअल लाइफ़ इंश्योरेंस@\n",
            "$sadiq mohammad@ -> $सदीक मोहम्मदसादिक मोहम्मद@\n",
            "$saint gobain@ -> $सेंट गॉबेनसेंट गॉबैन@\n",
            "$navabharat ferro alloys@ -> $नव भारत फ़ैरो अलॉय@\n",
            "$war of the holy league@ -> $वार ऑफ होली लीग@\n",
            "$opentv@ -> $ओपन टीवी@\n",
            "$tenerife south reina sofia@ -> $तेनेरीफ साउथरेइना सोफिया@\n",
            "$dibang valley@ -> $दिबंगवैली@\n",
            "$verrazanonarrows@ -> $वेराज़नो नॅरोज़@\n",
            "$dar es salaam@ -> $दारएसलाम@\n",
            "$robert kennedy@ -> $रॉबर्ट केनेडीरॉबर्ट कैनेडी@\n",
            "$barharwa junction@ -> $बरहरवा@\n",
            "$apna kaun @ -> $अपना कौन@\n",
            "$jose saramago@ -> $जोस सरभागोजोस सरमागो@\n",
            "$parkway apostolic@ -> $पार्क वे अपोस्टोलिक@\n",
            "$colourplus fashions@ -> $कलर प्लस फ़ैशन्स@\n",
            "$murraydarling@ -> $मुर्रे डार्लिंग@\n",
            "$netaji subhash chandra bose@ -> $नेताजी सुभाषचंद्र बोस@\n",
            "$londonheathrow@ -> $लंदन हीथ्रो@\n",
            "$new zealand@ -> $न्यूज़ीलैंड@\n",
            "$aldous huxley@ -> $अल्डुअस हक्सलेआल्डस हक्स्ले@\n",
            "$catherine zeta  jones@ -> $कैथरीन ज़ेटाजोन्स@\n",
            "$omkarnath thakur@ -> $ओंकार नाथ ठाकुर@\n",
            "$azamnagar road@ -> $आज़मनगर@\n",
            "$rockbrook united@ -> $रॉकब्रुक यूनाइटेड मेथोडिस्ट@\n",
            "$australian national university@ -> $ऑस्ट्रेलियननेशनल यूनिवर्सिटी@\n",
            "$cape town@ -> $केपटाउन@\n",
            "$kelvingrove art gallery and museum@ -> $केल्विनग्रोव आर्ट एण्ड म्युज़ियम@\n",
            "$chaitanya english medium high schooltirupathi@ -> $चैतन्य इंग्लिश मीडियम हाई स्कलू तिरुपती@\n",
            "$general electric@ -> $जनरल इलेक्टिकजनरल इलेक्ट्रिक@\n",
            "$newfoundland@ -> $न्यू फाउंडलैंड@\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPDxLGZBUQcW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d3e32216-685c-4c9f-8331-d2394b1429e2"
      },
      "source": [
        "input_text_tst,target_text_tst,lang_size_tst = mergeinput(input_texts_test,target_texts_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "$hewlett  packard@ -> $ह्यूलेटपैकर्ड@\n",
            "$stats chippac@ -> $स्टेट्सचिपपैक@\n",
            "$stoltnielsen@ -> $स्टॉल्ट निलसन@\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ilml9hGTEv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaxjlYchU1kA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combining train and test data\n",
        "input_trn_tst = input_text + input_text_tst\n",
        "target_trn_tst = target_text + target_text_tst"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdRPWEkgTjeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_vocab = sorted(set(\"\".join(input_trn_tst)))\n",
        "target_vocab = sorted(set(\"\".join(target_trn_tst)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdAc2R1aX_kN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert len(input_trn_tst) == len(target_trn_tst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwvfwsPZEmEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sz = 0;\n",
        "for x in (lang_size_trn):\n",
        "  train_sz+=x\n",
        "test_sz = 0\n",
        "for x in lang_size_tst:\n",
        "  test_sz+=x\n",
        "assert train_sz == len(input_text)\n",
        "assert train_sz == len(target_text)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZH34ZtH0Af9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a mapping from unique characters to indices in input text English\n",
        "char2idxEn = {}\n",
        "idx2charEn = {}\n",
        "char2idxEn[\"<\"] = 0\n",
        "for index, word in enumerate(input_vocab):\n",
        "      char2idxEn[word] = index + 1\n",
        "# print(char2idxEn)\n",
        "for word, index in char2idxEn.items():\n",
        "      idx2charEn[index] = word\n",
        "\n",
        "\n",
        "# Creating a mapping from unique characters to indices in input text Hindi\n",
        "char2idxHi = {}\n",
        "idx2charHi = {}\n",
        "char2idxHi[\"<\"] = 0\n",
        "for index, word in enumerate(target_vocab):\n",
        "      char2idxHi[word] = index + 1\n",
        "for word, index in char2idxHi.items():\n",
        "      idx2charHi[index] = word\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbUIfi8_0H3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getIpTextasInt(c):\n",
        "  f = np.array([ char2idxEn[i] for i in c])\n",
        "  return f\n",
        "\n",
        "def getTargTextasInt(c):\n",
        "  f = np.array([ char2idxHi[i] for i in c])\n",
        "  return f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSzz977U0LM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_text_as_int = np.array([getIpTextasInt(c) for c in input_trn_tst])\n",
        "input_char_dataset = [tf.data.Dataset.from_tensor_slices(i) for i in input_text_as_int]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPfkcaje0L-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_text_as_int = np.array([getTargTextasInt(c) for c in target_trn_tst])\n",
        "target_char_dataset = [tf.data.Dataset.from_tensor_slices(i) for i in target_text_as_int]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLBAK8J10TsH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9e641fa-9efa-4fd9-d088-5d5b1cc18799"
      },
      "source": [
        "examples_per_epoch = len(input_text)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = examples_per_epoch//BATCH_SIZE\n",
        "BUFFER_SIZE = 10000\n",
        "steps_per_epoch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "408"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKJro36t0fRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mtr7vcW80ig5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tensor = [];\n",
        "target_tensor = [];\n",
        "for i in range(0, len(input_text_as_int)):\n",
        "  input_tensor.append(tf.convert_to_tensor(input_text_as_int[i]))\n",
        "  target_tensor.append(tf.convert_to_tensor(target_text_as_int[i]))\n",
        "maxlen_inp = max(max_length(input_tensor), max_length(target_tensor));\n",
        "maxlen_targ = max(max_length(input_tensor), max_length(target_tensor));\n",
        "input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, padding='post', maxlen = maxlen_inp)\n",
        "target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, padding='post', maxlen = maxlen_targ)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRTAAgafqZ0r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5a371e9-d802-49b3-bd28-1dc1579b2e12"
      },
      "source": [
        "maxlen_inp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aJ0S_yl0vGK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9f1fb37-ff6a-409d-d42a-a5b993a229a5"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=test_sz,shuffle=False)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26150, 26150, 1976, 1976)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2JyR2j0Zo30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G28qapZV1IIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor)\n",
        "BATCH_SIZE = 64\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "embedding_dim = 512\n",
        "d_model = 128\n",
        "num_heads = 8\n",
        "input_vocab_size = len(input_vocab)+2\n",
        "target_vocab_size = len(target_vocab)+2\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train))\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True).shuffle(buffer_size= BUFFER_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nBQuibYA4n0n"
      },
      "source": [
        "## Positional encoding\n",
        "\n",
        "Since this model doesn't contain any recurrence or convolution, positional encoding is added to give the model some information about the relative position of the words in the sentence. \n",
        "\n",
        "The positional encoding vector is added to the embedding vector. Embeddings represent a token in a d-dimensional space where tokens with similar meaning will be closer to each other. But the embeddings do not encode the relative position of words in a sentence. So after adding the positional encoding, words will be closer to each other based on the *similarity of their meaning and their position in the sentence*, in the d-dimensional space.\n",
        "\n",
        "See the notebook on [positional encoding](https://github.com/tensorflow/examples/blob/master/community/en/position_encoding.ipynb) to learn more about it. The formula for calculating the positional encoding is as follows:\n",
        "\n",
        "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
        "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WhIOZjMNKujn",
        "colab": {}
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1Rz82wEs5biZ",
        "colab": {}
      },
      "source": [
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  \n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "  \n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    \n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    \n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1kLCla68EloE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "3e58ef13-24b0-48dc-b9e5-d54b25643258"
      },
      "source": [
        "pos_encoding = positional_encoding(50, 512)\n",
        "print (pos_encoding.shape)\n",
        "\n",
        "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0, 512))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 50, 512)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a_b4ou4TYqUN"
      },
      "source": [
        "## Masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s42Uydjkv0hF"
      },
      "source": [
        "Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value `0` is present: it outputs a `1` at those locations, and a `0` otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U2i8-e1s8ti9",
        "colab": {}
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  \n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A7BYeBCNvi7n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "14f06b90-5964-4860-c803-ea9563f27181"
      },
      "source": [
        "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
        "create_padding_mask(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
              "array([[[[0., 0., 1., 1., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., 1., 1.]]],\n",
              "\n",
              "\n",
              "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z0hzukDBgVom"
      },
      "source": [
        "The look-ahead mask is used to mask the future tokens in a sequence. In other words, the mask indicates which entries should not be used.\n",
        "\n",
        "This means that to predict the third word, only the first and second word will be used. Similarly to predict the fourth word, only the first, second and the third word will be used and so on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dVxS8OPI9uI0",
        "colab": {}
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yxKGuXxaBeeE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5e7e6a24-901b-44cf-9de6-6f69a0fc78e9"
      },
      "source": [
        "x = tf.random.uniform((1, 3))\n",
        "temp = create_look_ahead_mask(x.shape[1])\n",
        "temp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[0., 1., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xluDl5cXYy4y"
      },
      "source": [
        "## Scaled dot product attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vsxEE_-Wa1gF"
      },
      "source": [
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/scaled_attention.png\" width=\"500\" alt=\"scaled_dot_product_attention\">\n",
        "\n",
        "The attention function used by the transformer takes three inputs: Q (query), K (key), V (value). The equation used to calculate the attention weights is:\n",
        "\n",
        "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$\n",
        "\n",
        "The dot-product attention is scaled by a factor of square root of the depth. This is done because for large values of depth, the dot product grows large in magnitude pushing the softmax function where it has small gradients resulting in a very hard softmax. \n",
        "\n",
        "For example, consider that `Q` and `K` have a mean of 0 and variance of 1. Their matrix multiplication will have a mean of 0 and variance of `dk`. Hence, *square root of `dk`* is used for scaling (and not any other number) because the matmul of `Q` and `K` should have a mean of 0 and variance of 1, and you get a gentler softmax.\n",
        "\n",
        "The mask is multiplied with -1e9 (close to negative infinity). This is done because the mask is summed with the scaled matrix multiplication of Q and K and is applied immediately before a softmax. The goal is to zero out these cells, and large negative inputs to softmax are near zero in the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LazzUq3bJ5SH",
        "colab": {}
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead) \n",
        "  but it must be broadcastable for addition.\n",
        "  \n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable \n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "    \n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FiqETnhCkoXh"
      },
      "source": [
        "As the softmax normalization is done on K, its values decide the amount of importance given to Q.\n",
        "\n",
        "The output represents the multiplication of the attention weights and the V (value) vector. This ensures that the words you want to focus on are kept as-is and the irrelevant words are flushed out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n90YjClyInFy",
        "colab": {}
      },
      "source": [
        "def print_out(q, k, v):\n",
        "  temp_out, temp_attn = scaled_dot_product_attention(\n",
        "      q, k, v, None)\n",
        "  print ('Attention weights are:')\n",
        "  print (temp_attn)\n",
        "  print ('Output is:')\n",
        "  print (temp_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yAzUAf2DPlNt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d4c98c89-022a-4fca-8d29-7369f2b819b8"
      },
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "temp_k = tf.constant([[10,0,0],\n",
        "                      [0,10,0],\n",
        "                      [0,0,10],\n",
        "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
        "\n",
        "temp_v = tf.constant([[   1,0],\n",
        "                      [  10,0],\n",
        "                      [ 100,5],\n",
        "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
        "\n",
        "# This `query` aligns with the second `key`,\n",
        "# so the second `value` is returned.\n",
        "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention weights are:\n",
            "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
            "Output is:\n",
            "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zg6k-fGhgXra",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9f033afc-5812-4555-b66c-6d674578dfff"
      },
      "source": [
        "# This query aligns with a repeated key (third and fourth), \n",
        "# so all associated values get averaged.\n",
        "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention weights are:\n",
            "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
            "Output is:\n",
            "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UAq3YOzUgXhb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "41b48fbb-9c07-4df3-c62d-9877d2660702"
      },
      "source": [
        "# This query aligns equally with the first and second key, \n",
        "# so their values get averaged.\n",
        "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention weights are:\n",
            "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
            "Output is:\n",
            "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aOz-4_XIhaTP"
      },
      "source": [
        "Pass all the queries together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6dlU8Tm-hYrF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "1d28b35f-aab1-4abe-b766-7df92d08758c"
      },
      "source": [
        "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention weights are:\n",
            "tf.Tensor(\n",
            "[[0.  0.  0.5 0.5]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
            "Output is:\n",
            "tf.Tensor(\n",
            "[[550.    5.5]\n",
            " [ 10.    0. ]\n",
            " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kmzGPEy64qmA"
      },
      "source": [
        "## Multi-head attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fz5BMC8Kaoqo"
      },
      "source": [
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/multi_head_attention.png\" width=\"500\" alt=\"multi-head attention\">\n",
        "\n",
        "\n",
        "Multi-head attention consists of four parts:\n",
        "*    Linear layers and split into heads.\n",
        "*    Scaled dot-product attention.\n",
        "*    Concatenation of heads.\n",
        "*    Final linear layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JPmbr6F1C-v_"
      },
      "source": [
        "Each multi-head attention block gets three inputs; Q (query), K (key), V (value). These are put through linear (Dense) layers and split up into multiple heads. \n",
        "\n",
        "The `scaled_dot_product_attention` defined above is applied to each head (broadcasted for efficiency). An appropriate mask must be used in the attention step.  The attention output for each head is then concatenated (using `tf.transpose`, and `tf.reshape`) and put through a final `Dense` layer.\n",
        "\n",
        "Instead of one single attention head, Q, K, and V are split into multiple heads because it allows the model to jointly attend to information at different positions from different representational spaces. After the split each head has a reduced dimensionality, so the total computation cost is the same as a single head attention with full dimensionality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BSV3PPKsYecw",
        "colab": {}
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "    \n",
        "    assert d_model % self.num_heads == 0\n",
        "    \n",
        "    self.depth = d_model // self.num_heads\n",
        "    \n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "    \n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "    \n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "    \n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "    \n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "    \n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention, \n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    # why this extra line, coz this was not mentioned in model\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "        \n",
        "    return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0D8FJue5lDyZ"
      },
      "source": [
        "Create a `MultiHeadAttention` layer to try out. At each location in the sequence, `y`, the `MultiHeadAttention` runs all 8 attention heads across all other locations in the sequence, returning a new vector of the same length at each location."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hu94p-_-2_BX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "336322f5-a8db-4892-c1b2-b21b35a39674"
      },
      "source": [
        "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
        "y = tf.random.uniform((64, 62, 128))  # (batch_size, encoder_sequence, d_model)\n",
        "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
        "out.shape, attn.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 62, 512]), TensorShape([64, 8, 62, 62]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RdDqGayx67vv"
      },
      "source": [
        "## Point wise feed forward network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gBqzJXGfHK3X"
      },
      "source": [
        "Point wise feed forward network consists of two fully-connected layers with a ReLU activation in between."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ET7xLt0yCT6Z",
        "colab": {}
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mytb1lPyOHLB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46ab4829-d9fa-40c9-c930-873b07b3772e"
      },
      "source": [
        "sample_ffn = point_wise_feed_forward_network(500, 2048)\n",
        "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 50, 500])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7e7hKcxn6-zd"
      },
      "source": [
        "## Encoder and decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yScbC0MUH8dS"
      },
      "source": [
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\" width=\"600\" alt=\"transformer\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MfYJG-Kvgwy2"
      },
      "source": [
        "The transformer model follows the same general pattern as a standard [sequence to sequence with attention model](nmt_with_attention.ipynb). \n",
        "\n",
        "* The input sentence is passed through `N` encoder layers that generates an output for each word/token in the sequence.\n",
        "* The decoder attends on the encoder's output and its own input (self-attention) to predict the next word. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QFv-FNYUmvpn"
      },
      "source": [
        "### Encoder layer\n",
        "\n",
        "Each encoder layer consists of sublayers:\n",
        "\n",
        "1.   Multi-head attention (with padding mask) \n",
        "2.    Point wise feed forward networks. \n",
        "\n",
        "Each of these sublayers has a residual connection around it followed by a layer normalization. Residual connections help in avoiding the vanishing gradient problem in deep networks.\n",
        "\n",
        "The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis. There are N encoder layers in the transformer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ncyS-Ms3i2x_",
        "colab": {}
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    return out2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AzZRXdO0mI48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af0fc124-6602-4da4-c852-2407f2d41fc6"
      },
      "source": [
        "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
        "\n",
        "sample_encoder_layer_output = sample_encoder_layer(\n",
        "    tf.random.uniform((64, 43, 512)), False, None)\n",
        "\n",
        "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 43, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6LO_48Owmx_o"
      },
      "source": [
        "### Decoder layer\n",
        "\n",
        "Each decoder layer consists of sublayers:\n",
        "\n",
        "1.   Masked multi-head attention (with look ahead mask and padding mask)\n",
        "2.   Multi-head attention (with padding mask). V (value) and K (key) receive the *encoder output* as inputs. Q (query) receives the *output from the masked multi-head attention sublayer.*\n",
        "3.   Point wise feed forward networks\n",
        "\n",
        "Each of these sublayers has a residual connection around it followed by a layer normalization. The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis.\n",
        "\n",
        "There are N decoder layers in the transformer.\n",
        "\n",
        "As Q receives the output from decoder's first attention block, and K receives the encoder output, the attention weights represent the importance given to the decoder's input based on the encoder's output. In other words, the decoder predicts the next word by looking at the encoder output and self-attending to its own output. See the demonstration above in the scaled dot product attention section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9SoX0-vd1hue",
        "colab": {}
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        " \n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "    \n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ne2Bqx8k71l0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0500b61-6b0c-4dd5-ead9-002396e54019"
      },
      "source": [
        "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
        "\n",
        "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
        "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
        "    False, None, None)\n",
        "\n",
        "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 50, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly9VEv-UAU2w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c5cc8ce-0f72-4cc2-ed94-7ab23a7b9726"
      },
      "source": [
        "input_vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SE1H51Ajm0q1"
      },
      "source": [
        "### Encoder\n",
        "\n",
        "The `Encoder` consists of:\n",
        "1.   Input Embedding\n",
        "2.   Positional Encoding\n",
        "3.   N encoder layers\n",
        "\n",
        "The input is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jpEox7gJ8FCI",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
        "                                            self.d_model)\n",
        "    \n",
        "    \n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "  \n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    # adding embedding and position encoding.\n",
        "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "    x = self.dropout(x, training=training)\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "    return x  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p-uO6ls8m2O5"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZtT7PKzrXkNr"
      },
      "source": [
        " The `Decoder` consists of:\n",
        "1.   Output Embedding\n",
        "2.   Positional Encoding\n",
        "3.   N decoder layers\n",
        "\n",
        "The target is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the decoder layers. The output of the decoder is the input to the final linear layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d5_d5-PLQXwY",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "     \n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "    \n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "    \n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "    \n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "    \n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "      \n",
        "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "    \n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y54xnJnuYgJ7"
      },
      "source": [
        "## Create the Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uERO1y54cOKq"
      },
      "source": [
        "Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PED3bIpOYkBu",
        "colab": {}
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
        "                           input_vocab_size, pe_input, rate)\n",
        "\n",
        "    self.decoder1 = Decoder(num_layers, d_model, num_heads, dff, \n",
        "                           target_vocab_size, pe_target, rate)\n",
        "    self.decoder2 = Decoder(num_layers, d_model, num_heads, dff, \n",
        "                           target_vocab_size, pe_target, rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "  def call(self, inp, tar, training, enc_padding_mask, \n",
        "           look_ahead_mask, dec_padding_mask, num_heads, maxlen_targ, batch_size):\n",
        "\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output = tf.random.uniform((batch_size, maxlen_targ, d_model))\n",
        "    if(inp[0][0] == char2idxEn[\"$\"]):\n",
        "      dec_output, attention_weights = self.decoder1(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "    if(inp[0][0] == char2idxEn[\"%\"]):\n",
        "      dec_output, attention_weights = self.decoder2(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "    \n",
        "    return final_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wsINyf1VEQLC"
      },
      "source": [
        "## Set hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zVjWCxFNcgbt"
      },
      "source": [
        "To keep this example small and relatively fast, the values for *num_layers, d_model, and dff* have been reduced. \n",
        "\n",
        "The values used in the base model of transformer were; *num_layers=6*, *d_model = 512*, *dff = 2048*. See the [paper](https://arxiv.org/abs/1706.03762) for all the other versions of the transformer.\n",
        "\n",
        "Note: By changing the values below, you can get the model that achieved state of the art on many tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lnJn5SLA2ahP",
        "colab": {}
      },
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xYEGhEOtzn5W"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GOmWW--yP3zx"
      },
      "source": [
        "Use the Adam optimizer with a custom learning rate scheduler according to the formula in the [paper](https://arxiv.org/abs/1706.03762).\n",
        "\n",
        "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iYQdOO1axwEI",
        "colab": {}
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    \n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "    \n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "    \n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7r4scdulztRx",
        "colab": {}
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YgkDE7hzo8r5"
      },
      "source": [
        "## Loss and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oxGJtoDuYIHL"
      },
      "source": [
        "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MlhsJMm0TW_B",
        "colab": {}
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "67oqVHiT0Eiu",
        "colab": {}
      },
      "source": [
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "  \n",
        "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "phlyxMnm-Tpx",
        "colab": {}
      },
      "source": [
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aeHumfr7zmMa"
      },
      "source": [
        "## Training and checkpointing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UiysUa--4tOU",
        "colab": {}
      },
      "source": [
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size, \n",
        "                          pe_input=100, \n",
        "                          pe_target=100,\n",
        "                          rate=dropout_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZOJUSB1T8GjM",
        "colab": {}
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "  # Encoder padding mask\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # Used in the 2nd attention block in the decoder.\n",
        "  # This padding mask is used to mask the encoder outputs.\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # Used in the 1st attention block in the decoder.\n",
        "  # It is used to pad and mask future tokens in the input received by \n",
        "  # the decoder.\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "  \n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGJUnpXA-7BI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fzuf06YZp66w"
      },
      "source": [
        "Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hNhuYfllndLZ",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"./checkpoints/train\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print ('Latest checkpoint restored!!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6KWiBZ87uw6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f22e11a4-3067-4c9d-fdd2-493599da212d"
      },
      "source": [
        "maxlen_inp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb-cvPbmkQC1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80450ee5-c57c-4fdf-a02a-e588e6eac5d7"
      },
      "source": [
        "num_heads"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LKpoA6q1sJFj",
        "colab": {}
      },
      "source": [
        "EPOCHS = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iJwmp9OE29oj",
        "colab": {}
      },
      "source": [
        "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
        "# execution. The function specializes to the precise shape of the argument\n",
        "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
        "# batch sizes (the last batch is smaller), use input_signature to specify\n",
        "# more generic shapes.\n",
        "\n",
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(64, maxlen_inp), dtype=tf.int32),\n",
        "    tf.TensorSpec(shape=(64, maxlen_targ), dtype=tf.int32),\n",
        "]\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions= transformer(inp, tar_inp, \n",
        "                                 True, \n",
        "                                 enc_padding_mask, \n",
        "                                 combined_mask, \n",
        "                                 dec_padding_mask, num_heads, maxlen_targ, BATCH_SIZE)\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "  \n",
        "  train_loss(loss)\n",
        "  train_accuracy(tar_real, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qM2PDWGDJ_8V"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "English is used as the input language and Hindi is the target language."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bbvmaKNiznHZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1e9809cf-a680-4dac-d3f3-bbabc12b665b"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "  \n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  \n",
        "  # inp -> portuguese, tar -> english\n",
        "  for (batch, (inp, tar)) in enumerate(dataset):\n",
        "    train_step(inp, tar)\n",
        "    if batch % 50 == 0:\n",
        "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "      \n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
        "                                                         ckpt_save_path))\n",
        "    \n",
        "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
        "                                                train_loss.result(), \n",
        "                                                train_accuracy.result()))\n",
        "\n",
        "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 5.2635 Accuracy 0.0221\n",
            "Epoch 1 Batch 50 Loss 5.0477 Accuracy 0.0085\n",
            "Epoch 1 Batch 100 Loss 4.6132 Accuracy 0.0193\n",
            "Epoch 1 Batch 150 Loss 4.3493 Accuracy 0.0242\n",
            "Epoch 1 Batch 200 Loss 4.1672 Accuracy 0.0282\n",
            "Epoch 1 Batch 250 Loss 4.0246 Accuracy 0.0328\n",
            "Epoch 1 Batch 300 Loss 3.8971 Accuracy 0.0372\n",
            "Epoch 1 Batch 350 Loss 3.7833 Accuracy 0.0414\n",
            "Epoch 1 Batch 400 Loss 3.6792 Accuracy 0.0453\n",
            "Epoch 1 Loss 3.6651 Accuracy 0.0459\n",
            "Time taken for 1 epoch: 59.31021189689636 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 2.7336 Accuracy 0.0835\n",
            "Epoch 2 Batch 50 Loss 2.6818 Accuracy 0.0877\n",
            "Epoch 2 Batch 100 Loss 2.6217 Accuracy 0.0889\n",
            "Epoch 2 Batch 150 Loss 2.5636 Accuracy 0.0913\n",
            "Epoch 2 Batch 200 Loss 2.5221 Accuracy 0.0931\n",
            "Epoch 2 Batch 250 Loss 2.4844 Accuracy 0.0950\n",
            "Epoch 2 Batch 300 Loss 2.4453 Accuracy 0.0972\n",
            "Epoch 2 Batch 350 Loss 2.4020 Accuracy 0.0997\n",
            "Epoch 2 Batch 400 Loss 2.3552 Accuracy 0.1024\n",
            "Epoch 2 Loss 2.3499 Accuracy 0.1028\n",
            "Time taken for 1 epoch: 32.977914571762085 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.8327 Accuracy 0.1374\n",
            "Epoch 3 Batch 50 Loss 1.9451 Accuracy 0.1333\n",
            "Epoch 3 Batch 100 Loss 1.8780 Accuracy 0.1372\n",
            "Epoch 3 Batch 150 Loss 1.8061 Accuracy 0.1416\n",
            "Epoch 3 Batch 200 Loss 1.7571 Accuracy 0.1452\n",
            "Epoch 3 Batch 250 Loss 1.6836 Accuracy 0.1507\n",
            "Epoch 3 Batch 300 Loss 1.6356 Accuracy 0.1544\n",
            "Epoch 3 Batch 350 Loss 1.5868 Accuracy 0.1584\n",
            "Epoch 3 Batch 400 Loss 1.5336 Accuracy 0.1626\n",
            "Epoch 3 Loss 1.5304 Accuracy 0.1630\n",
            "Time taken for 1 epoch: 33.008917570114136 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.2449 Accuracy 0.1875\n",
            "Epoch 4 Batch 50 Loss 1.1742 Accuracy 0.1922\n",
            "Epoch 4 Batch 100 Loss 1.1545 Accuracy 0.1907\n",
            "Epoch 4 Batch 150 Loss 1.1134 Accuracy 0.1942\n",
            "Epoch 4 Batch 200 Loss 1.0870 Accuracy 0.1958\n",
            "Epoch 4 Batch 250 Loss 1.0821 Accuracy 0.1981\n",
            "Epoch 4 Batch 300 Loss 1.0793 Accuracy 0.1986\n",
            "Epoch 4 Batch 350 Loss 1.0674 Accuracy 0.1995\n",
            "Epoch 4 Batch 400 Loss 1.0577 Accuracy 0.2008\n",
            "Epoch 4 Loss 1.0578 Accuracy 0.2009\n",
            "Time taken for 1 epoch: 32.99008750915527 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.1231 Accuracy 0.2398\n",
            "Epoch 5 Batch 50 Loss 0.9317 Accuracy 0.2135\n",
            "Epoch 5 Batch 100 Loss 0.9761 Accuracy 0.2104\n",
            "Epoch 5 Batch 150 Loss 0.9361 Accuracy 0.2125\n",
            "Epoch 5 Batch 200 Loss 0.9204 Accuracy 0.2130\n",
            "Epoch 5 Batch 250 Loss 0.9097 Accuracy 0.2135\n",
            "Epoch 5 Batch 300 Loss 0.8956 Accuracy 0.2141\n",
            "Epoch 5 Batch 350 Loss 0.8962 Accuracy 0.2148\n",
            "Epoch 5 Batch 400 Loss 0.8817 Accuracy 0.2152\n",
            "Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-1\n",
            "Epoch 5 Loss 0.8799 Accuracy 0.2153\n",
            "Time taken for 1 epoch: 33.43977975845337 secs\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.7107 Accuracy 0.2123\n",
            "Epoch 6 Batch 50 Loss 0.8010 Accuracy 0.2207\n",
            "Epoch 6 Batch 100 Loss 0.7963 Accuracy 0.2215\n",
            "Epoch 6 Batch 150 Loss 0.8192 Accuracy 0.2198\n",
            "Epoch 6 Batch 200 Loss 0.8015 Accuracy 0.2212\n",
            "Epoch 6 Batch 250 Loss 0.7940 Accuracy 0.2222\n",
            "Epoch 6 Batch 300 Loss 0.7986 Accuracy 0.2221\n",
            "Epoch 6 Batch 350 Loss 0.7882 Accuracy 0.2224\n",
            "Epoch 6 Batch 400 Loss 0.7938 Accuracy 0.2220\n",
            "Epoch 6 Loss 0.7932 Accuracy 0.2221\n",
            "Time taken for 1 epoch: 32.92723560333252 secs\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.9066 Accuracy 0.2161\n",
            "Epoch 7 Batch 50 Loss 0.6854 Accuracy 0.2295\n",
            "Epoch 7 Batch 100 Loss 0.7067 Accuracy 0.2279\n",
            "Epoch 7 Batch 150 Loss 0.7041 Accuracy 0.2291\n",
            "Epoch 7 Batch 200 Loss 0.7025 Accuracy 0.2294\n",
            "Epoch 7 Batch 250 Loss 0.7083 Accuracy 0.2286\n",
            "Epoch 7 Batch 300 Loss 0.7013 Accuracy 0.2293\n",
            "Epoch 7 Batch 350 Loss 0.7016 Accuracy 0.2297\n",
            "Epoch 7 Batch 400 Loss 0.7011 Accuracy 0.2302\n",
            "Epoch 7 Loss 0.7010 Accuracy 0.2301\n",
            "Time taken for 1 epoch: 33.03077530860901 secs\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.5804 Accuracy 0.2301\n",
            "Epoch 8 Batch 50 Loss 0.6617 Accuracy 0.2373\n",
            "Epoch 8 Batch 100 Loss 0.6549 Accuracy 0.2378\n",
            "Epoch 8 Batch 150 Loss 0.6487 Accuracy 0.2367\n",
            "Epoch 8 Batch 200 Loss 0.6557 Accuracy 0.2358\n",
            "Epoch 8 Batch 250 Loss 0.6520 Accuracy 0.2357\n",
            "Epoch 8 Batch 300 Loss 0.6468 Accuracy 0.2360\n",
            "Epoch 8 Batch 350 Loss 0.6556 Accuracy 0.2349\n",
            "Epoch 8 Batch 400 Loss 0.6482 Accuracy 0.2350\n",
            "Epoch 8 Loss 0.6471 Accuracy 0.2350\n",
            "Time taken for 1 epoch: 32.95695996284485 secs\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.6723 Accuracy 0.2861\n",
            "Epoch 9 Batch 50 Loss 0.5904 Accuracy 0.2357\n",
            "Epoch 9 Batch 100 Loss 0.6450 Accuracy 0.2338\n",
            "Epoch 9 Batch 150 Loss 0.6302 Accuracy 0.2363\n",
            "Epoch 9 Batch 200 Loss 0.6271 Accuracy 0.2365\n",
            "Epoch 9 Batch 250 Loss 0.6227 Accuracy 0.2367\n",
            "Epoch 9 Batch 300 Loss 0.6200 Accuracy 0.2367\n",
            "Epoch 9 Batch 350 Loss 0.6187 Accuracy 0.2374\n",
            "Epoch 9 Batch 400 Loss 0.6162 Accuracy 0.2376\n",
            "Epoch 9 Loss 0.6150 Accuracy 0.2377\n",
            "Time taken for 1 epoch: 33.053959608078 secs\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.6244 Accuracy 0.2274\n",
            "Epoch 10 Batch 50 Loss 0.5982 Accuracy 0.2421\n",
            "Epoch 10 Batch 100 Loss 0.5890 Accuracy 0.2426\n",
            "Epoch 10 Batch 150 Loss 0.5883 Accuracy 0.2397\n",
            "Epoch 10 Batch 200 Loss 0.5853 Accuracy 0.2419\n",
            "Epoch 10 Batch 250 Loss 0.5855 Accuracy 0.2417\n",
            "Epoch 10 Batch 300 Loss 0.5878 Accuracy 0.2409\n",
            "Epoch 10 Batch 350 Loss 0.5889 Accuracy 0.2405\n",
            "Epoch 10 Batch 400 Loss 0.5872 Accuracy 0.2404\n",
            "Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-2\n",
            "Epoch 10 Loss 0.5872 Accuracy 0.2405\n",
            "Time taken for 1 epoch: 33.46090817451477 secs\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.4710 Accuracy 0.2629\n",
            "Epoch 11 Batch 50 Loss 0.5556 Accuracy 0.2436\n",
            "Epoch 11 Batch 100 Loss 0.5509 Accuracy 0.2430\n",
            "Epoch 11 Batch 150 Loss 0.5569 Accuracy 0.2415\n",
            "Epoch 11 Batch 200 Loss 0.5577 Accuracy 0.2413\n",
            "Epoch 11 Batch 250 Loss 0.5561 Accuracy 0.2416\n",
            "Epoch 11 Batch 300 Loss 0.5554 Accuracy 0.2425\n",
            "Epoch 11 Batch 350 Loss 0.5537 Accuracy 0.2433\n",
            "Epoch 11 Batch 400 Loss 0.5559 Accuracy 0.2432\n",
            "Epoch 11 Loss 0.5558 Accuracy 0.2432\n",
            "Time taken for 1 epoch: 33.113065242767334 secs\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.5590 Accuracy 0.2247\n",
            "Epoch 12 Batch 50 Loss 0.5199 Accuracy 0.2428\n",
            "Epoch 12 Batch 100 Loss 0.5123 Accuracy 0.2428\n",
            "Epoch 12 Batch 150 Loss 0.5046 Accuracy 0.2447\n",
            "Epoch 12 Batch 200 Loss 0.5059 Accuracy 0.2447\n",
            "Epoch 12 Batch 250 Loss 0.5107 Accuracy 0.2444\n",
            "Epoch 12 Batch 300 Loss 0.5125 Accuracy 0.2462\n",
            "Epoch 12 Batch 350 Loss 0.5118 Accuracy 0.2469\n",
            "Epoch 12 Batch 400 Loss 0.5118 Accuracy 0.2467\n",
            "Epoch 12 Loss 0.5110 Accuracy 0.2468\n",
            "Time taken for 1 epoch: 33.02793574333191 secs\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.4165 Accuracy 0.2672\n",
            "Epoch 13 Batch 50 Loss 0.4695 Accuracy 0.2465\n",
            "Epoch 13 Batch 100 Loss 0.4663 Accuracy 0.2495\n",
            "Epoch 13 Batch 150 Loss 0.4683 Accuracy 0.2501\n",
            "Epoch 13 Batch 200 Loss 0.4672 Accuracy 0.2508\n",
            "Epoch 13 Batch 250 Loss 0.4724 Accuracy 0.2505\n",
            "Epoch 13 Batch 300 Loss 0.4742 Accuracy 0.2504\n",
            "Epoch 13 Batch 350 Loss 0.4733 Accuracy 0.2503\n",
            "Epoch 13 Batch 400 Loss 0.4786 Accuracy 0.2495\n",
            "Epoch 13 Loss 0.4795 Accuracy 0.2496\n",
            "Time taken for 1 epoch: 33.073638916015625 secs\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.4652 Accuracy 0.2958\n",
            "Epoch 14 Batch 50 Loss 0.4442 Accuracy 0.2489\n",
            "Epoch 14 Batch 100 Loss 0.4518 Accuracy 0.2511\n",
            "Epoch 14 Batch 150 Loss 0.4492 Accuracy 0.2519\n",
            "Epoch 14 Batch 200 Loss 0.4551 Accuracy 0.2517\n",
            "Epoch 14 Batch 250 Loss 0.4502 Accuracy 0.2524\n",
            "Epoch 14 Batch 300 Loss 0.4501 Accuracy 0.2527\n",
            "Epoch 14 Batch 350 Loss 0.4528 Accuracy 0.2520\n",
            "Epoch 14 Batch 400 Loss 0.4531 Accuracy 0.2515\n",
            "Epoch 14 Loss 0.4531 Accuracy 0.2519\n",
            "Time taken for 1 epoch: 33.016770362854004 secs\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.4314 Accuracy 0.2468\n",
            "Epoch 15 Batch 50 Loss 0.4329 Accuracy 0.2513\n",
            "Epoch 15 Batch 100 Loss 0.4268 Accuracy 0.2533\n",
            "Epoch 15 Batch 150 Loss 0.4270 Accuracy 0.2536\n",
            "Epoch 15 Batch 200 Loss 0.4312 Accuracy 0.2521\n",
            "Epoch 15 Batch 250 Loss 0.4310 Accuracy 0.2522\n",
            "Epoch 15 Batch 300 Loss 0.4307 Accuracy 0.2530\n",
            "Epoch 15 Batch 350 Loss 0.4336 Accuracy 0.2537\n",
            "Epoch 15 Batch 400 Loss 0.4332 Accuracy 0.2536\n",
            "Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-3\n",
            "Epoch 15 Loss 0.4334 Accuracy 0.2538\n",
            "Time taken for 1 epoch: 33.523244857788086 secs\n",
            "\n",
            "Epoch 16 Batch 0 Loss 0.3454 Accuracy 0.2969\n",
            "Epoch 16 Batch 50 Loss 0.3921 Accuracy 0.2572\n",
            "Epoch 16 Batch 100 Loss 0.3995 Accuracy 0.2534\n",
            "Epoch 16 Batch 150 Loss 0.4038 Accuracy 0.2527\n",
            "Epoch 16 Batch 200 Loss 0.4071 Accuracy 0.2541\n",
            "Epoch 16 Batch 250 Loss 0.4103 Accuracy 0.2545\n",
            "Epoch 16 Batch 300 Loss 0.4097 Accuracy 0.2557\n",
            "Epoch 16 Batch 350 Loss 0.4095 Accuracy 0.2563\n",
            "Epoch 16 Batch 400 Loss 0.4108 Accuracy 0.2556\n",
            "Epoch 16 Loss 0.4108 Accuracy 0.2556\n",
            "Time taken for 1 epoch: 33.1483154296875 secs\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.3586 Accuracy 0.2980\n",
            "Epoch 17 Batch 50 Loss 0.3778 Accuracy 0.2597\n",
            "Epoch 17 Batch 100 Loss 0.3854 Accuracy 0.2574\n",
            "Epoch 17 Batch 150 Loss 0.3882 Accuracy 0.2580\n",
            "Epoch 17 Batch 200 Loss 0.3880 Accuracy 0.2587\n",
            "Epoch 17 Batch 250 Loss 0.3888 Accuracy 0.2576\n",
            "Epoch 17 Batch 300 Loss 0.3951 Accuracy 0.2572\n",
            "Epoch 17 Batch 350 Loss 0.3942 Accuracy 0.2569\n",
            "Epoch 17 Batch 400 Loss 0.3935 Accuracy 0.2570\n",
            "Epoch 17 Loss 0.3935 Accuracy 0.2569\n",
            "Time taken for 1 epoch: 33.20318293571472 secs\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.3530 Accuracy 0.2845\n",
            "Epoch 18 Batch 50 Loss 0.3698 Accuracy 0.2556\n",
            "Epoch 18 Batch 100 Loss 0.3718 Accuracy 0.2552\n",
            "Epoch 18 Batch 150 Loss 0.3698 Accuracy 0.2567\n",
            "Epoch 18 Batch 200 Loss 0.3740 Accuracy 0.2573\n",
            "Epoch 18 Batch 250 Loss 0.3773 Accuracy 0.2570\n",
            "Epoch 18 Batch 300 Loss 0.3771 Accuracy 0.2581\n",
            "Epoch 18 Batch 350 Loss 0.3765 Accuracy 0.2585\n",
            "Epoch 18 Batch 400 Loss 0.3770 Accuracy 0.2582\n",
            "Epoch 18 Loss 0.3772 Accuracy 0.2584\n",
            "Time taken for 1 epoch: 33.20909786224365 secs\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.3622 Accuracy 0.2306\n",
            "Epoch 19 Batch 50 Loss 0.3539 Accuracy 0.2612\n",
            "Epoch 19 Batch 100 Loss 0.3536 Accuracy 0.2616\n",
            "Epoch 19 Batch 150 Loss 0.3588 Accuracy 0.2590\n",
            "Epoch 19 Batch 200 Loss 0.3609 Accuracy 0.2591\n",
            "Epoch 19 Batch 250 Loss 0.3643 Accuracy 0.2589\n",
            "Epoch 19 Batch 300 Loss 0.3622 Accuracy 0.2588\n",
            "Epoch 19 Batch 350 Loss 0.3638 Accuracy 0.2591\n",
            "Epoch 19 Batch 400 Loss 0.3644 Accuracy 0.2595\n",
            "Epoch 19 Loss 0.3646 Accuracy 0.2596\n",
            "Time taken for 1 epoch: 33.072702169418335 secs\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.2328 Accuracy 0.3050\n",
            "Epoch 20 Batch 50 Loss 0.3361 Accuracy 0.2647\n",
            "Epoch 20 Batch 100 Loss 0.3406 Accuracy 0.2622\n",
            "Epoch 20 Batch 150 Loss 0.3436 Accuracy 0.2617\n",
            "Epoch 20 Batch 200 Loss 0.3439 Accuracy 0.2606\n",
            "Epoch 20 Batch 250 Loss 0.3447 Accuracy 0.2617\n",
            "Epoch 20 Batch 300 Loss 0.3474 Accuracy 0.2612\n",
            "Epoch 20 Batch 350 Loss 0.3482 Accuracy 0.2609\n",
            "Epoch 20 Batch 400 Loss 0.3489 Accuracy 0.2608\n",
            "Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-4\n",
            "Epoch 20 Loss 0.3492 Accuracy 0.2609\n",
            "Time taken for 1 epoch: 33.590553760528564 secs\n",
            "\n",
            "Epoch 21 Batch 0 Loss 0.2426 Accuracy 0.2909\n",
            "Epoch 21 Batch 50 Loss 0.3233 Accuracy 0.2637\n",
            "Epoch 21 Batch 100 Loss 0.3211 Accuracy 0.2666\n",
            "Epoch 21 Batch 150 Loss 0.3250 Accuracy 0.2667\n",
            "Epoch 21 Batch 200 Loss 0.3283 Accuracy 0.2640\n",
            "Epoch 21 Batch 250 Loss 0.3332 Accuracy 0.2630\n",
            "Epoch 21 Batch 300 Loss 0.3351 Accuracy 0.2626\n",
            "Epoch 21 Batch 350 Loss 0.3340 Accuracy 0.2631\n",
            "Epoch 21 Batch 400 Loss 0.3350 Accuracy 0.2622\n",
            "Epoch 21 Loss 0.3355 Accuracy 0.2623\n",
            "Time taken for 1 epoch: 33.12712383270264 secs\n",
            "\n",
            "Epoch 22 Batch 0 Loss 0.4105 Accuracy 0.3141\n",
            "Epoch 22 Batch 50 Loss 0.3107 Accuracy 0.2664\n",
            "Epoch 22 Batch 100 Loss 0.3131 Accuracy 0.2643\n",
            "Epoch 22 Batch 150 Loss 0.3116 Accuracy 0.2631\n",
            "Epoch 22 Batch 200 Loss 0.3144 Accuracy 0.2641\n",
            "Epoch 22 Batch 250 Loss 0.3163 Accuracy 0.2639\n",
            "Epoch 22 Batch 300 Loss 0.3192 Accuracy 0.2638\n",
            "Epoch 22 Batch 350 Loss 0.3205 Accuracy 0.2632\n",
            "Epoch 22 Batch 400 Loss 0.3218 Accuracy 0.2632\n",
            "Epoch 22 Loss 0.3219 Accuracy 0.2634\n",
            "Time taken for 1 epoch: 33.13517117500305 secs\n",
            "\n",
            "Epoch 23 Batch 0 Loss 0.2941 Accuracy 0.2786\n",
            "Epoch 23 Batch 50 Loss 0.3081 Accuracy 0.2635\n",
            "Epoch 23 Batch 100 Loss 0.2985 Accuracy 0.2630\n",
            "Epoch 23 Batch 150 Loss 0.2980 Accuracy 0.2658\n",
            "Epoch 23 Batch 200 Loss 0.3042 Accuracy 0.2643\n",
            "Epoch 23 Batch 250 Loss 0.3052 Accuracy 0.2659\n",
            "Epoch 23 Batch 300 Loss 0.3070 Accuracy 0.2662\n",
            "Epoch 23 Batch 350 Loss 0.3115 Accuracy 0.2644\n",
            "Epoch 23 Batch 400 Loss 0.3128 Accuracy 0.2642\n",
            "Epoch 23 Loss 0.3127 Accuracy 0.2643\n",
            "Time taken for 1 epoch: 33.043339252471924 secs\n",
            "\n",
            "Epoch 24 Batch 0 Loss 0.2921 Accuracy 0.2662\n",
            "Epoch 24 Batch 50 Loss 0.2886 Accuracy 0.2612\n",
            "Epoch 24 Batch 100 Loss 0.2876 Accuracy 0.2637\n",
            "Epoch 24 Batch 150 Loss 0.2896 Accuracy 0.2658\n",
            "Epoch 24 Batch 200 Loss 0.2892 Accuracy 0.2673\n",
            "Epoch 24 Batch 250 Loss 0.2925 Accuracy 0.2671\n",
            "Epoch 24 Batch 300 Loss 0.2948 Accuracy 0.2660\n",
            "Epoch 24 Batch 350 Loss 0.3006 Accuracy 0.2654\n",
            "Epoch 24 Batch 400 Loss 0.3016 Accuracy 0.2655\n",
            "Epoch 24 Loss 0.3013 Accuracy 0.2654\n",
            "Time taken for 1 epoch: 33.10939359664917 secs\n",
            "\n",
            "Epoch 25 Batch 0 Loss 0.2343 Accuracy 0.2565\n",
            "Epoch 25 Batch 50 Loss 0.2693 Accuracy 0.2681\n",
            "Epoch 25 Batch 100 Loss 0.2720 Accuracy 0.2687\n",
            "Epoch 25 Batch 150 Loss 0.2781 Accuracy 0.2685\n",
            "Epoch 25 Batch 200 Loss 0.2825 Accuracy 0.2666\n",
            "Epoch 25 Batch 250 Loss 0.2837 Accuracy 0.2660\n",
            "Epoch 25 Batch 300 Loss 0.2898 Accuracy 0.2655\n",
            "Epoch 25 Batch 350 Loss 0.2915 Accuracy 0.2656\n",
            "Epoch 25 Batch 400 Loss 0.2904 Accuracy 0.2662\n",
            "Saving checkpoint for epoch 25 at ./checkpoints/train/ckpt-5\n",
            "Epoch 25 Loss 0.2906 Accuracy 0.2664\n",
            "Time taken for 1 epoch: 33.579742431640625 secs\n",
            "\n",
            "Epoch 26 Batch 0 Loss 0.2720 Accuracy 0.3211\n",
            "Epoch 26 Batch 50 Loss 0.2717 Accuracy 0.2694\n",
            "Epoch 26 Batch 100 Loss 0.2698 Accuracy 0.2718\n",
            "Epoch 26 Batch 150 Loss 0.2738 Accuracy 0.2709\n",
            "Epoch 26 Batch 200 Loss 0.2759 Accuracy 0.2711\n",
            "Epoch 26 Batch 250 Loss 0.2756 Accuracy 0.2701\n",
            "Epoch 26 Batch 300 Loss 0.2784 Accuracy 0.2682\n",
            "Epoch 26 Batch 350 Loss 0.2793 Accuracy 0.2678\n",
            "Epoch 26 Batch 400 Loss 0.2792 Accuracy 0.2675\n",
            "Epoch 26 Loss 0.2793 Accuracy 0.2674\n",
            "Time taken for 1 epoch: 33.029396533966064 secs\n",
            "\n",
            "Epoch 27 Batch 0 Loss 0.3098 Accuracy 0.2301\n",
            "Epoch 27 Batch 50 Loss 0.2400 Accuracy 0.2753\n",
            "Epoch 27 Batch 100 Loss 0.2485 Accuracy 0.2749\n",
            "Epoch 27 Batch 150 Loss 0.2530 Accuracy 0.2731\n",
            "Epoch 27 Batch 200 Loss 0.2588 Accuracy 0.2712\n",
            "Epoch 27 Batch 250 Loss 0.2635 Accuracy 0.2693\n",
            "Epoch 27 Batch 300 Loss 0.2657 Accuracy 0.2692\n",
            "Epoch 27 Batch 350 Loss 0.2671 Accuracy 0.2691\n",
            "Epoch 27 Batch 400 Loss 0.2697 Accuracy 0.2682\n",
            "Epoch 27 Loss 0.2705 Accuracy 0.2681\n",
            "Time taken for 1 epoch: 33.17470598220825 secs\n",
            "\n",
            "Epoch 28 Batch 0 Loss 0.2570 Accuracy 0.2812\n",
            "Epoch 28 Batch 50 Loss 0.2447 Accuracy 0.2645\n",
            "Epoch 28 Batch 100 Loss 0.2446 Accuracy 0.2697\n",
            "Epoch 28 Batch 150 Loss 0.2501 Accuracy 0.2689\n",
            "Epoch 28 Batch 200 Loss 0.2558 Accuracy 0.2689\n",
            "Epoch 28 Batch 250 Loss 0.2560 Accuracy 0.2678\n",
            "Epoch 28 Batch 300 Loss 0.2581 Accuracy 0.2680\n",
            "Epoch 28 Batch 350 Loss 0.2576 Accuracy 0.2693\n",
            "Epoch 28 Batch 400 Loss 0.2581 Accuracy 0.2693\n",
            "Epoch 28 Loss 0.2578 Accuracy 0.2692\n",
            "Time taken for 1 epoch: 33.184159994125366 secs\n",
            "\n",
            "Epoch 29 Batch 0 Loss 0.2046 Accuracy 0.2263\n",
            "Epoch 29 Batch 50 Loss 0.2302 Accuracy 0.2705\n",
            "Epoch 29 Batch 100 Loss 0.2367 Accuracy 0.2694\n",
            "Epoch 29 Batch 150 Loss 0.2405 Accuracy 0.2692\n",
            "Epoch 29 Batch 200 Loss 0.2424 Accuracy 0.2693\n",
            "Epoch 29 Batch 250 Loss 0.2437 Accuracy 0.2699\n",
            "Epoch 29 Batch 300 Loss 0.2469 Accuracy 0.2700\n",
            "Epoch 29 Batch 350 Loss 0.2504 Accuracy 0.2699\n",
            "Epoch 29 Batch 400 Loss 0.2508 Accuracy 0.2698\n",
            "Epoch 29 Loss 0.2511 Accuracy 0.2697\n",
            "Time taken for 1 epoch: 33.22793531417847 secs\n",
            "\n",
            "Epoch 30 Batch 0 Loss 0.1913 Accuracy 0.3190\n",
            "Epoch 30 Batch 50 Loss 0.2111 Accuracy 0.2803\n",
            "Epoch 30 Batch 100 Loss 0.2293 Accuracy 0.2741\n",
            "Epoch 30 Batch 150 Loss 0.2314 Accuracy 0.2724\n",
            "Epoch 30 Batch 200 Loss 0.2350 Accuracy 0.2727\n",
            "Epoch 30 Batch 250 Loss 0.2367 Accuracy 0.2719\n",
            "Epoch 30 Batch 300 Loss 0.2389 Accuracy 0.2711\n",
            "Epoch 30 Batch 350 Loss 0.2416 Accuracy 0.2708\n",
            "Epoch 30 Batch 400 Loss 0.2427 Accuracy 0.2705\n",
            "Saving checkpoint for epoch 30 at ./checkpoints/train/ckpt-6\n",
            "Epoch 30 Loss 0.2425 Accuracy 0.2705\n",
            "Time taken for 1 epoch: 33.53361916542053 secs\n",
            "\n",
            "Epoch 31 Batch 0 Loss 0.2284 Accuracy 0.2915\n",
            "Epoch 31 Batch 50 Loss 0.2130 Accuracy 0.2734\n",
            "Epoch 31 Batch 100 Loss 0.2220 Accuracy 0.2724\n",
            "Epoch 31 Batch 150 Loss 0.2249 Accuracy 0.2716\n",
            "Epoch 31 Batch 200 Loss 0.2258 Accuracy 0.2717\n",
            "Epoch 31 Batch 250 Loss 0.2302 Accuracy 0.2707\n",
            "Epoch 31 Batch 300 Loss 0.2309 Accuracy 0.2717\n",
            "Epoch 31 Batch 350 Loss 0.2323 Accuracy 0.2716\n",
            "Epoch 31 Batch 400 Loss 0.2336 Accuracy 0.2715\n",
            "Epoch 31 Loss 0.2337 Accuracy 0.2715\n",
            "Time taken for 1 epoch: 33.14782094955444 secs\n",
            "\n",
            "Epoch 32 Batch 0 Loss 0.2266 Accuracy 0.2662\n",
            "Epoch 32 Batch 50 Loss 0.1997 Accuracy 0.2815\n",
            "Epoch 32 Batch 100 Loss 0.2073 Accuracy 0.2749\n",
            "Epoch 32 Batch 150 Loss 0.2151 Accuracy 0.2744\n",
            "Epoch 32 Batch 200 Loss 0.2192 Accuracy 0.2731\n",
            "Epoch 32 Batch 250 Loss 0.2202 Accuracy 0.2726\n",
            "Epoch 32 Batch 300 Loss 0.2207 Accuracy 0.2724\n",
            "Epoch 32 Batch 350 Loss 0.2227 Accuracy 0.2723\n",
            "Epoch 32 Batch 400 Loss 0.2254 Accuracy 0.2723\n",
            "Epoch 32 Loss 0.2257 Accuracy 0.2722\n",
            "Time taken for 1 epoch: 33.06063771247864 secs\n",
            "\n",
            "Epoch 33 Batch 0 Loss 0.1902 Accuracy 0.2532\n",
            "Epoch 33 Batch 50 Loss 0.2042 Accuracy 0.2701\n",
            "Epoch 33 Batch 100 Loss 0.2046 Accuracy 0.2705\n",
            "Epoch 33 Batch 150 Loss 0.2069 Accuracy 0.2712\n",
            "Epoch 33 Batch 200 Loss 0.2102 Accuracy 0.2730\n",
            "Epoch 33 Batch 250 Loss 0.2127 Accuracy 0.2727\n",
            "Epoch 33 Batch 300 Loss 0.2143 Accuracy 0.2730\n",
            "Epoch 33 Batch 350 Loss 0.2159 Accuracy 0.2724\n",
            "Epoch 33 Batch 400 Loss 0.2189 Accuracy 0.2728\n",
            "Epoch 33 Loss 0.2191 Accuracy 0.2728\n",
            "Time taken for 1 epoch: 33.036356925964355 secs\n",
            "\n",
            "Epoch 34 Batch 0 Loss 0.1805 Accuracy 0.2565\n",
            "Epoch 34 Batch 50 Loss 0.1786 Accuracy 0.2800\n",
            "Epoch 34 Batch 100 Loss 0.1877 Accuracy 0.2761\n",
            "Epoch 34 Batch 150 Loss 0.1938 Accuracy 0.2764\n",
            "Epoch 34 Batch 200 Loss 0.1972 Accuracy 0.2748\n",
            "Epoch 34 Batch 250 Loss 0.2033 Accuracy 0.2741\n",
            "Epoch 34 Batch 300 Loss 0.2060 Accuracy 0.2739\n",
            "Epoch 34 Batch 350 Loss 0.2089 Accuracy 0.2738\n",
            "Epoch 34 Batch 400 Loss 0.2098 Accuracy 0.2739\n",
            "Epoch 34 Loss 0.2101 Accuracy 0.2737\n",
            "Time taken for 1 epoch: 33.039172887802124 secs\n",
            "\n",
            "Epoch 35 Batch 0 Loss 0.1611 Accuracy 0.2936\n",
            "Epoch 35 Batch 50 Loss 0.1849 Accuracy 0.2755\n",
            "Epoch 35 Batch 100 Loss 0.1929 Accuracy 0.2757\n",
            "Epoch 35 Batch 150 Loss 0.1939 Accuracy 0.2762\n",
            "Epoch 35 Batch 200 Loss 0.1971 Accuracy 0.2763\n",
            "Epoch 35 Batch 250 Loss 0.1983 Accuracy 0.2757\n",
            "Epoch 35 Batch 300 Loss 0.2012 Accuracy 0.2742\n",
            "Epoch 35 Batch 350 Loss 0.2041 Accuracy 0.2736\n",
            "Epoch 35 Batch 400 Loss 0.2042 Accuracy 0.2741\n",
            "Saving checkpoint for epoch 35 at ./checkpoints/train/ckpt-7\n",
            "Epoch 35 Loss 0.2042 Accuracy 0.2742\n",
            "Time taken for 1 epoch: 33.43785214424133 secs\n",
            "\n",
            "Epoch 36 Batch 0 Loss 0.1358 Accuracy 0.3082\n",
            "Epoch 36 Batch 50 Loss 0.1756 Accuracy 0.2760\n",
            "Epoch 36 Batch 100 Loss 0.1833 Accuracy 0.2783\n",
            "Epoch 36 Batch 150 Loss 0.1882 Accuracy 0.2767\n",
            "Epoch 36 Batch 200 Loss 0.1902 Accuracy 0.2775\n",
            "Epoch 36 Batch 250 Loss 0.1933 Accuracy 0.2762\n",
            "Epoch 36 Batch 300 Loss 0.1959 Accuracy 0.2757\n",
            "Epoch 36 Batch 350 Loss 0.1973 Accuracy 0.2749\n",
            "Epoch 36 Batch 400 Loss 0.1982 Accuracy 0.2748\n",
            "Epoch 36 Loss 0.1982 Accuracy 0.2747\n",
            "Time taken for 1 epoch: 33.02584266662598 secs\n",
            "\n",
            "Epoch 37 Batch 0 Loss 0.1593 Accuracy 0.3157\n",
            "Epoch 37 Batch 50 Loss 0.1701 Accuracy 0.2814\n",
            "Epoch 37 Batch 100 Loss 0.1758 Accuracy 0.2782\n",
            "Epoch 37 Batch 150 Loss 0.1776 Accuracy 0.2779\n",
            "Epoch 37 Batch 200 Loss 0.1814 Accuracy 0.2776\n",
            "Epoch 37 Batch 250 Loss 0.1841 Accuracy 0.2770\n",
            "Epoch 37 Batch 300 Loss 0.1860 Accuracy 0.2768\n",
            "Epoch 37 Batch 350 Loss 0.1877 Accuracy 0.2760\n",
            "Epoch 37 Batch 400 Loss 0.1916 Accuracy 0.2754\n",
            "Epoch 37 Loss 0.1919 Accuracy 0.2755\n",
            "Time taken for 1 epoch: 33.150288581848145 secs\n",
            "\n",
            "Epoch 38 Batch 0 Loss 0.1472 Accuracy 0.2904\n",
            "Epoch 38 Batch 50 Loss 0.1674 Accuracy 0.2777\n",
            "Epoch 38 Batch 100 Loss 0.1706 Accuracy 0.2773\n",
            "Epoch 38 Batch 150 Loss 0.1765 Accuracy 0.2773\n",
            "Epoch 38 Batch 200 Loss 0.1783 Accuracy 0.2765\n",
            "Epoch 38 Batch 250 Loss 0.1809 Accuracy 0.2760\n",
            "Epoch 38 Batch 300 Loss 0.1821 Accuracy 0.2748\n",
            "Epoch 38 Batch 350 Loss 0.1850 Accuracy 0.2749\n",
            "Epoch 38 Batch 400 Loss 0.1846 Accuracy 0.2760\n",
            "Epoch 38 Loss 0.1847 Accuracy 0.2759\n",
            "Time taken for 1 epoch: 33.110533237457275 secs\n",
            "\n",
            "Epoch 39 Batch 0 Loss 0.1919 Accuracy 0.2538\n",
            "Epoch 39 Batch 50 Loss 0.1739 Accuracy 0.2786\n",
            "Epoch 39 Batch 100 Loss 0.1697 Accuracy 0.2770\n",
            "Epoch 39 Batch 150 Loss 0.1719 Accuracy 0.2772\n",
            "Epoch 39 Batch 200 Loss 0.1724 Accuracy 0.2773\n",
            "Epoch 39 Batch 250 Loss 0.1752 Accuracy 0.2772\n",
            "Epoch 39 Batch 300 Loss 0.1778 Accuracy 0.2768\n",
            "Epoch 39 Batch 350 Loss 0.1791 Accuracy 0.2766\n",
            "Epoch 39 Batch 400 Loss 0.1802 Accuracy 0.2765\n",
            "Epoch 39 Loss 0.1803 Accuracy 0.2766\n",
            "Time taken for 1 epoch: 33.03303241729736 secs\n",
            "\n",
            "Epoch 40 Batch 0 Loss 0.1102 Accuracy 0.3093\n",
            "Epoch 40 Batch 50 Loss 0.1544 Accuracy 0.2749\n",
            "Epoch 40 Batch 100 Loss 0.1557 Accuracy 0.2792\n",
            "Epoch 40 Batch 150 Loss 0.1611 Accuracy 0.2790\n",
            "Epoch 40 Batch 200 Loss 0.1628 Accuracy 0.2792\n",
            "Epoch 40 Batch 250 Loss 0.1672 Accuracy 0.2778\n",
            "Epoch 40 Batch 300 Loss 0.1704 Accuracy 0.2773\n",
            "Epoch 40 Batch 350 Loss 0.1717 Accuracy 0.2775\n",
            "Epoch 40 Batch 400 Loss 0.1737 Accuracy 0.2772\n",
            "Saving checkpoint for epoch 40 at ./checkpoints/train/ckpt-8\n",
            "Epoch 40 Loss 0.1741 Accuracy 0.2773\n",
            "Time taken for 1 epoch: 33.32665252685547 secs\n",
            "\n",
            "Epoch 41 Batch 0 Loss 0.0928 Accuracy 0.2947\n",
            "Epoch 41 Batch 50 Loss 0.1495 Accuracy 0.2813\n",
            "Epoch 41 Batch 100 Loss 0.1527 Accuracy 0.2808\n",
            "Epoch 41 Batch 150 Loss 0.1553 Accuracy 0.2792\n",
            "Epoch 41 Batch 200 Loss 0.1607 Accuracy 0.2787\n",
            "Epoch 41 Batch 250 Loss 0.1634 Accuracy 0.2780\n",
            "Epoch 41 Batch 300 Loss 0.1646 Accuracy 0.2782\n",
            "Epoch 41 Batch 350 Loss 0.1668 Accuracy 0.2786\n",
            "Epoch 41 Batch 400 Loss 0.1691 Accuracy 0.2780\n",
            "Epoch 41 Loss 0.1694 Accuracy 0.2777\n",
            "Time taken for 1 epoch: 32.88954997062683 secs\n",
            "\n",
            "Epoch 42 Batch 0 Loss 0.1155 Accuracy 0.2947\n",
            "Epoch 42 Batch 50 Loss 0.1567 Accuracy 0.2851\n",
            "Epoch 42 Batch 100 Loss 0.1549 Accuracy 0.2820\n",
            "Epoch 42 Batch 150 Loss 0.1578 Accuracy 0.2785\n",
            "Epoch 42 Batch 200 Loss 0.1594 Accuracy 0.2801\n",
            "Epoch 42 Batch 250 Loss 0.1603 Accuracy 0.2796\n",
            "Epoch 42 Batch 300 Loss 0.1618 Accuracy 0.2788\n",
            "Epoch 42 Batch 350 Loss 0.1623 Accuracy 0.2788\n",
            "Epoch 42 Batch 400 Loss 0.1626 Accuracy 0.2782\n",
            "Epoch 42 Loss 0.1630 Accuracy 0.2783\n",
            "Time taken for 1 epoch: 33.0611515045166 secs\n",
            "\n",
            "Epoch 43 Batch 0 Loss 0.1692 Accuracy 0.2419\n",
            "Epoch 43 Batch 50 Loss 0.1448 Accuracy 0.2817\n",
            "Epoch 43 Batch 100 Loss 0.1428 Accuracy 0.2839\n",
            "Epoch 43 Batch 150 Loss 0.1459 Accuracy 0.2835\n",
            "Epoch 43 Batch 200 Loss 0.1508 Accuracy 0.2818\n",
            "Epoch 43 Batch 250 Loss 0.1540 Accuracy 0.2809\n",
            "Epoch 43 Batch 300 Loss 0.1558 Accuracy 0.2802\n",
            "Epoch 43 Batch 350 Loss 0.1570 Accuracy 0.2796\n",
            "Epoch 43 Batch 400 Loss 0.1590 Accuracy 0.2788\n",
            "Epoch 43 Loss 0.1596 Accuracy 0.2786\n",
            "Time taken for 1 epoch: 33.04896664619446 secs\n",
            "\n",
            "Epoch 44 Batch 0 Loss 0.1296 Accuracy 0.2823\n",
            "Epoch 44 Batch 50 Loss 0.1424 Accuracy 0.2858\n",
            "Epoch 44 Batch 100 Loss 0.1405 Accuracy 0.2808\n",
            "Epoch 44 Batch 150 Loss 0.1430 Accuracy 0.2808\n",
            "Epoch 44 Batch 200 Loss 0.1446 Accuracy 0.2807\n",
            "Epoch 44 Batch 250 Loss 0.1496 Accuracy 0.2804\n",
            "Epoch 44 Batch 300 Loss 0.1511 Accuracy 0.2800\n",
            "Epoch 44 Batch 350 Loss 0.1519 Accuracy 0.2796\n",
            "Epoch 44 Batch 400 Loss 0.1531 Accuracy 0.2796\n",
            "Epoch 44 Loss 0.1533 Accuracy 0.2794\n",
            "Time taken for 1 epoch: 33.025185346603394 secs\n",
            "\n",
            "Epoch 45 Batch 0 Loss 0.0992 Accuracy 0.2732\n",
            "Epoch 45 Batch 50 Loss 0.1337 Accuracy 0.2828\n",
            "Epoch 45 Batch 100 Loss 0.1354 Accuracy 0.2818\n",
            "Epoch 45 Batch 150 Loss 0.1377 Accuracy 0.2813\n",
            "Epoch 45 Batch 200 Loss 0.1416 Accuracy 0.2818\n",
            "Epoch 45 Batch 250 Loss 0.1437 Accuracy 0.2813\n",
            "Epoch 45 Batch 300 Loss 0.1440 Accuracy 0.2806\n",
            "Epoch 45 Batch 350 Loss 0.1462 Accuracy 0.2801\n",
            "Epoch 45 Batch 400 Loss 0.1478 Accuracy 0.2799\n",
            "Saving checkpoint for epoch 45 at ./checkpoints/train/ckpt-9\n",
            "Epoch 45 Loss 0.1484 Accuracy 0.2797\n",
            "Time taken for 1 epoch: 33.576679944992065 secs\n",
            "\n",
            "Epoch 46 Batch 0 Loss 0.1233 Accuracy 0.2893\n",
            "Epoch 46 Batch 50 Loss 0.1316 Accuracy 0.2846\n",
            "Epoch 46 Batch 100 Loss 0.1330 Accuracy 0.2863\n",
            "Epoch 46 Batch 150 Loss 0.1346 Accuracy 0.2848\n",
            "Epoch 46 Batch 200 Loss 0.1372 Accuracy 0.2835\n",
            "Epoch 46 Batch 250 Loss 0.1396 Accuracy 0.2824\n",
            "Epoch 46 Batch 300 Loss 0.1415 Accuracy 0.2812\n",
            "Epoch 46 Batch 350 Loss 0.1439 Accuracy 0.2814\n",
            "Epoch 46 Batch 400 Loss 0.1463 Accuracy 0.2804\n",
            "Epoch 46 Loss 0.1465 Accuracy 0.2800\n",
            "Time taken for 1 epoch: 33.048850774765015 secs\n",
            "\n",
            "Epoch 47 Batch 0 Loss 0.1527 Accuracy 0.2592\n",
            "Epoch 47 Batch 50 Loss 0.1297 Accuracy 0.2829\n",
            "Epoch 47 Batch 100 Loss 0.1308 Accuracy 0.2796\n",
            "Epoch 47 Batch 150 Loss 0.1346 Accuracy 0.2799\n",
            "Epoch 47 Batch 200 Loss 0.1384 Accuracy 0.2805\n",
            "Epoch 47 Batch 250 Loss 0.1385 Accuracy 0.2813\n",
            "Epoch 47 Batch 300 Loss 0.1397 Accuracy 0.2800\n",
            "Epoch 47 Batch 350 Loss 0.1413 Accuracy 0.2802\n",
            "Epoch 47 Batch 400 Loss 0.1428 Accuracy 0.2801\n",
            "Epoch 47 Loss 0.1429 Accuracy 0.2804\n",
            "Time taken for 1 epoch: 32.825324058532715 secs\n",
            "\n",
            "Epoch 48 Batch 0 Loss 0.1107 Accuracy 0.3114\n",
            "Epoch 48 Batch 50 Loss 0.1172 Accuracy 0.2845\n",
            "Epoch 48 Batch 100 Loss 0.1218 Accuracy 0.2812\n",
            "Epoch 48 Batch 150 Loss 0.1291 Accuracy 0.2804\n",
            "Epoch 48 Batch 200 Loss 0.1308 Accuracy 0.2802\n",
            "Epoch 48 Batch 250 Loss 0.1331 Accuracy 0.2805\n",
            "Epoch 48 Batch 300 Loss 0.1340 Accuracy 0.2794\n",
            "Epoch 48 Batch 350 Loss 0.1346 Accuracy 0.2812\n",
            "Epoch 48 Batch 400 Loss 0.1364 Accuracy 0.2811\n",
            "Epoch 48 Loss 0.1367 Accuracy 0.2810\n",
            "Time taken for 1 epoch: 32.790619134902954 secs\n",
            "\n",
            "Epoch 49 Batch 0 Loss 0.0611 Accuracy 0.2985\n",
            "Epoch 49 Batch 50 Loss 0.1177 Accuracy 0.2900\n",
            "Epoch 49 Batch 100 Loss 0.1194 Accuracy 0.2868\n",
            "Epoch 49 Batch 150 Loss 0.1193 Accuracy 0.2846\n",
            "Epoch 49 Batch 200 Loss 0.1250 Accuracy 0.2827\n",
            "Epoch 49 Batch 250 Loss 0.1263 Accuracy 0.2833\n",
            "Epoch 49 Batch 300 Loss 0.1287 Accuracy 0.2828\n",
            "Epoch 49 Batch 350 Loss 0.1320 Accuracy 0.2821\n",
            "Epoch 49 Batch 400 Loss 0.1337 Accuracy 0.2813\n",
            "Epoch 49 Loss 0.1338 Accuracy 0.2813\n",
            "Time taken for 1 epoch: 32.94604969024658 secs\n",
            "\n",
            "Epoch 50 Batch 0 Loss 0.0879 Accuracy 0.3195\n",
            "Epoch 50 Batch 50 Loss 0.1165 Accuracy 0.2865\n",
            "Epoch 50 Batch 100 Loss 0.1181 Accuracy 0.2805\n",
            "Epoch 50 Batch 150 Loss 0.1221 Accuracy 0.2807\n",
            "Epoch 50 Batch 200 Loss 0.1241 Accuracy 0.2809\n",
            "Epoch 50 Batch 250 Loss 0.1248 Accuracy 0.2821\n",
            "Epoch 50 Batch 300 Loss 0.1261 Accuracy 0.2818\n",
            "Epoch 50 Batch 350 Loss 0.1271 Accuracy 0.2822\n",
            "Epoch 50 Batch 400 Loss 0.1286 Accuracy 0.2816\n",
            "Saving checkpoint for epoch 50 at ./checkpoints/train/ckpt-10\n",
            "Epoch 50 Loss 0.1291 Accuracy 0.2817\n",
            "Time taken for 1 epoch: 33.264110803604126 secs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QfcsSWswSdGV"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTPOYBJNqTqe",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y6APsFrgImLW"
      },
      "source": [
        "The following steps are used for evaluation:\n",
        "\n",
        "* Encode the input sentence using the Portuguese tokenizer (`tokenizer_pt`). Moreover, add the start and end token so the input is equivalent to what the model is trained with. This is the encoder input.\n",
        "* The decoder input is the `start token == tokenizer_en.vocab_size`.\n",
        "* Calculate the padding masks and the look ahead masks.\n",
        "* The `decoder` then outputs the predictions by looking at the `encoder output` and its own output (self-attention).\n",
        "* Select the last word and calculate the argmax of that.\n",
        "* Concatentate the predicted word to the decoder input as pass it to the decoder.\n",
        "* In this approach, the decoder predicts the next word based on the previous words it predicted.\n",
        "\n",
        "Note: The model used here has less capacity to keep the example relatively faster so the predictions maybe less right. To reproduce the results in the paper, use the entire dataset and base transformer model or transformer XL, by changing the hyperparameters above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR5FQmjw_dAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 62"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5buvMlnvyrFm",
        "colab": {}
      },
      "source": [
        "def evaluate(word):\n",
        "  inputs = [char2idxEn[i] for i in (word)]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=maxlen_inp, padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "  # print(inputs)\n",
        "  # start_token = [tokenizer_pt.vocab_size]\n",
        "  # end_token = [tokenizer_pt.vocab_size + 1]\n",
        "  \n",
        "  # inp sentence is portuguese, hence adding the start and end token\n",
        "  # inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
        "  encoder_input = inputs\n",
        "  # print(encoder_input)\n",
        "  # as the target is english, the first word to the transformer should be the\n",
        "  # english start token.\n",
        "  decoder_input = [char2idxHi[word[0]]]\n",
        "  output = tf.expand_dims(decoder_input, 0)\n",
        "  # print(\"check1 passed\")\n",
        "  for i in range(MAX_LENGTH):\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "        encoder_input, output)\n",
        "    # print(\"check2 passed\")\n",
        "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "    predictions = transformer(encoder_input, output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask,num_heads, maxlen_targ, BATCH_SIZE)\n",
        "    # print(\"check3 passed\")\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "    \n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if predicted_id == char2idxHi['@']:\n",
        "      return tf.squeeze(output, axis=0)\n",
        "    \n",
        "    # concatentate the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "  return tf.squeeze(output, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lU2_yG_vBGza",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "  \n",
        "  result = evaluate(sentence)\n",
        "  predicted_sentence = \"\"\n",
        "  # print(result)\n",
        "  for i in result:\n",
        "    if i >= len(special_words)+2:\n",
        "      predicted_sentence += idx2charHi[i.numpy()]\n",
        "  print(predicted_sentence)\n",
        " \n",
        "  # print(predicted_sentence)  \n",
        "\n",
        "  # print('Input: {}'.format(sentence))\n",
        "  # print('Predicted translation: {}'.format(predicted_sentence))\n",
        "  \n",
        "  # if plot:\n",
        "  #   plot_attention_weights(attention_weights, sentence, result, plot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4ygXkf1awiT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a886b90a-3997-415f-868d-1a203f54fe9f"
      },
      "source": [
        "idx2charHi[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YsxrAlvFG8SZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f916938-3e7a-4179-b9dd-0d9b5c583d49"
      },
      "source": [
        "translate(\"$priyanka@\")\n",
        "# print (\"Real translation: this is a problem we have to solve .\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "प्रियांका\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEFcg9Y1xJzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "special_chars = special_words\n",
        "special_chars.append('@')\n",
        "special_chars.append('<')\n",
        "special_char_set = set(special_chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrms1PbslaAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @tf.function\n",
        "def predictAccuracyBg(mismatch_pair,strmismatch):\n",
        "  ip = \"\";\n",
        "  cnt = 0;\n",
        "  output = \"\";\n",
        "  trueVal = \"\";\n",
        "  cnt2char = 0;\n",
        "  totalcharcnt = 0;\n",
        "  avgmismatch = 0;\n",
        "  mismatchcnt = 0;\n",
        "  total_bangla_word = 0\n",
        "  l = (int)(len(input_tensor_val));\n",
        "  for i in range(0, l):\n",
        "    print(100*i/l, \"% completed\")\n",
        "    input_word = input_tensor_val[i];\n",
        "    target_word = target_tensor_val[i];\n",
        "    if(input_word[0] != char2idxEn[\"%\"]):\n",
        "      continue\n",
        "    total_bangla_word += 1\n",
        "    for r in input_word:\n",
        "      if(r == 0):\n",
        "        break\n",
        "      else: \n",
        "        ip += idx2charEn[r]\n",
        "    # print(\"hi\")\n",
        "    result = evaluate(ip)\n",
        "    \n",
        "    for k in result:\n",
        "      if (idx2charHi[k.numpy()] not in special_char_set):\n",
        "        output += idx2charHi[k.numpy()]\n",
        "    # print(output)\n",
        "    # print(\"hilo\")\n",
        "    # print(word)\n",
        "    for r in target_word:\n",
        "      if(idx2charHi[r] not in special_char_set):\n",
        "        trueVal += idx2charHi[r]\n",
        "    print(trueVal+\"  : \"+output);\n",
        "    # print(output)\n",
        "    if(len(output) == len(trueVal)):\n",
        "      wordlen = len(trueVal);\n",
        "      totalcharcnt += int(wordlen);\n",
        "      tempcnt = 0;\n",
        "      for k in range(0,int(wordlen)):\n",
        "        if(output[k] == trueVal[k]):\n",
        "          cnt2char +=  1;\n",
        "        else :\n",
        "          mismatch_pair.append({output[k], trueVal[k]});\n",
        "          strmismatch += output[k];\n",
        "          tempcnt += 1;\n",
        "          mismatchcnt += 1;\n",
        "      avgmismatch += (tempcnt/wordlen);\n",
        "    if(output==trueVal):\n",
        "      cnt = cnt+1; \n",
        "    ip = \"\"\n",
        "    output = \"\"\n",
        "    trueVal = \"\"\n",
        "    \n",
        "  print(100*cnt/(int(total_bangla_word)))\n",
        "  print(100*cnt2char/totalcharcnt);\n",
        "  print(avgmismatch/(l-cnt));\n",
        "  print(set(strmismatch));\n",
        "  return 100*cnt/(int(l)), 100*cnt2char/totalcharcnt, (avgmismatch/(l-cnt)), set(strmismatch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7EH5y_aqI4t1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d67c62da-4bfc-45b9-e328-bcfafe83866b"
      },
      "source": [
        "mismatch_pair = [];\n",
        "strmismatch = \"\";\n",
        "a,b,c,d = predictAccuracyBg(mismatch_pair,strmismatch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 % completed\n",
            "0.05060728744939271 % completed\n",
            "0.10121457489878542 % completed\n",
            "0.15182186234817813 % completed\n",
            "0.20242914979757085 % completed\n",
            "0.25303643724696356 % completed\n",
            "0.30364372469635625 % completed\n",
            "0.354251012145749 % completed\n",
            "0.4048582995951417 % completed\n",
            "0.45546558704453444 % completed\n",
            "0.5060728744939271 % completed\n",
            "0.5566801619433198 % completed\n",
            "0.6072874493927125 % completed\n",
            "0.6578947368421053 % completed\n",
            "0.708502024291498 % completed\n",
            "0.7591093117408907 % completed\n",
            "0.8097165991902834 % completed\n",
            "0.8603238866396761 % completed\n",
            "0.9109311740890689 % completed\n",
            "0.9615384615384616 % completed\n",
            "1.0121457489878543 % completed\n",
            "1.062753036437247 % completed\n",
            "1.1133603238866396 % completed\n",
            "1.1639676113360324 % completed\n",
            "1.214574898785425 % completed\n",
            "1.2651821862348178 % completed\n",
            "1.3157894736842106 % completed\n",
            "1.3663967611336032 % completed\n",
            "1.417004048582996 % completed\n",
            "1.4676113360323886 % completed\n",
            "1.5182186234817814 % completed\n",
            "1.5688259109311742 % completed\n",
            "1.6194331983805668 % completed\n",
            "1.6700404858299596 % completed\n",
            "1.7206477732793521 % completed\n",
            "1.771255060728745 % completed\n",
            "1.8218623481781377 % completed\n",
            "1.8724696356275303 % completed\n",
            "1.9230769230769231 % completed\n",
            "1.9736842105263157 % completed\n",
            "2.0242914979757085 % completed\n",
            "2.074898785425101 % completed\n",
            "2.125506072874494 % completed\n",
            "2.1761133603238867 % completed\n",
            "2.2267206477732793 % completed\n",
            "2.277327935222672 % completed\n",
            "2.327935222672065 % completed\n",
            "2.3785425101214575 % completed\n",
            "2.42914979757085 % completed\n",
            "2.479757085020243 % completed\n",
            "2.5303643724696356 % completed\n",
            "2.580971659919028 % completed\n",
            "2.6315789473684212 % completed\n",
            "2.682186234817814 % completed\n",
            "2.7327935222672064 % completed\n",
            "2.783400809716599 % completed\n",
            "2.834008097165992 % completed\n",
            "2.8846153846153846 % completed\n",
            "2.935222672064777 % completed\n",
            "2.98582995951417 % completed\n",
            "3.0364372469635628 % completed\n",
            "3.0870445344129553 % completed\n",
            "3.1376518218623484 % completed\n",
            "3.188259109311741 % completed\n",
            "3.2388663967611335 % completed\n",
            "3.289473684210526 % completed\n",
            "3.340080971659919 % completed\n",
            "3.3906882591093117 % completed\n",
            "3.4412955465587043 % completed\n",
            "3.4919028340080973 % completed\n",
            "3.54251012145749 % completed\n",
            "3.5931174089068825 % completed\n",
            "3.6437246963562755 % completed\n",
            "3.694331983805668 % completed\n",
            "3.7449392712550607 % completed\n",
            "3.7955465587044532 % completed\n",
            "3.8461538461538463 % completed\n",
            "3.896761133603239 % completed\n",
            "3.9473684210526314 % completed\n",
            "3.9979757085020244 % completed\n",
            "4.048582995951417 % completed\n",
            "4.09919028340081 % completed\n",
            "4.149797570850202 % completed\n",
            "4.200404858299595 % completed\n",
            "4.251012145748988 % completed\n",
            "4.301619433198381 % completed\n",
            "4.352226720647773 % completed\n",
            "4.402834008097166 % completed\n",
            "4.4534412955465585 % completed\n",
            "4.504048582995951 % completed\n",
            "4.554655870445344 % completed\n",
            "4.605263157894737 % completed\n",
            "4.65587044534413 % completed\n",
            "4.706477732793522 % completed\n",
            "4.757085020242915 % completed\n",
            "4.8076923076923075 % completed\n",
            "4.8582995951417 % completed\n",
            "4.9089068825910935 % completed\n",
            "4.959514170040486 % completed\n",
            "5.010121457489879 % completed\n",
            "5.060728744939271 % completed\n",
            "5.111336032388664 % completed\n",
            "5.161943319838056 % completed\n",
            "5.212550607287449 % completed\n",
            "5.2631578947368425 % completed\n",
            "5.313765182186235 % completed\n",
            "5.364372469635628 % completed\n",
            "5.41497975708502 % completed\n",
            "5.465587044534413 % completed\n",
            "5.516194331983805 % completed\n",
            "5.566801619433198 % completed\n",
            "5.617408906882591 % completed\n",
            "5.668016194331984 % completed\n",
            "5.718623481781377 % completed\n",
            "5.769230769230769 % completed\n",
            "5.819838056680162 % completed\n",
            "5.870445344129554 % completed\n",
            "5.921052631578948 % completed\n",
            "5.97165991902834 % completed\n",
            "6.022267206477733 % completed\n",
            "6.0728744939271255 % completed\n",
            "6.123481781376518 % completed\n",
            "6.174089068825911 % completed\n",
            "6.224696356275303 % completed\n",
            "6.275303643724697 % completed\n",
            "6.325910931174089 % completed\n",
            "6.376518218623482 % completed\n",
            "6.4271255060728745 % completed\n",
            "6.477732793522267 % completed\n",
            "6.52834008097166 % completed\n",
            "6.578947368421052 % completed\n",
            "6.629554655870446 % completed\n",
            "6.680161943319838 % completed\n",
            "6.730769230769231 % completed\n",
            "6.781376518218623 % completed\n",
            "6.831983805668016 % completed\n",
            "6.882591093117409 % completed\n",
            "6.933198380566802 % completed\n",
            "6.983805668016195 % completed\n",
            "7.034412955465587 % completed\n",
            "7.08502024291498 % completed\n",
            "7.135627530364372 % completed\n",
            "7.186234817813765 % completed\n",
            "7.2368421052631575 % completed\n",
            "7.287449392712551 % completed\n",
            "7.338056680161944 % completed\n",
            "7.388663967611336 % completed\n",
            "7.439271255060729 % completed\n",
            "7.489878542510121 % completed\n",
            "7.540485829959514 % completed\n",
            "7.5910931174089065 % completed\n",
            "7.6417004048583 % completed\n",
            "7.6923076923076925 % completed\n",
            "7.742914979757085 % completed\n",
            "7.793522267206478 % completed\n",
            "7.84412955465587 % completed\n",
            "7.894736842105263 % completed\n",
            "7.945344129554656 % completed\n",
            "7.995951417004049 % completed\n",
            "8.04655870445344 % completed\n",
            "8.097165991902834 % completed\n",
            "8.147773279352228 % completed\n",
            "8.19838056680162 % completed\n",
            "8.248987854251013 % completed\n",
            "8.299595141700404 % completed\n",
            "8.350202429149798 % completed\n",
            "8.40080971659919 % completed\n",
            "8.451417004048583 % completed\n",
            "8.502024291497976 % completed\n",
            "8.552631578947368 % completed\n",
            "8.603238866396762 % completed\n",
            "8.653846153846153 % completed\n",
            "8.704453441295547 % completed\n",
            "8.755060728744938 % completed\n",
            "8.805668016194332 % completed\n",
            "8.856275303643725 % completed\n",
            "8.906882591093117 % completed\n",
            "8.95748987854251 % completed\n",
            "9.008097165991902 % completed\n",
            "9.058704453441296 % completed\n",
            "9.109311740890687 % completed\n",
            "9.15991902834008 % completed\n",
            "9.210526315789474 % completed\n",
            "9.261133603238866 % completed\n",
            "9.31174089068826 % completed\n",
            "9.362348178137651 % completed\n",
            "9.412955465587045 % completed\n",
            "9.463562753036438 % completed\n",
            "9.51417004048583 % completed\n",
            "9.564777327935223 % completed\n",
            "9.615384615384615 % completed\n",
            "9.665991902834008 % completed\n",
            "9.7165991902834 % completed\n",
            "9.767206477732794 % completed\n",
            "9.817813765182187 % completed\n",
            "9.868421052631579 % completed\n",
            "9.919028340080972 % completed\n",
            "9.969635627530364 % completed\n",
            "10.020242914979757 % completed\n",
            "10.070850202429149 % completed\n",
            "10.121457489878543 % completed\n",
            "10.172064777327936 % completed\n",
            "10.222672064777328 % completed\n",
            "10.273279352226721 % completed\n",
            "10.323886639676113 % completed\n",
            "10.374493927125506 % completed\n",
            "10.425101214574898 % completed\n",
            "10.475708502024291 % completed\n",
            "10.526315789473685 % completed\n",
            "10.576923076923077 % completed\n",
            "10.62753036437247 % completed\n",
            "10.678137651821862 % completed\n",
            "10.728744939271255 % completed\n",
            "10.779352226720647 % completed\n",
            "10.82995951417004 % completed\n",
            "10.880566801619434 % completed\n",
            "10.931174089068826 % completed\n",
            "10.981781376518219 % completed\n",
            "11.03238866396761 % completed\n",
            "11.082995951417004 % completed\n",
            "11.133603238866396 % completed\n",
            "11.18421052631579 % completed\n",
            "11.234817813765183 % completed\n",
            "11.285425101214575 % completed\n",
            "11.336032388663968 % completed\n",
            "11.38663967611336 % completed\n",
            "11.437246963562753 % completed\n",
            "11.487854251012147 % completed\n",
            "11.538461538461538 % completed\n",
            "11.589068825910932 % completed\n",
            "11.639676113360323 % completed\n",
            "11.690283400809717 % completed\n",
            "11.740890688259109 % completed\n",
            "11.791497975708502 % completed\n",
            "11.842105263157896 % completed\n",
            "11.892712550607287 % completed\n",
            "11.94331983805668 % completed\n",
            "11.993927125506072 % completed\n",
            "12.044534412955466 % completed\n",
            "12.095141700404858 % completed\n",
            "12.145748987854251 % completed\n",
            "12.196356275303645 % completed\n",
            "12.246963562753036 % completed\n",
            "12.29757085020243 % completed\n",
            "12.348178137651821 % completed\n",
            "12.398785425101215 % completed\n",
            "12.449392712550607 % completed\n",
            "12.5 % completed\n",
            "12.550607287449393 % completed\n",
            "12.601214574898785 % completed\n",
            "12.651821862348179 % completed\n",
            "12.70242914979757 % completed\n",
            "12.753036437246964 % completed\n",
            "12.803643724696355 % completed\n",
            "12.854251012145749 % completed\n",
            "12.904858299595142 % completed\n",
            "12.955465587044534 % completed\n",
            "13.006072874493928 % completed\n",
            "13.05668016194332 % completed\n",
            "13.107287449392713 % completed\n",
            "13.157894736842104 % completed\n",
            "13.208502024291498 % completed\n",
            "13.259109311740891 % completed\n",
            "13.309716599190283 % completed\n",
            "13.360323886639677 % completed\n",
            "13.410931174089068 % completed\n",
            "13.461538461538462 % completed\n",
            "13.512145748987853 % completed\n",
            "13.562753036437247 % completed\n",
            "13.61336032388664 % completed\n",
            "13.663967611336032 % completed\n",
            "13.714574898785425 % completed\n",
            "13.765182186234817 % completed\n",
            "13.81578947368421 % completed\n",
            "13.866396761133604 % completed\n",
            "13.917004048582996 % completed\n",
            "13.96761133603239 % completed\n",
            "14.018218623481781 % completed\n",
            "14.068825910931174 % completed\n",
            "14.119433198380566 % completed\n",
            "14.17004048582996 % completed\n",
            "14.220647773279353 % completed\n",
            "14.271255060728745 % completed\n",
            "14.321862348178138 % completed\n",
            "14.37246963562753 % completed\n",
            "14.423076923076923 % completed\n",
            "14.473684210526315 % completed\n",
            "14.524291497975709 % completed\n",
            "14.574898785425102 % completed\n",
            "14.625506072874494 % completed\n",
            "14.676113360323887 % completed\n",
            "14.726720647773279 % completed\n",
            "14.777327935222672 % completed\n",
            "14.827935222672064 % completed\n",
            "14.878542510121457 % completed\n",
            "14.929149797570851 % completed\n",
            "14.979757085020243 % completed\n",
            "15.030364372469636 % completed\n",
            "15.080971659919028 % completed\n",
            "15.131578947368421 % completed\n",
            "15.182186234817813 % completed\n",
            "15.232793522267206 % completed\n",
            "15.2834008097166 % completed\n",
            "15.334008097165992 % completed\n",
            "15.384615384615385 % completed\n",
            "15.435222672064777 % completed\n",
            "15.48582995951417 % completed\n",
            "15.536437246963562 % completed\n",
            "15.587044534412955 % completed\n",
            "15.637651821862349 % completed\n",
            "15.68825910931174 % completed\n",
            "15.738866396761134 % completed\n",
            "15.789473684210526 % completed\n",
            "15.84008097165992 % completed\n",
            "15.890688259109313 % completed\n",
            "15.941295546558704 % completed\n",
            "15.991902834008098 % completed\n",
            "16.04251012145749 % completed\n",
            "16.09311740890688 % completed\n",
            "16.143724696356276 % completed\n",
            "16.194331983805668 % completed\n",
            "16.24493927125506 % completed\n",
            "16.295546558704455 % completed\n",
            "16.346153846153847 % completed\n",
            "16.39676113360324 % completed\n",
            "16.44736842105263 % completed\n",
            "16.497975708502025 % completed\n",
            "16.548582995951417 % completed\n",
            "16.59919028340081 % completed\n",
            "16.649797570850204 % completed\n",
            "16.700404858299596 % completed\n",
            "16.751012145748987 % completed\n",
            "16.80161943319838 % completed\n",
            "16.852226720647774 % completed\n",
            "16.902834008097166 % completed\n",
            "16.953441295546558 % completed\n",
            "17.004048582995953 % completed\n",
            "17.054655870445345 % completed\n",
            "17.105263157894736 % completed\n",
            "17.155870445344128 % completed\n",
            "17.206477732793523 % completed\n",
            "17.257085020242915 % completed\n",
            "17.307692307692307 % completed\n",
            "17.358299595141702 % completed\n",
            "17.408906882591094 % completed\n",
            "17.459514170040485 % completed\n",
            "17.510121457489877 % completed\n",
            "17.560728744939272 % completed\n",
            "17.611336032388664 % completed\n",
            "17.661943319838056 % completed\n",
            "17.71255060728745 % completed\n",
            "17.763157894736842 % completed\n",
            "17.813765182186234 % completed\n",
            "17.864372469635626 % completed\n",
            "17.91497975708502 % completed\n",
            "17.965587044534413 % completed\n",
            "18.016194331983804 % completed\n",
            "18.0668016194332 % completed\n",
            "18.11740890688259 % completed\n",
            "18.168016194331983 % completed\n",
            "18.218623481781375 % completed\n",
            "18.26923076923077 % completed\n",
            "18.31983805668016 % completed\n",
            "18.370445344129553 % completed\n",
            "18.42105263157895 % completed\n",
            "18.47165991902834 % completed\n",
            "18.522267206477732 % completed\n",
            "18.572874493927124 % completed\n",
            "18.62348178137652 % completed\n",
            "18.67408906882591 % completed\n",
            "18.724696356275302 % completed\n",
            "18.775303643724698 % completed\n",
            "18.82591093117409 % completed\n",
            "18.87651821862348 % completed\n",
            "18.927125506072876 % completed\n",
            "18.977732793522268 % completed\n",
            "19.02834008097166 % completed\n",
            "19.07894736842105 % completed\n",
            "19.129554655870447 % completed\n",
            "19.18016194331984 % completed\n",
            "19.23076923076923 % completed\n",
            "19.281376518218625 % completed\n",
            "19.331983805668017 % completed\n",
            "19.38259109311741 % completed\n",
            "19.4331983805668 % completed\n",
            "19.483805668016196 % completed\n",
            "19.534412955465587 % completed\n",
            "19.58502024291498 % completed\n",
            "19.635627530364374 % completed\n",
            "19.686234817813766 % completed\n",
            "19.736842105263158 % completed\n",
            "19.78744939271255 % completed\n",
            "19.838056680161944 % completed\n",
            "19.888663967611336 % completed\n",
            "19.939271255060728 % completed\n",
            "19.989878542510123 % completed\n",
            "20.040485829959515 % completed\n",
            "20.091093117408906 % completed\n",
            "20.141700404858298 % completed\n",
            "20.192307692307693 % completed\n",
            "20.242914979757085 % completed\n",
            "20.293522267206477 % completed\n",
            "20.344129554655872 % completed\n",
            "20.394736842105264 % completed\n",
            "20.445344129554655 % completed\n",
            "20.495951417004047 % completed\n",
            "20.546558704453442 % completed\n",
            "20.597165991902834 % completed\n",
            "20.647773279352226 % completed\n",
            "20.69838056680162 % completed\n",
            "20.748987854251013 % completed\n",
            "20.799595141700404 % completed\n",
            "20.850202429149796 % completed\n",
            "20.90080971659919 % completed\n",
            "20.951417004048583 % completed\n",
            "21.002024291497975 % completed\n",
            "21.05263157894737 % completed\n",
            "21.10323886639676 % completed\n",
            "21.153846153846153 % completed\n",
            "21.204453441295545 % completed\n",
            "21.25506072874494 % completed\n",
            "21.305668016194332 % completed\n",
            "21.356275303643724 % completed\n",
            "21.40688259109312 % completed\n",
            "21.45748987854251 % completed\n",
            "21.508097165991902 % completed\n",
            "21.558704453441294 % completed\n",
            "21.60931174089069 % completed\n",
            "21.65991902834008 % completed\n",
            "21.710526315789473 % completed\n",
            "21.761133603238868 % completed\n",
            "21.81174089068826 % completed\n",
            "21.86234817813765 % completed\n",
            "21.912955465587043 % completed\n",
            "21.963562753036438 % completed\n",
            "22.01417004048583 % completed\n",
            "22.06477732793522 % completed\n",
            "22.115384615384617 % completed\n",
            "22.16599190283401 % completed\n",
            "22.2165991902834 % completed\n",
            "22.267206477732792 % completed\n",
            "22.317813765182187 % completed\n",
            "22.36842105263158 % completed\n",
            "22.41902834008097 % completed\n",
            "22.469635627530366 % completed\n",
            "22.520242914979757 % completed\n",
            "22.57085020242915 % completed\n",
            "22.62145748987854 % completed\n",
            "22.672064777327936 % completed\n",
            "22.722672064777328 % completed\n",
            "22.77327935222672 % completed\n",
            "22.823886639676115 % completed\n",
            "22.874493927125506 % completed\n",
            "22.925101214574898 % completed\n",
            "22.975708502024293 % completed\n",
            "23.026315789473685 % completed\n",
            "23.076923076923077 % completed\n",
            "23.12753036437247 % completed\n",
            "23.178137651821864 % completed\n",
            "23.228744939271255 % completed\n",
            "23.279352226720647 % completed\n",
            "23.329959514170042 % completed\n",
            "23.380566801619434 % completed\n",
            "23.431174089068826 % completed\n",
            "23.481781376518217 % completed\n",
            "23.532388663967613 % completed\n",
            "23.582995951417004 % completed\n",
            "23.633603238866396 % completed\n",
            "23.68421052631579 % completed\n",
            "23.734817813765183 % completed\n",
            "23.785425101214575 % completed\n",
            "23.836032388663966 % completed\n",
            "23.88663967611336 % completed\n",
            "23.937246963562753 % completed\n",
            "23.987854251012145 % completed\n",
            "24.03846153846154 % completed\n",
            "24.089068825910932 % completed\n",
            "24.139676113360323 % completed\n",
            "24.190283400809715 % completed\n",
            "24.24089068825911 % completed\n",
            "24.291497975708502 % completed\n",
            "24.342105263157894 % completed\n",
            "24.39271255060729 % completed\n",
            "24.44331983805668 % completed\n",
            "24.493927125506072 % completed\n",
            "24.544534412955464 % completed\n",
            "24.59514170040486 % completed\n",
            "24.64574898785425 % completed\n",
            "24.696356275303643 % completed\n",
            "24.746963562753038 % completed\n",
            "24.79757085020243 % completed\n",
            "24.84817813765182 % completed\n",
            "24.898785425101213 % completed\n",
            "24.94939271255061 % completed\n",
            "25.0 % completed\n",
            "25.05060728744939 % completed\n",
            "25.101214574898787 % completed\n",
            "25.15182186234818 % completed\n",
            "25.20242914979757 % completed\n",
            "25.253036437246962 % completed\n",
            "25.303643724696357 % completed\n",
            "25.35425101214575 % completed\n",
            "25.40485829959514 % completed\n",
            "25.455465587044536 % completed\n",
            "25.506072874493928 % completed\n",
            "25.55668016194332 % completed\n",
            "25.60728744939271 % completed\n",
            "25.657894736842106 % completed\n",
            "25.708502024291498 % completed\n",
            "25.75910931174089 % completed\n",
            "25.809716599190285 % completed\n",
            "25.860323886639677 % completed\n",
            "25.910931174089068 % completed\n",
            "25.96153846153846 % completed\n",
            "26.012145748987855 % completed\n",
            "26.062753036437247 % completed\n",
            "26.11336032388664 % completed\n",
            "26.163967611336034 % completed\n",
            "26.214574898785425 % completed\n",
            "26.265182186234817 % completed\n",
            "26.31578947368421 % completed\n",
            "26.366396761133604 % completed\n",
            "26.417004048582996 % completed\n",
            "26.467611336032387 % completed\n",
            "26.518218623481783 % completed\n",
            "26.568825910931174 % completed\n",
            "26.619433198380566 % completed\n",
            "26.670040485829958 % completed\n",
            "26.720647773279353 % completed\n",
            "26.771255060728745 % completed\n",
            "26.821862348178136 % completed\n",
            "26.87246963562753 % completed\n",
            "26.923076923076923 % completed\n",
            "26.973684210526315 % completed\n",
            "27.024291497975707 % completed\n",
            "27.074898785425102 % completed\n",
            "27.125506072874494 % completed\n",
            "27.176113360323885 % completed\n",
            "27.22672064777328 % completed\n",
            "27.277327935222672 % completed\n",
            "27.327935222672064 % completed\n",
            "27.37854251012146 % completed\n",
            "27.42914979757085 % completed\n",
            "27.479757085020243 % completed\n",
            "27.530364372469634 % completed\n",
            "27.58097165991903 % completed\n",
            "27.63157894736842 % completed\n",
            "27.682186234817813 % completed\n",
            "27.732793522267208 % completed\n",
            "27.7834008097166 % completed\n",
            "27.83400809716599 % completed\n",
            "27.884615384615383 % completed\n",
            "27.93522267206478 % completed\n",
            "27.98582995951417 % completed\n",
            "28.036437246963562 % completed\n",
            "28.087044534412957 % completed\n",
            "28.13765182186235 % completed\n",
            "28.18825910931174 % completed\n",
            "28.238866396761132 % completed\n",
            "28.289473684210527 % completed\n",
            "28.34008097165992 % completed\n",
            "28.39068825910931 % completed\n",
            "28.441295546558706 % completed\n",
            "28.491902834008098 % completed\n",
            "28.54251012145749 % completed\n",
            "28.59311740890688 % completed\n",
            "28.643724696356276 % completed\n",
            "28.694331983805668 % completed\n",
            "28.74493927125506 % completed\n",
            "28.795546558704455 % completed\n",
            "28.846153846153847 % completed\n",
            "28.89676113360324 % completed\n",
            "28.94736842105263 % completed\n",
            "28.997975708502025 % completed\n",
            "29.048582995951417 % completed\n",
            "29.09919028340081 % completed\n",
            "29.149797570850204 % completed\n",
            "29.200404858299596 % completed\n",
            "29.251012145748987 % completed\n",
            "29.30161943319838 % completed\n",
            "29.352226720647774 % completed\n",
            "29.402834008097166 % completed\n",
            "29.453441295546558 % completed\n",
            "29.504048582995953 % completed\n",
            "29.554655870445345 % completed\n",
            "29.605263157894736 % completed\n",
            "29.655870445344128 % completed\n",
            "29.706477732793523 % completed\n",
            "29.757085020242915 % completed\n",
            "29.807692307692307 % completed\n",
            "29.858299595141702 % completed\n",
            "29.908906882591094 % completed\n",
            "29.959514170040485 % completed\n",
            "30.010121457489877 % completed\n",
            "30.060728744939272 % completed\n",
            "30.111336032388664 % completed\n",
            "30.161943319838056 % completed\n",
            "30.21255060728745 % completed\n",
            "30.263157894736842 % completed\n",
            "30.313765182186234 % completed\n",
            "30.364372469635626 % completed\n",
            "30.41497975708502 % completed\n",
            "30.465587044534413 % completed\n",
            "30.516194331983804 % completed\n",
            "30.5668016194332 % completed\n",
            "30.61740890688259 % completed\n",
            "30.668016194331983 % completed\n",
            "30.718623481781375 % completed\n",
            "30.76923076923077 % completed\n",
            "30.81983805668016 % completed\n",
            "30.870445344129553 % completed\n",
            "30.92105263157895 % completed\n",
            "30.97165991902834 % completed\n",
            "31.022267206477732 % completed\n",
            "31.072874493927124 % completed\n",
            "31.12348178137652 % completed\n",
            "31.17408906882591 % completed\n",
            "31.224696356275302 % completed\n",
            "31.275303643724698 % completed\n",
            "31.32591093117409 % completed\n",
            "31.37651821862348 % completed\n",
            "31.427125506072876 % completed\n",
            "31.477732793522268 % completed\n",
            "31.52834008097166 % completed\n",
            "31.57894736842105 % completed\n",
            "31.629554655870447 % completed\n",
            "31.68016194331984 % completed\n",
            "31.73076923076923 % completed\n",
            "31.781376518218625 % completed\n",
            "31.831983805668017 % completed\n",
            "31.88259109311741 % completed\n",
            "31.9331983805668 % completed\n",
            "31.983805668016196 % completed\n",
            "32.034412955465584 % completed\n",
            "32.08502024291498 % completed\n",
            "32.135627530364374 % completed\n",
            "32.18623481781376 % completed\n",
            "32.23684210526316 % completed\n",
            "32.28744939271255 % completed\n",
            "32.33805668016194 % completed\n",
            "32.388663967611336 % completed\n",
            "32.43927125506073 % completed\n",
            "32.48987854251012 % completed\n",
            "32.540485829959515 % completed\n",
            "32.59109311740891 % completed\n",
            "32.6417004048583 % completed\n",
            "32.69230769230769 % completed\n",
            "32.74291497975708 % completed\n",
            "32.79352226720648 % completed\n",
            "32.84412955465587 % completed\n",
            "32.89473684210526 % completed\n",
            "32.945344129554655 % completed\n",
            "32.99595141700405 % completed\n",
            "33.04655870445344 % completed\n",
            "33.097165991902834 % completed\n",
            "33.14777327935223 % completed\n",
            "33.19838056680162 % completed\n",
            "33.24898785425101 % completed\n",
            "33.29959514170041 % completed\n",
            "33.350202429149796 % completed\n",
            "33.40080971659919 % completed\n",
            "33.45141700404859 % completed\n",
            "33.502024291497975 % completed\n",
            "33.55263157894737 % completed\n",
            "33.60323886639676 % completed\n",
            "33.65384615384615 % completed\n",
            "33.70445344129555 % completed\n",
            "33.75506072874494 % completed\n",
            "33.80566801619433 % completed\n",
            "33.85627530364373 % completed\n",
            "33.906882591093115 % completed\n",
            "33.95748987854251 % completed\n",
            "34.008097165991906 % completed\n",
            "34.058704453441294 % completed\n",
            "34.10931174089069 % completed\n",
            "34.159919028340084 % completed\n",
            "34.21052631578947 % completed\n",
            "34.26113360323887 % completed\n",
            "34.311740890688256 % completed\n",
            "34.36234817813765 % completed\n",
            "34.412955465587046 % completed\n",
            "34.463562753036435 % completed\n",
            "34.51417004048583 % completed\n",
            "34.564777327935225 % completed\n",
            "34.61538461538461 % completed\n",
            "34.66599190283401 % completed\n",
            "34.716599190283404 % completed\n",
            "34.76720647773279 % completed\n",
            "34.81781376518219 % completed\n",
            "34.86842105263158 % completed\n",
            "34.91902834008097 % completed\n",
            "34.969635627530366 % completed\n",
            "35.020242914979754 % completed\n",
            "35.07085020242915 % completed\n",
            "35.121457489878544 % completed\n",
            "35.17206477732793 % completed\n",
            "35.22267206477733 % completed\n",
            "35.27327935222672 % completed\n",
            "35.32388663967611 % completed\n",
            "35.374493927125506 % completed\n",
            "35.4251012145749 % completed\n",
            "35.47570850202429 % completed\n",
            "35.526315789473685 % completed\n",
            "35.57692307692308 % completed\n",
            "35.62753036437247 % completed\n",
            "35.678137651821864 % completed\n",
            "35.72874493927125 % completed\n",
            "35.77935222672065 % completed\n",
            "35.82995951417004 % completed\n",
            "35.88056680161943 % completed\n",
            "35.931174089068826 % completed\n",
            "35.98178137651822 % completed\n",
            "36.03238866396761 % completed\n",
            "36.082995951417004 % completed\n",
            "36.1336032388664 % completed\n",
            "36.18421052631579 % completed\n",
            "36.23481781376518 % completed\n",
            "36.28542510121458 % completed\n",
            "36.336032388663966 % completed\n",
            "36.38663967611336 % completed\n",
            "36.43724696356275 % completed\n",
            "36.487854251012145 % completed\n",
            "36.53846153846154 % completed\n",
            "36.58906882591093 % completed\n",
            "36.63967611336032 % completed\n",
            "36.69028340080972 % completed\n",
            "36.74089068825911 % completed\n",
            "36.7914979757085 % completed\n",
            "36.8421052631579 % completed\n",
            "36.892712550607285 % completed\n",
            "36.94331983805668 % completed\n",
            "36.993927125506076 % completed\n",
            "37.044534412955464 % completed\n",
            "37.09514170040486 % completed\n",
            "37.14574898785425 % completed\n",
            "37.19635627530364 % completed\n",
            "37.24696356275304 % completed\n",
            "37.297570850202426 % completed\n",
            "37.34817813765182 % completed\n",
            "37.39878542510122 % completed\n",
            "37.449392712550605 % completed\n",
            "37.5 % completed\n",
            "37.550607287449395 % completed\n",
            "37.60121457489878 % completed\n",
            "37.65182186234818 % completed\n",
            "37.702429149797574 % completed\n",
            "37.75303643724696 % completed\n",
            "37.80364372469636 % completed\n",
            "37.85425101214575 % completed\n",
            "37.90485829959514 % completed\n",
            "37.955465587044536 % completed\n",
            "38.006072874493924 % completed\n",
            "38.05668016194332 % completed\n",
            "38.107287449392715 % completed\n",
            "38.1578947368421 % completed\n",
            "38.2085020242915 % completed\n",
            "38.25910931174089 % completed\n",
            "38.30971659919028 % completed\n",
            "38.36032388663968 % completed\n",
            "38.41093117408907 % completed\n",
            "38.46153846153846 % completed\n",
            "38.512145748987855 % completed\n",
            "38.56275303643725 % completed\n",
            "38.61336032388664 % completed\n",
            "38.663967611336034 % completed\n",
            "38.71457489878542 % completed\n",
            "38.76518218623482 % completed\n",
            "38.81578947368421 % completed\n",
            "38.8663967611336 % completed\n",
            "38.917004048582996 % completed\n",
            "38.96761133603239 % completed\n",
            "39.01821862348178 % completed\n",
            "39.068825910931174 % completed\n",
            "39.11943319838057 % completed\n",
            "39.17004048582996 % completed\n",
            "39.22064777327935 % completed\n",
            "39.27125506072875 % completed\n",
            "39.321862348178136 % completed\n",
            "39.37246963562753 % completed\n",
            "39.42307692307692 % completed\n",
            "39.473684210526315 % completed\n",
            "39.52429149797571 % completed\n",
            "39.5748987854251 % completed\n",
            "39.625506072874494 % completed\n",
            "39.67611336032389 % completed\n",
            "39.72672064777328 % completed\n",
            "39.77732793522267 % completed\n",
            "39.82793522267207 % completed\n",
            "39.878542510121456 % completed\n",
            "39.92914979757085 % completed\n",
            "39.979757085020246 % completed\n",
            "40.030364372469634 % completed\n",
            "40.08097165991903 % completed\n",
            "40.13157894736842 % completed\n",
            "40.18218623481781 % completed\n",
            "40.23279352226721 % completed\n",
            "40.283400809716596 % completed\n",
            "40.33400809716599 % completed\n",
            "40.38461538461539 % completed\n",
            "40.435222672064775 % completed\n",
            "40.48582995951417 % completed\n",
            "40.536437246963565 % completed\n",
            "40.587044534412954 % completed\n",
            "40.63765182186235 % completed\n",
            "40.688259109311744 % completed\n",
            "40.73886639676113 % completed\n",
            "40.78947368421053 % completed\n",
            "40.840080971659916 % completed\n",
            "40.89068825910931 % completed\n",
            "40.941295546558706 % completed\n",
            "40.991902834008094 % completed\n",
            "41.04251012145749 % completed\n",
            "41.093117408906885 % completed\n",
            "41.14372469635627 % completed\n",
            "41.19433198380567 % completed\n",
            "41.24493927125506 % completed\n",
            "41.29554655870445 % completed\n",
            "41.34615384615385 % completed\n",
            "41.39676113360324 % completed\n",
            "41.44736842105263 % completed\n",
            "41.497975708502025 % completed\n",
            "41.54858299595141 % completed\n",
            "41.59919028340081 % completed\n",
            "41.649797570850204 % completed\n",
            "41.70040485829959 % completed\n",
            "41.75101214574899 % completed\n",
            "41.80161943319838 % completed\n",
            "41.85222672064777 % completed\n",
            "41.902834008097166 % completed\n",
            "41.95344129554656 % completed\n",
            "42.00404858299595 % completed\n",
            "42.054655870445345 % completed\n",
            "42.10526315789474 % completed\n",
            "42.15587044534413 % completed\n",
            "42.20647773279352 % completed\n",
            "42.25708502024292 % completed\n",
            "42.30769230769231 % completed\n",
            "42.3582995951417 % completed\n",
            "42.40890688259109 % completed\n",
            "42.459514170040485 % completed\n",
            "42.51012145748988 % completed\n",
            "42.56072874493927 % completed\n",
            "42.611336032388664 % completed\n",
            "42.66194331983806 % completed\n",
            "42.71255060728745 % completed\n",
            "42.76315789473684 % completed\n",
            "42.81376518218624 % completed\n",
            "42.864372469635626 % completed\n",
            "42.91497975708502 % completed\n",
            "42.965587044534416 % completed\n",
            "43.016194331983804 % completed\n",
            "43.0668016194332 % completed\n",
            "43.11740890688259 % completed\n",
            "43.16801619433198 % completed\n",
            "43.21862348178138 % completed\n",
            "43.26923076923077 % completed\n",
            "43.31983805668016 % completed\n",
            "43.37044534412956 % completed\n",
            "43.421052631578945 % completed\n",
            "43.47165991902834 % completed\n",
            "43.522267206477736 % completed\n",
            "43.572874493927124 % completed\n",
            "43.62348178137652 % completed\n",
            "43.674089068825914 % completed\n",
            "43.7246963562753 % completed\n",
            "43.7753036437247 % completed\n",
            "43.825910931174086 % completed\n",
            "43.87651821862348 % completed\n",
            "43.927125506072876 % completed\n",
            "43.977732793522264 % completed\n",
            "44.02834008097166 % completed\n",
            "44.078947368421055 % completed\n",
            "44.12955465587044 % completed\n",
            "44.18016194331984 % completed\n",
            "44.23076923076923 % completed\n",
            "44.28137651821862 % completed\n",
            "44.33198380566802 % completed\n",
            "44.38259109311741 % completed\n",
            "44.4331983805668 % completed\n",
            "44.483805668016196 % completed\n",
            "44.534412955465584 % completed\n",
            "44.58502024291498 % completed\n",
            "44.635627530364374 % completed\n",
            "44.68623481781376 % completed\n",
            "44.73684210526316 % completed\n",
            "44.78744939271255 % completed\n",
            "44.83805668016194 % completed\n",
            "44.888663967611336 % completed\n",
            "44.93927125506073 % completed\n",
            "44.98987854251012 % completed\n",
            "45.040485829959515 % completed\n",
            "45.09109311740891 % completed\n",
            "45.1417004048583 % completed\n",
            "45.19230769230769 % completed\n",
            "45.24291497975708 % completed\n",
            "45.29352226720648 % completed\n",
            "45.34412955465587 % completed\n",
            "45.39473684210526 % completed\n",
            "45.445344129554655 % completed\n",
            "45.49595141700405 % completed\n",
            "45.54655870445344 % completed\n",
            "45.597165991902834 % completed\n",
            "45.64777327935223 % completed\n",
            "45.69838056680162 % completed\n",
            "45.74898785425101 % completed\n",
            "45.79959514170041 % completed\n",
            "45.850202429149796 % completed\n",
            "45.90080971659919 % completed\n",
            "45.95141700404859 % completed\n",
            "46.002024291497975 % completed\n",
            "46.05263157894737 % completed\n",
            "46.10323886639676 % completed\n",
            "46.15384615384615 % completed\n",
            "46.20445344129555 % completed\n",
            "46.25506072874494 % completed\n",
            "46.30566801619433 % completed\n",
            "46.35627530364373 % completed\n",
            "46.406882591093115 % completed\n",
            "46.45748987854251 % completed\n",
            "46.508097165991906 % completed\n",
            "46.558704453441294 % completed\n",
            "46.60931174089069 % completed\n",
            "46.659919028340084 % completed\n",
            "46.71052631578947 % completed\n",
            "46.76113360323887 % completed\n",
            "46.811740890688256 % completed\n",
            "46.86234817813765 % completed\n",
            "46.912955465587046 % completed\n",
            "46.963562753036435 % completed\n",
            "47.01417004048583 % completed\n",
            "47.064777327935225 % completed\n",
            "47.11538461538461 % completed\n",
            "47.16599190283401 % completed\n",
            "47.216599190283404 % completed\n",
            "47.26720647773279 % completed\n",
            "47.31781376518219 % completed\n",
            "47.36842105263158 % completed\n",
            "47.41902834008097 % completed\n",
            "47.469635627530366 % completed\n",
            "47.520242914979754 % completed\n",
            "47.57085020242915 % completed\n",
            "47.621457489878544 % completed\n",
            "47.67206477732793 % completed\n",
            "47.72267206477733 % completed\n",
            "47.77327935222672 % completed\n",
            "47.82388663967611 % completed\n",
            "47.874493927125506 % completed\n",
            "47.9251012145749 % completed\n",
            "47.97570850202429 % completed\n",
            "48.026315789473685 % completed\n",
            "48.07692307692308 % completed\n",
            "48.12753036437247 % completed\n",
            "48.178137651821864 % completed\n",
            "48.22874493927125 % completed\n",
            "48.27935222672065 % completed\n",
            "48.32995951417004 % completed\n",
            "48.38056680161943 % completed\n",
            "48.431174089068826 % completed\n",
            "48.48178137651822 % completed\n",
            "48.53238866396761 % completed\n",
            "48.582995951417004 % completed\n",
            "48.6336032388664 % completed\n",
            "48.68421052631579 % completed\n",
            "48.73481781376518 % completed\n",
            "48.78542510121458 % completed\n",
            "48.836032388663966 % completed\n",
            "48.88663967611336 % completed\n",
            "48.93724696356275 % completed\n",
            "48.987854251012145 % completed\n",
            "49.03846153846154 % completed\n",
            "49.08906882591093 % completed\n",
            "49.13967611336032 % completed\n",
            "49.19028340080972 % completed\n",
            "49.24089068825911 % completed\n",
            "49.2914979757085 % completed\n",
            "49.3421052631579 % completed\n",
            "49.392712550607285 % completed\n",
            "আদা  : আদা\n",
            "49.44331983805668 % completed\n",
            "অবলাকান্ত  : অবলাকান্ত\n",
            "49.493927125506076 % completed\n",
            "অবনীধর  : অবনীধর\n",
            "49.544534412955464 % completed\n",
            "আবদুলরশিদ  : আব্দুলরাশিদ\n",
            "49.59514170040486 % completed\n",
            "আবেদআলি  : আবেদআলি\n",
            "49.64574898785425 % completed\n",
            "আভা  : অভ\n",
            "49.69635627530364 % completed\n",
            "আভিজিত  : অভিজিত\n",
            "49.74696356275304 % completed\n",
            "আবিরা  : আবিরা\n",
            "49.797570850202426 % completed\n",
            "আড্যামস  : আডামস\n",
            "49.84817813765182 % completed\n",
            "আদিৎপারা  : আদিতপারা\n",
            "49.89878542510122 % completed\n",
            "আফ্রিকান  : আফ্রিক্যান\n",
            "49.949392712550605 % completed\n",
            "অ্যাফটেক  : আফতেক\n",
            "50.0 % completed\n",
            "অজন্তা  : অজনতা\n",
            "50.050607287449395 % completed\n",
            "আজিফা  : আজিফা\n",
            "50.10121457489878 % completed\n",
            "আজিমাবেগম  : আজিমাবেগম\n",
            "50.15182186234818 % completed\n",
            "আজিথ  : অজিথ\n",
            "50.202429149797574 % completed\n",
            "আজমতুল্লা  : আজমাতুল্লা\n",
            "50.25303643724696 % completed\n",
            "একাডেমিন্স  : আকাডেমিনস\n",
            "50.30364372469636 % completed\n",
            "অখিলবন্ধু  : অখিলবন্ধু\n",
            "50.35425101214575 % completed\n",
            "অকোসোমবো  : আকোসোম্বো\n",
            "50.40485829959514 % completed\n",
            "অ্যাকতিয়েসেলসকবেট  : অ্যাকটিসেলস্কাবেট\n",
            "50.455465587044536 % completed\n",
            "আলমআরা  : আলমারা\n",
            "50.506072874493924 % completed\n",
            "আলিগড়  : আলিগড়\n",
            "50.55668016194332 % completed\n",
            "অ্যালিইয়েনজ  : অ্যালিয়ানজ\n",
            "50.607287449392715 % completed\n",
            "অলকা  : আলোকা\n",
            "50.6578947368421 % completed\n",
            "আলোরানী  : আলোরানী\n",
            "50.7085020242915 % completed\n",
            "আল্পনারানী  : আলপানারানী\n",
            "50.75910931174089 % completed\n",
            "অমরচাঁদ  : অমরচাঁদ\n",
            "50.80971659919028 % completed\n",
            "অমরকৃষ্ণ  : অমরকৃষ্ণ\n",
            "50.86032388663968 % completed\n",
            "অমরকুমার  : আমরকুমার\n",
            "50.91093117408907 % completed\n",
            "আম্বিযাখাতুন  : আমবিযাখাতুন\n",
            "50.96153846153846 % completed\n",
            "অমিতাভ  : অমিতাভা\n",
            "51.012145748987855 % completed\n",
            "আমনাবিবি  : আমনাবিবি\n",
            "51.06275303643725 % completed\n",
            "আর্মস্টারডাম  : আমস্টারডম\n",
            "51.11336032388664 % completed\n",
            "অ্যামটেক  : অমতেক\n",
            "51.163967611336034 % completed\n",
            "আনন্দমোহন  : আনন্দমোহন\n",
            "51.21457489878542 % completed\n",
            "অনাথবন্ধু  : অনাথবন্ধু\n",
            "51.26518218623482 % completed\n",
            "অ্যানাটমি  : অ্যানাটমি\n",
            "51.31578947368421 % completed\n",
            "আন্দামান  : আন্দমন\n",
            "51.3663967611336 % completed\n",
            "আনেসাবেগম  : আনেসাবেগম\n",
            "51.417004048582996 % completed\n",
            "অনিলা  : অনিলা\n",
            "51.46761133603239 % completed\n",
            "অনীলকুমার  : অনিলকুমার\n",
            "51.51821862348178 % completed\n",
            "অনিশ  : অনিশ\n",
            "51.568825910931174 % completed\n",
            "অঙ্কন  : আঙ্কন\n",
            "51.61943319838057 % completed\n",
            "আনকোল  : আঙ্কোলা\n",
            "51.67004048582996 % completed\n",
            "আনসারা  : আনসারা\n",
            "51.72064777327935 % completed\n",
            "অ্যানসেল  : আন্সেল\n",
            "51.77125506072875 % completed\n",
            "অ্যানথ্রোপলজি  : আনথরোপোলজি\n",
            "51.821862348178136 % completed\n",
            "অনুপকুমার  : অনুপকুমার\n",
            "51.87246963562753 % completed\n",
            "অনুশ্রী  : অনুশ্রী\n",
            "51.92307692307692 % completed\n",
            "আওরঙ্গজেব  : আওরানগাজেব\n",
            "51.973684210526315 % completed\n",
            "অপ্সরা  : অপসারা\n",
            "52.02429149797571 % completed\n",
            "আরাবিয়ান  : আরবিয়ান\n",
            "52.0748987854251 % completed\n",
            "আরাসুর  : আরাসুর\n",
            "52.125506072874494 % completed\n",
            "আরতীবালা  : অরতিবালা\n",
            "52.17611336032389 % completed\n",
            "আর্কডিস  : আরকাডিস\n",
            "52.22672064777328 % completed\n",
            "আরজেনটিনাআর্জেন্টিনা  : আর্জেন্টিনা\n",
            "52.27732793522267 % completed\n",
            "এয়ারল্যান্ড  : আরলান্ডা\n",
            "52.32793522267207 % completed\n",
            "আর্মস্ট্রং  : আর্মস্ট্রোঙ্গ\n",
            "52.378542510121456 % completed\n",
            "অন্নপূর্না  : আরনাপুর্ণা\n",
            "52.42914979757085 % completed\n",
            "অরূপ  : আরূপ\n",
            "52.479757085020246 % completed\n",
            "আশাহি  : আসাহি\n",
            "52.530364372469634 % completed\n",
            "আসাম  : আসাম\n",
            "52.58097165991903 % completed\n",
            "আসামা  : আসামা\n",
            "52.63157894736842 % completed\n",
            "আঃসাত্তার  : আসাতার\n",
            "52.68218623481781 % completed\n",
            "আসেমা  : আসেমা\n",
            "52.73279352226721 % completed\n",
            "আশা  : আশা\n",
            "52.783400809716596 % completed\n",
            "আশাদেবী  : আশাদেবী\n",
            "52.83400809716599 % completed\n",
            "অসীমা  : আশিমা\n",
            "52.88461538461539 % completed\n",
            "আসরফি  : আশরফি\n",
            "52.935222672064775 % completed\n",
            "আসলিমা  : আসলিমা\n",
            "52.98582995951417 % completed\n",
            "এস্ট্রোনোমিক্যাল  : অ্যাসট্রোনোমিক্যাল\n",
            "53.036437246963565 % completed\n",
            "অতনুকুমার  : অতনুকুমার\n",
            "53.087044534412954 % completed\n",
            "আটাটুর্ক  : অটাটাটার্ক\n",
            "53.13765182186235 % completed\n",
            "আটি  : আতি\n",
            "53.188259109311744 % completed\n",
            "অতীন  : আতিন\n",
            "53.23886639676113 % completed\n",
            "অতীশ  : অতিশ\n",
            "53.28947368421053 % completed\n",
            "আটরামপুর  : আত্রমপুর\n",
            "53.340080971659916 % completed\n",
            "অস্ট্রিয়ান  : অস্ট্রিয়ান\n",
            "53.39068825910931 % completed\n",
            "অথোরিটি  : অথরিতি\n",
            "53.441295546558706 % completed\n",
            "আইয়ার  : আয়ের\n",
            "53.491902834008094 % completed\n",
            "আজাদ  : আজাদ\n",
            "53.54251012145749 % completed\n",
            "আজিজ  : আজিজ\n",
            "53.593117408906885 % completed\n",
            "ব্যাঙ্ক  : বী\n",
            "53.64372469635627 % completed\n",
            "বাবরআলি  : বাবারআলি\n",
            "53.69433198380567 % completed\n",
            "বাচুস  : বাচুস\n",
            "53.74493927125506 % completed\n",
            "বাদাগারা  : বাদাগারা\n",
            "53.79554655870445 % completed\n",
            "বাদলকুমার  : বাদলকুমার\n",
            "53.84615384615385 % completed\n",
            "বাগিভাদি  : বাগিভাদি\n",
            "53.89676113360324 % completed\n",
            "বাগ্গা  : বাগ্গা\n",
            "53.94736842105263 % completed\n",
            "বাঘেল  : বাঘেল\n",
            "53.997975708502025 % completed\n",
            "বাগরাই  : বাগরাই\n",
            "54.04858299595141 % completed\n",
            "বাহাট  : বাহট\n",
            "54.09919028340081 % completed\n",
            "বৈজনাথ  : বৈজনাথ\n",
            "54.149797570850204 % completed\n",
            "বৈরাগনিয়া  : বায়রাগনিয়া\n",
            "54.20040485829959 % completed\n",
            "বাইসিয়া  : বৈশ্য\n",
            "54.25101214574899 % completed\n",
            "বৈতুল  : বৈতুল\n",
            "54.30161943319838 % completed\n",
            "বক্সী  : বকসি\n",
            "54.35222672064777 % completed\n",
            "বালাফোন  : বালাফোন\n",
            "54.402834008097166 % completed\n",
            "বালালাইকা  : বালালাইকা\n",
            "54.45344129554656 % completed\n",
            "বালানগির  : বালাঙ্গির\n",
            "54.50404858299595 % completed\n",
            "বলবন্ত  : বলবন্ট\n",
            "54.554655870445345 % completed\n",
            "বলবিন্দর  : বলবিন্দর\n",
            "54.60526315789474 % completed\n",
            "বালড্রিজ  : বাল্ড্রাইজ\n",
            "54.65587044534413 % completed\n",
            "বালি  : বালি\n",
            "54.70647773279352 % completed\n",
            "বালজান  : বালজান\n",
            "54.75708502024292 % completed\n",
            "বামহানি  : বামহানি\n",
            "54.80769230769231 % completed\n",
            "বান্ডোলা  : বান্ডোলা\n",
            "54.8582995951417 % completed\n",
            "বাঙ্গালোর  : ব্যাঙ্গালোর\n",
            "54.90890688259109 % completed\n",
            "বনিজান  : বানিজান\n",
            "54.959514170040485 % completed\n",
            "বানিয়া  : বানিয়া\n",
            "55.01012145748988 % completed\n",
            "বাঙ্কা  : বঙ্ক\n",
            "55.06072874493927 % completed\n",
            "বংশীধারী  : বংশীধারী\n",
            "55.111336032388664 % completed\n",
            "বংশীলাল  : বংশীলাল\n",
            "55.16194331983806 % completed\n",
            "বারগাঁও  : বারাগাঁও\n",
            "55.21255060728745 % completed\n",
            "বারানসী  : বারানাসি\n",
            "55.26315789473684 % completed\n",
            "বারানফ  : বারানোফ\n",
            "55.31376518218624 % completed\n",
            "বার্সিলোনা  : বার্সেলোনা\n",
            "55.364372469635626 % completed\n",
            "বারহনি  : বারহনি\n",
            "55.41497975708502 % completed\n",
            "বারিদা  : বারিদা\n",
            "55.465587044534416 % completed\n",
            "বারীন্দ্র  : বরিন্দ্র\n",
            "55.516194331983804 % completed\n",
            "বড়জাহান  : বারজাহান\n",
            "55.5668016194332 % completed\n",
            "বার্ট  : বার্ট\n",
            "55.61740890688259 % completed\n",
            "বাসন্তীবাসন্তি  : বাসন্তী\n",
            "55.66801619433198 % completed\n",
            "বাসি  : বাসি\n",
            "55.71862348178138 % completed\n",
            "বাসকে  : বাস্ক\n",
            "55.76923076923077 % completed\n",
            "বসতা  : বাস্তা\n",
            "55.81983805668016 % completed\n",
            "ব্যাটারি  : ব্যাটারি\n",
            "55.87044534412956 % completed\n",
            "বাতুলন  : বতুলান\n",
            "55.921052631578945 % completed\n",
            "বেফিল্ড  : বেইফিল্ড\n",
            "55.97165991902834 % completed\n",
            "বেদেনা  : বেদেনা\n",
            "56.022267206477736 % completed\n",
            "বেগু  : বিগু\n",
            "56.072874493927124 % completed\n",
            "বেলান  : বেলন\n",
            "56.12348178137652 % completed\n",
            "বেলেজান  : বেলেজান\n",
            "56.174089068825914 % completed\n",
            "বেলিসারিও  : বেলিসারিও\n",
            "56.2246963562753 % completed\n",
            "বেলসাউথ  : বেলসাউথ\n",
            "56.2753036437247 % completed\n",
            "বেনজির  : বেনাজির\n",
            "56.325910931174086 % completed\n",
            "বেণীমাধব  : বেনিমাধব\n",
            "56.37651821862348 % completed\n",
            "বেরী  : বেরি\n",
            "56.427125506072876 % completed\n",
            "বেসকিডি  : বেস্কিডি\n",
            "56.477732793522264 % completed\n",
            "বেটি  : বেট্য\n",
            "56.52834008097166 % completed\n",
            "বেতোয়া  : বেটওয়া\n",
            "56.578947368421055 % completed\n",
            "ভাবরী  : ভবরী\n",
            "56.62955465587044 % completed\n",
            "ভাদভাদে  : ভাদভাদে\n",
            "56.68016194331984 % completed\n",
            "ভাগিগা  : ভাগেগা\n",
            "56.73076923076923 % completed\n",
            "ভাগীরথী  : ভগীরথী\n",
            "56.78137651821862 % completed\n",
            "ভালে  : ভালে\n",
            "56.83198380566802 % completed\n",
            "ভাঙ্গে  : ভানগে\n",
            "56.88259109311741 % completed\n",
            "ভাংড়া  : ভানগ্রা\n",
            "56.9331983805668 % completed\n",
            "ভাগনু  : ভাঁগু\n",
            "56.983805668016196 % completed\n",
            "ভারদ্বাজ  : ভারদাজ\n",
            "57.034412955465584 % completed\n",
            "ভাটিয়া  : ভাতিয়া\n",
            "57.08502024291498 % completed\n",
            "ভাতিন্দা  : ভাতিনদা\n",
            "57.135627530364374 % completed\n",
            "ভাটনগর  : ভাতনগর\n",
            "57.18623481781376 % completed\n",
            "ভীমস্বাদী  : ভেমস্বাদি\n",
            "57.23684210526316 % completed\n",
            "ভিগওয়ান  : ভিগওয়ান\n",
            "57.28744939271255 % completed\n",
            "ভিভানি  : ভিভানি\n",
            "57.33805668016194 % completed\n",
            "ভোলা  : ভোলা\n",
            "57.388663967611336 % completed\n",
            "ভূজ  : ভূজ\n",
            "57.43927125506073 % completed\n",
            "ভুজঙ্গ  : ভুজাং\n",
            "57.48987854251012 % completed\n",
            "ভুটকি  : ভুটকি\n",
            "57.540485829959515 % completed\n",
            "বিবেকসর  : বিবেকসর\n",
            "57.59109311740891 % completed\n",
            "বিভুতিভুষনবিভূতিভূষণ  : বিভুতিভুষণ\n",
            "57.6417004048583 % completed\n",
            "বিসব্রোয়েক  : বিয়েসব্রোইক\n",
            "57.69230769230769 % completed\n",
            "বিহার  : বিহার\n",
            "57.74291497975708 % completed\n",
            "বিলাসপুরি  : বিলাসপুরি\n",
            "57.79352226720648 % completed\n",
            "বিলসন  : বিলসন\n",
            "57.84412955465587 % completed\n",
            "বিমলারাণীবিমলারানী  : বিমলারাণী\n",
            "57.89473684210526 % completed\n",
            "বিনাপানি  : বিনাপনি\n",
            "57.945344129554655 % completed\n",
            "বীনারানীবীণারাণী  : বিনারাণী\n",
            "57.99595141700405 % completed\n",
            "বিনযকৃষ্ণ  : বিনযকৃষ্ণ\n",
            "58.04655870445344 % completed\n",
            "বিনযকুমার  : বিনযকুমার\n",
            "58.097165991902834 % completed\n",
            "বিন্দা  : বিন্দা\n",
            "58.14777327935223 % completed\n",
            "বিন্দুবালা  : বিন্দুবালা\n",
            "58.19838056680162 % completed\n",
            "বিপদী  : বিপদি\n",
            "58.24898785425101 % completed\n",
            "বরদাকান্ত  : বিরিদাকান্ত\n",
            "58.29959514170041 % completed\n",
            "বীরসিংহপুর  : বীরসিংহপুর\n",
            "58.350202429149796 % completed\n",
            "বোধরান  : বোধরান\n",
            "58.40080971659919 % completed\n",
            "বোকাঞ্জন  : বোকাজান\n",
            "58.45141700404859 % completed\n",
            "বোনাপাট  : বোনাপার্ট\n",
            "58.502024291497975 % completed\n",
            "বোম্পস  : বুম্পস\n",
            "58.55263157894737 % completed\n",
            "বোনস  : বুনস\n",
            "58.60323886639676 % completed\n",
            "বূট  : বুট\n",
            "58.65384615384615 % completed\n",
            "বোরিভালি  : বোরিভালি\n",
            "58.70445344129555 % completed\n",
            "বোটাড  : বোটাদ\n",
            "58.75506072874494 % completed\n",
            "বোথ  : বোথা\n",
            "58.80566801619433 % completed\n",
            "ব্রাসওয়েল  : ব্রেসউয়েল\n",
            "58.85627530364373 % completed\n",
            "ব্রাডলে  : ব্রেডলি\n",
            "58.906882591093115 % completed\n",
            "ব্রেসনান  : ব্রেসনন\n",
            "58.95748987854251 % completed\n",
            "ব্রিটেন  : ব্রিটেন\n",
            "59.008097165991906 % completed\n",
            "ব্রিটিশ  : ব্রিটিশ\n",
            "59.058704453441294 % completed\n",
            "ব্রুকেস  : ব্রুকেস\n",
            "59.10931174089069 % completed\n",
            "বুদ্ধিইজম  : বাড্ধিজম\n",
            "59.159919028340084 % completed\n",
            "বূধন  : বুধন\n",
            "59.21052631578947 % completed\n",
            "বুধুসিং  : বুধুসিং\n",
            "59.26113360323887 % completed\n",
            "বুলাল  : বুলাল\n",
            "59.311740890688256 % completed\n",
            "বুলবুলি  : বুলবুলি\n",
            "59.36234817813765 % completed\n",
            "বুলু  : বুলু\n",
            "59.412955465587046 % completed\n",
            "বুলুনী  : বুলুনী\n",
            "59.463562753036435 % completed\n",
            "বুরেন  : বুরেন\n",
            "59.51417004048583 % completed\n",
            "কাকাহুয়ামিল্পা  : কাকাহুয়ামিল্পা\n",
            "59.564777327935225 % completed\n",
            "কাছার  : ক্যাকার\n",
            "59.61538461538461 % completed\n",
            "ক্যাডবেরিস  : কাডবারিস\n",
            "59.66599190283401 % completed\n",
            "ক্যাডিলা  : কাডিলা\n",
            "59.716599190283404 % completed\n",
            "ক্যাডমিয়াম  : ক্যাডমিয়াম\n",
            "59.76720647773279 % completed\n",
            "কাজা  : কাজা\n",
            "59.81781376518219 % completed\n",
            "কার্গিল  : কার্জিল\n",
            "59.86842105263158 % completed\n",
            "ক্যারিগনানো  : ক্যারিগনানো\n",
            "59.91902834008097 % completed\n",
            "কার্লি  : কার্লি\n",
            "59.969635627530366 % completed\n",
            "কার্পার  : কার্পার\n",
            "60.020242914979754 % completed\n",
            "কাভোর  : কাভার\n",
            "60.07085020242915 % completed\n",
            "সিয়েট  : সিট\n",
            "60.121457489878544 % completed\n",
            "সিমেন্টস  : সিমেন্টস\n",
            "60.17206477732793 % completed\n",
            "সেন্ট্রিকা  : সেন্ট্রিকা\n",
            "60.22267206477733 % completed\n",
            "চাদোতার  : চাদোতার\n",
            "60.27327935222672 % completed\n",
            "চামিন্ডা  : চামিন্ডা\n",
            "60.32388663967611 % completed\n",
            "চম্পাদেবী  : চম্পাদেবী\n",
            "60.374493927125506 % completed\n",
            "চন্ডীচরণ  : চণ্ডিচরন\n",
            "60.4251012145749 % completed\n",
            "চান্দিসার  : চন্দিসর\n",
            "60.47570850202429 % completed\n",
            "চান্দলোদিয়া  : চাঁদলোদিয়া\n",
            "60.526315789473685 % completed\n",
            "চন্দ্রভাগা  : চন্দ্রভাগ\n",
            "60.57692307692308 % completed\n",
            "চন্দ্রলেখা  : চন্দ্রলেখা\n",
            "60.62753036437247 % completed\n",
            "চন্দ্রমোহন  : চন্দ্রমোহন\n",
            "60.678137651821864 % completed\n",
            "চন্দ্রনা  : চন্দ্রনা\n",
            "60.72874493927125 % completed\n",
            "চন্দ্রনী  : চন্দ্রানী\n",
            "60.77935222672065 % completed\n",
            "চাফেকার  : চাফেকার\n",
            "60.82995951417004 % completed\n",
            "চাথানুর  : চাথানওর\n",
            "60.88056680161943 % completed\n",
            "চাট্টেরগুন  : ছাটারগুন\n",
            "60.931174089068826 % completed\n",
            "চৌথাম  : চৌথম\n",
            "60.98178137651822 % completed\n",
            "চাওলা  : চাওলা\n",
            "61.03238866396761 % completed\n",
            "চায়গাঁও  : চেগাঁও\n",
            "61.082995951417004 % completed\n",
            "চেনব  : চেনব\n",
            "61.1336032388664 % completed\n",
            "চেংচেঙ্গ  : চেঙ্গ\n",
            "61.18421052631579 % completed\n",
            "চিপক  : চিপাউক\n",
            "61.23481781376518 % completed\n",
            "ছাম্ব  : ছাম্ব\n",
            "61.28542510121458 % completed\n",
            "ছাতনা  : ছাতনা\n",
            "61.336032388663966 % completed\n",
            "চিভাভা  : চিভাভাভা\n",
            "61.38663967611336 % completed\n",
            "চিকালথন  : চিকালথন\n",
            "61.43724696356275 % completed\n",
            "চিঞ্চোর  : চিঞ্চোর\n",
            "61.487854251012145 % completed\n",
            "চিনুবালা  : চিনুবালা\n",
            "61.53846153846154 % completed\n",
            "চিপুরুপাল্লি  : চিপারুপলা\n",
            "61.58906882591093 % completed\n",
            "চিরঞ্জিত্  : চিরঞ্জিত\n",
            "61.63967611336032 % completed\n",
            "চিওরঞ্জন  : চিতারঞ্জন\n",
            "61.69028340080972 % completed\n",
            "চিতৌরচিত্তূর  : চিত্তুর\n",
            "61.74089068825911 % completed\n",
            "চোপান  : চোপন\n",
            "61.7914979757085 % completed\n",
            "চোপদা  : চোপদা\n",
            "61.8421052631579 % completed\n",
            "ক্রিসমাস  : ক্রিস্টমাস\n",
            "61.892712550607285 % completed\n",
            "চাক  : চাক\n",
            "61.94331983805668 % completed\n",
            "চুন্নী  : চুন্নি\n",
            "61.993927125506076 % completed\n",
            "চুরাচন্দপুর  : চুরাচাঁদপুর\n",
            "62.044534412955464 % completed\n",
            "সিদাদেস  : সাইডাডেস\n",
            "62.09514170040486 % completed\n",
            "সিটিগেট  : সিটিগেট\n",
            "62.14574898785425 % completed\n",
            "ক্লেমেন্ট  : ক্লেমেন্ট\n",
            "62.19635627530364 % completed\n",
            "কোলিয়ার  : কলিয়ার\n",
            "62.24696356275304 % completed\n",
            "কলম্বো  : কোলোম্বো\n",
            "62.297570850202426 % completed\n",
            "কলম্বিয়াকোলুম্বিয়া  : কোলাম্বিয়া\n",
            "62.34817813765182 % completed\n",
            "কোলুসা  : কোলা\n",
            "62.39878542510122 % completed\n",
            "কোনান  : কোনান\n",
            "62.449392712550605 % completed\n",
            "কংগ্রেসানাল  : কংগ্রেশনাল\n",
            "62.5 % completed\n",
            "কনসাল্টিং  : কনসাল্টিং\n",
            "62.550607287449395 % completed\n",
            "কুপার্স  : কুপারস\n",
            "62.60121457489878 % completed\n",
            "কপার  : কপার\n",
            "62.65182186234818 % completed\n",
            "কোরক  : কোর্ক\n",
            "62.702429149797574 % completed\n",
            "কর্ণারস্টোন  : করনার্স্টোন\n",
            "62.75303643724696 % completed\n",
            "কোর্টল্যান্ড  : কোর্টল্যান্ড\n",
            "62.80364372469636 % completed\n",
            "কসমো  : কসমো\n",
            "62.85425101214575 % completed\n",
            "কোস্টনার  : কস্টনার\n",
            "62.90485829959514 % completed\n",
            "কান্ট্রি  : কান্ট্রি\n",
            "62.955465587044536 % completed\n",
            "ক্রোনিয়া  : ক্রোনজ\n",
            "63.006072874493924 % completed\n",
            "ক্রোকুয়েট  : ক্রোকুয়েট\n",
            "63.05668016194332 % completed\n",
            "ক্রো  : ক্রোই\n",
            "63.107287449392715 % completed\n",
            "কুম্বালোম  : সাইমবালম\n",
            "63.1578947368421 % completed\n",
            "ডি  : ড\n",
            "63.2085020242915 % completed\n",
            "দ্যা  : দা\n",
            "63.25910931174089 % completed\n",
            "ডাবেঙ্গা  : দাবেনগওয়া\n",
            "63.30971659919028 % completed\n",
            "দাদরা  : দাদরা\n",
            "63.36032388663968 % completed\n",
            "দাহার  : দাহার\n",
            "63.41093117408907 % completed\n",
            "ডেইলওয়ারা  : দৈলওয়ারা\n",
            "63.46153846153846 % completed\n",
            "দৈনিক  : দৈনিক\n",
            "63.512145748987855 % completed\n",
            "দাকোতা  : দাকোটা\n",
            "63.56275303643725 % completed\n",
            "ডালমিয়া  : দালমিয়া\n",
            "63.61336032388664 % completed\n",
            "দাপোদি  : দাপোদি\n",
            "63.663967611336034 % completed\n",
            "ডার্টস  : ডার্ট\n",
            "63.71457489878542 % completed\n",
            "ডাসসল্ট  : দাসাউল্ট\n",
            "63.76518218623482 % completed\n",
            "দাসুয়া  : দাসুয়া\n",
            "63.81578947368421 % completed\n",
            "দাউদ  : দাউদ\n",
            "63.8663967611336 % completed\n",
            "দায়ি  : দাওই\n",
            "63.917004048582996 % completed\n",
            "ডেকিন  : ডেকিন\n",
            "63.96761133603239 % completed\n",
            "দেবদাস  : দেবদাস\n",
            "64.01821862348179 % completed\n",
            "দেবেন  : ডেবেন\n",
            "64.06882591093117 % completed\n",
            "দীপ  : দীপ\n",
            "64.11943319838056 % completed\n",
            "দিউ  : দীভ\n",
            "64.17004048582996 % completed\n",
            "ডেফ্রেটস  : ডেফ্রেইটাস\n",
            "64.22064777327935 % completed\n",
            "ডেজি  : দেেজি\n",
            "64.27125506072875 % completed\n",
            "ডেলরাম  : ডেলরান\n",
            "64.32186234817814 % completed\n",
            "ডেমোক্রেটিক  : ডেমোক্রাটি\n",
            "64.37246963562752 % completed\n",
            "ডেনিস  : ডেনিস\n",
            "64.42307692307692 % completed\n",
            "দেরগাঁও  : দারগাঁও\n",
            "64.47368421052632 % completed\n",
            "ডাচেস  : ডেউটস্চে\n",
            "64.52429149797571 % completed\n",
            "ডেভোলুশান  : ডেভোলিউশান\n",
            "64.5748987854251 % completed\n",
            "দাদভাইওয়ালে  : ধাদভাইওয়ালে\n",
            "64.6255060728745 % completed\n",
            "ধরমবীর  : ধরামবীর\n",
            "64.67611336032388 % completed\n",
            "ধর্মসেনা  : ধর্মসেনা\n",
            "64.72672064777328 % completed\n",
            "ধর্মভরম  : ধর্মবারাম\n",
            "64.77732793522267 % completed\n",
            "ধেকনে  : ধেকনে\n",
            "64.82793522267207 % completed\n",
            "ধেনকানাল  : ধেঙ্কানাল\n",
            "64.87854251012146 % completed\n",
            "ধীরনবালা  : ধীরেনবালা\n",
            "64.92914979757084 % completed\n",
            "ধিরপুর  : ধিরপুর\n",
            "64.97975708502024 % completed\n",
            "ধুল  : ধুল\n",
            "65.03036437246963 % completed\n",
            "দি  : দি\n",
            "65.08097165991903 % completed\n",
            "ডায়াবলো  : ডিয়াবলো\n",
            "65.13157894736842 % completed\n",
            "দিবারানী  : দিবারাণী\n",
            "65.18218623481782 % completed\n",
            "ডিকম্যান  : ডিকম্যান\n",
            "65.2327935222672 % completed\n",
            "দীলদারনগর  : দিলদারনগর\n",
            "65.2834008097166 % completed\n",
            "ডিল্লে  : ডিলি\n",
            "65.33400809716599 % completed\n",
            "দিলমহাম্মদ  : দিলমহম্মদ\n",
            "65.38461538461539 % completed\n",
            "দিপা  : দীপা\n",
            "65.43522267206478 % completed\n",
            "ডিপেনার  : দীপেনার\n",
            "65.48582995951416 % completed\n",
            "ডিস্ক  : ডিস্ক\n",
            "65.53643724696356 % completed\n",
            "দিসপুর  : ডিসপুর\n",
            "65.58704453441295 % completed\n",
            "ডোনেলি  : ডোনেল্লি\n",
            "65.63765182186235 % completed\n",
            "ড্রাপার  : ড্রেপার\n",
            "65.68825910931174 % completed\n",
            "ড্রুম  : ড্রুম\n",
            "65.73886639676114 % completed\n",
            "ড্রুমন্ড  : ড্রুমোন্ড\n",
            "65.78947368421052 % completed\n",
            "দুলালকান্তি  : দুলালকান্তি\n",
            "65.84008097165992 % completed\n",
            "দুলারা  : দুলারা\n",
            "65.89068825910931 % completed\n",
            "দুলুরাণী  : দুলুরানী\n",
            "65.9412955465587 % completed\n",
            "ডাম্বারটন  : ডাম্বার্টন\n",
            "65.9919028340081 % completed\n",
            "দুর্বাদল  : দুরবাদাল\n",
            "66.0425101214575 % completed\n",
            "দুর্গাপ্রসাদ  : দূর্গাপ্রসাদ\n",
            "66.09311740890688 % completed\n",
            "ডাচেস  : ডুটচেস\n",
            "66.14372469635627 % completed\n",
            "দ্বরকাগঞ্জ  : দ্বারকাগঞ্জ\n",
            "66.19433198380567 % completed\n",
            "ইকুয়েডর  : ইকুয়াডোর\n",
            "66.24493927125506 % completed\n",
            "ঈগার  : এডগার\n",
            "66.29554655870446 % completed\n",
            "এইসেনহোওয়ের  : ইসেনহাওয়ার\n",
            "66.34615384615384 % completed\n",
            "ইমারসন  : এমারসন\n",
            "66.39676113360323 % completed\n",
            "ইঞ্জিন  : এনজিন\n",
            "66.44736842105263 % completed\n",
            "এপিসকোপাল  : এপিসকোপাল\n",
            "66.49797570850203 % completed\n",
            "আর্বিয়াম  : আর্বিয়াম\n",
            "66.54858299595142 % completed\n",
            "আরনেস্টলি  : আর্নিসেটল\n",
            "66.59919028340082 % completed\n",
            "এসেক্স  : এসেক্স\n",
            "66.6497975708502 % completed\n",
            "ইথিওপিয়া  : ইথিওপিয়া\n",
            "66.70040485829959 % completed\n",
            "ইউরোপ  : ইউরোপ\n",
            "66.75101214574899 % completed\n",
            "এভারেস্ট  : এভারেস্ট\n",
            "66.80161943319838 % completed\n",
            "ফাদো  : ফাদো\n",
            "66.85222672064778 % completed\n",
            "ফজরুল  : ফজরুল\n",
            "66.90283400809717 % completed\n",
            "ফকিরমহম্মদ  : ফকিরমহম্মদ\n",
            "66.95344129554655 % completed\n",
            "ফেম  : ফাম\n",
            "67.00404858299595 % completed\n",
            "ফরিদাবাদ  : ফরিদাবাদ\n",
            "67.05465587044534 % completed\n",
            "ফাটারফোড  : ফাতারফোদ\n",
            "67.10526315789474 % completed\n",
            "ফিল্ড  : ফ্লিড\n",
            "67.15587044534414 % completed\n",
            "ফিলিবার্তো  : ফিলিবার্টো\n",
            "67.20647773279352 % completed\n",
            "ফার্স্টসার্ভিস  : ফার্স্টসেনফাইস\n",
            "67.25708502024291 % completed\n",
            "ফিরুজা  : ফিরুজা\n",
            "67.3076923076923 % completed\n",
            "ফিটনেস  : ফাইটনেস\n",
            "67.3582995951417 % completed\n",
            "ফ্লেক  : ফ্লিস\n",
            "67.4089068825911 % completed\n",
            "ফ্লোরিনা  : ফ্লোরিনা\n",
            "67.45951417004049 % completed\n",
            "ফুটবল  : ফুটবল\n",
            "67.51012145748987 % completed\n",
            "ফ্রান্সিসকো  : ফ্রানসেসকো\n",
            "67.56072874493927 % completed\n",
            "ফুলমণিফুলমনি  : ফুলমণি\n",
            "67.61133603238866 % completed\n",
            "ফুলপতি  : ফুলপতি\n",
            "67.66194331983806 % completed\n",
            "ফুরিয়াস  : ফুরিয়াস\n",
            "67.71255060728745 % completed\n",
            "ফিউচার  : ফিউচার\n",
            "67.76315789473684 % completed\n",
            "ফিউচারমিডিয়া  : ফিউটুরেমিডিয়া\n",
            "67.81376518218623 % completed\n",
            "গেইল  : গাল\n",
            "67.86437246963563 % completed\n",
            "গালভা  : গলভা\n",
            "67.91497975708502 % completed\n",
            "গনেশ  : গানেশ\n",
            "67.96558704453442 % completed\n",
            "গনেশগঁঞ্জ  : গানেশগঞ্জ\n",
            "68.01619433198381 % completed\n",
            "গাঙ্গুলি  : গ্যাঙ্গুলি\n",
            "68.06680161943319 % completed\n",
            "গ্যাসুনি  : গাসুনি\n",
            "68.11740890688259 % completed\n",
            "গ্যাজ  : গাজ\n",
            "68.16801619433198 % completed\n",
            "জেনারেল  : জেনারেল\n",
            "68.21862348178138 % completed\n",
            "জেন্টিয়াম  : জেন্টিয়াম\n",
            "68.26923076923077 % completed\n",
            "জেফফ্রি  : জিওফ্রে\n",
            "68.31983805668017 % completed\n",
            "জিওর্জ  : গর্গ\n",
            "68.37044534412955 % completed\n",
            "ঘারু  : ঘারু\n",
            "68.42105263157895 % completed\n",
            "ঘুম্মান  : ঘুম্মান\n",
            "68.47165991902834 % completed\n",
            "গ্রীন্সবার্গ  : গিনসবার্গ\n",
            "68.52226720647774 % completed\n",
            "গিরাজ  : গিরাজ\n",
            "68.57287449392713 % completed\n",
            "গিরীবালা  : গিরিবালা\n",
            "68.62348178137651 % completed\n",
            "গীরিডি  : গিরিডিহ\n",
            "68.67408906882591 % completed\n",
            "গঘ  : গোঘ\n",
            "68.7246963562753 % completed\n",
            "গোহানা  : গোহনা\n",
            "68.7753036437247 % completed\n",
            "গোলান্থরা  : গোলান্থরা\n",
            "68.82591093117409 % completed\n",
            "গোল্ডম্যান  : গোল্ডম্যান\n",
            "68.87651821862349 % completed\n",
            "গোলসার  : গোলসার\n",
            "68.92712550607287 % completed\n",
            "গুনাসেকেরা  : গুনাসেকেরা\n",
            "68.97773279352226 % completed\n",
            "গোপাল  : গোপাল\n",
            "69.02834008097166 % completed\n",
            "গোলাপচাঁদ  : গোপালচাঁদ\n",
            "69.07894736842105 % completed\n",
            "গোপীবালা  : গোপীবালা\n",
            "69.12955465587045 % completed\n",
            "গোরখপুরগোরক্ষপুর  : গোরাখপুর\n",
            "69.18016194331983 % completed\n",
            "গোরখনাথ  : গোরোকনাথ\n",
            "69.23076923076923 % completed\n",
            "গোস্পার  : গসপার\n",
            "69.28137651821862 % completed\n",
            "গৌর  : গোউর\n",
            "69.33198380566802 % completed\n",
            "গৌরীদেবী  : গৌরিদেবী\n",
            "69.38259109311741 % completed\n",
            "গোভিন্দপুরি  : গোভিন্দপুরি\n",
            "69.43319838056681 % completed\n",
            "গ্রে  : গ্রেই\n",
            "69.48380566801619 % completed\n",
            "গ্রিফিন  : গ্রিফিন\n",
            "69.53441295546558 % completed\n",
            "গ্রৌচ  : গ্রৌচো\n",
            "69.58502024291498 % completed\n",
            "গ্রুপ  : গ্রাউপ\n",
            "69.63562753036437 % completed\n",
            "গুইরো  : গুইরো\n",
            "69.68623481781377 % completed\n",
            "গুজহানদি  : গুঝান্ডি\n",
            "69.73684210526316 % completed\n",
            "গুরুদীপ  : গুরুদীপ\n",
            "69.78744939271255 % completed\n",
            "গোয়ালিয়র  : গোয়ালিওর\n",
            "69.83805668016194 % completed\n",
            "গোয়ালপাড়া  : গোয়ালপদ\n",
            "69.88866396761134 % completed\n",
            "এইচ  : এ\n",
            "69.93927125506073 % completed\n",
            "হাযদরআলি  : হায়দারআলি\n",
            "69.98987854251013 % completed\n",
            "হালিমা  : হালিমা\n",
            "70.04048582995951 % completed\n",
            "হামেদান  : হমেদান\n",
            "70.0910931174089 % completed\n",
            "হামিদাবেগম  : হামিদাবেগম\n",
            "70.1417004048583 % completed\n",
            "হ্যান্স  : হানস\n",
            "70.1923076923077 % completed\n",
            "হরিরাম  : হরিরাম\n",
            "70.24291497975709 % completed\n",
            "হারুন  : হারুন\n",
            "70.29352226720648 % completed\n",
            "হারভে  : হারভে\n",
            "70.34412955465586 % completed\n",
            "হাসি  : হাসি\n",
            "70.39473684210526 % completed\n",
            "হাসীনাবেগমহাসিনাবেগম  : হাসিনাবেগম\n",
            "70.44534412955466 % completed\n",
            "হাসমিনা  : হাসমিনা\n",
            "70.49595141700405 % completed\n",
            "হৌপাঙ্গ  : হাউপাঙ্গো\n",
            "70.54655870445345 % completed\n",
            "হার্ট  : হার্ট\n",
            "70.59716599190283 % completed\n",
            "হেলগোল্যান্ড  : হেলগোল্যান্ড\n",
            "70.64777327935222 % completed\n",
            "হেলস  : হেলস\n",
            "70.69838056680162 % completed\n",
            "হেমগোপাল  : হেমগোপাল\n",
            "70.74898785425101 % completed\n",
            "হারসেল  : হার্সেলে\n",
            "70.79959514170041 % completed\n",
            "হিক  : হিক\n",
            "70.8502024291498 % completed\n",
            "হিগস  : হাইজস\n",
            "70.90080971659918 % completed\n",
            "হিলস  : হিল\n",
            "70.95141700404858 % completed\n",
            "হিঙ্গানকার  : হিঙ্গানকার\n",
            "71.00202429149797 % completed\n",
            "হিসর  : হিসার\n",
            "71.05263157894737 % completed\n",
            "হিটলার  : হিতলার\n",
            "71.10323886639677 % completed\n",
            "হোল্লান্ড  : হোল্যান্ড\n",
            "71.15384615384616 % completed\n",
            "হোমে  : হোম\n",
            "71.20445344129554 % completed\n",
            "হোন্ডা  : হোন্ডা\n",
            "71.25506072874494 % completed\n",
            "হর্ন  : হর্ন\n",
            "71.30566801619433 % completed\n",
            "হোশিয়ারপুর  : হোশিয়ারপুর\n",
            "71.35627530364373 % completed\n",
            "হোটেলস  : হোটেলস\n",
            "71.40688259109312 % completed\n",
            "হোসেন  : হুসেন\n",
            "71.4574898785425 % completed\n",
            "হুসসি  : হুসে\n",
            "71.5080971659919 % completed\n",
            "ইয়ান  : লান\n",
            "71.5587044534413 % completed\n",
            "ইব্রাহিমইব্রাহীম  : ইব্রাহিম\n",
            "71.60931174089069 % completed\n",
            "ইবসেন  : ইবসেন\n",
            "71.65991902834008 % completed\n",
            "ইকাহন  : আইকান\n",
            "71.71052631578948 % completed\n",
            "ইদ্রীশ  : ইদ্রিশ\n",
            "71.76113360323886 % completed\n",
            "ইগুয়াকু  : ইগুয়াকু\n",
            "71.81174089068826 % completed\n",
            "ল্লিংওরথ  : ইলিংওরথ\n",
            "71.86234817813765 % completed\n",
            "ইন্দু  : ইন্ডু\n",
            "71.91295546558705 % completed\n",
            "ইন্দুভূষণ  : ইন্দুভূষন\n",
            "71.96356275303644 % completed\n",
            "ইনখুলাব  : ইনকুলাব\n",
            "72.01417004048584 % completed\n",
            "ইপকা  : ইপকা\n",
            "72.06477732793522 % completed\n",
            "ইরাকি  : ইরাকি\n",
            "72.11538461538461 % completed\n",
            "ইশাক  : ইশাক\n",
            "72.16599190283401 % completed\n",
            "ইস্তভান  : ইস্টভান\n",
            "72.2165991902834 % completed\n",
            "ইতাওয়া  : ইটায়া\n",
            "72.2672064777328 % completed\n",
            "লভেনটুর  : ইভেনচার\n",
            "72.31781376518218 % completed\n",
            "জে  : জ\n",
            "72.36842105263158 % completed\n",
            "জ্যাকব  : জ্যাকোব\n",
            "72.41902834008097 % completed\n",
            "জাফার  : জাফার\n",
            "72.46963562753037 % completed\n",
            "জগা  : জগা\n",
            "72.52024291497976 % completed\n",
            "জগধাত্রী  : জগাধাত্রি\n",
            "72.57085020242916 % completed\n",
            "জগজীবন  : জগজীবান\n",
            "72.62145748987854 % completed\n",
            "জগমোহন  : জগমোহন\n",
            "72.67206477732793 % completed\n",
            "জগদেও  : জগদেও\n",
            "72.72267206477733 % completed\n",
            "জাহাঙ্গীর  : জহঙ্গির\n",
            "72.77327935222672 % completed\n",
            "জহরাবিবি  : জাহারাবিবি\n",
            "72.82388663967612 % completed\n",
            "জৈন  : জেই\n",
            "72.8744939271255 % completed\n",
            "জেমস  : জেমস\n",
            "72.9251012145749 % completed\n",
            "জমিনা  : জামিনা\n",
            "72.97570850202429 % completed\n",
            "জমসেদআলি  : জামসেদআলি\n",
            "73.02631578947368 % completed\n",
            "জঙ্গল  : জ্যাংলে\n",
            "73.07692307692308 % completed\n",
            "জ়াপান  : জপন\n",
            "73.12753036437248 % completed\n",
            "জাপরা  : জাপরা\n",
            "73.17813765182186 % completed\n",
            "জাসমুন্দ  : জসমন্ড\n",
            "73.22874493927125 % completed\n",
            "জয়াসিংহে  : জয়সিংহ\n",
            "73.27935222672065 % completed\n",
            "জেসি  : জেসি\n",
            "73.32995951417004 % completed\n",
            "জেফ  : জেফ\n",
            "73.38056680161944 % completed\n",
            "জেরোম  : জেরোম\n",
            "73.43117408906883 % completed\n",
            "জেরাহি  : জেরাহি\n",
            "73.48178137651821 % completed\n",
            "ঝড়ুচরণ  : ঝারুচরণ\n",
            "73.53238866396761 % completed\n",
            "জিমি  : জিমি\n",
            "73.582995951417 % completed\n",
            "জোহনসন  : জোনসন\n",
            "73.6336032388664 % completed\n",
            "জুবাইর  : জুবের\n",
            "73.6842105263158 % completed\n",
            "জুডি  : জাডি\n",
            "73.73481781376518 % completed\n",
            "কৈলাশ  : কৈলাশ\n",
            "73.78542510121457 % completed\n",
            "কালাহান্ডি  : কালাহানদি\n",
            "73.83603238866397 % completed\n",
            "কাল্লাবতী  : কল্লবতী\n",
            "73.88663967611336 % completed\n",
            "কল্পনাথ  : কল্পনাথ\n",
            "73.93724696356276 % completed\n",
            "কাল্টু  : কাল্টু\n",
            "73.98785425101215 % completed\n",
            "কল্যাণী  : কালইয়ানী\n",
            "74.03846153846153 % completed\n",
            "কমলেন্দু  : কমলেন্দু\n",
            "74.08906882591093 % completed\n",
            "কামেঙ্গ  : কামেং\n",
            "74.13967611336032 % completed\n",
            "কানাড়ী  : কানাদি\n",
            "74.19028340080972 % completed\n",
            "করবী  : কারাবি\n",
            "74.24089068825911 % completed\n",
            "কার্গাম  : কার্গাম\n",
            "74.2914979757085 % completed\n",
            "কার্নেস  : কার্নেস\n",
            "74.34210526315789 % completed\n",
            "কার্তিক  : কার্টিক\n",
            "74.39271255060729 % completed\n",
            "কাশিকার  : কাশিকার\n",
            "74.44331983805668 % completed\n",
            "কাঠপাল  : কথপাল\n",
            "74.49392712550608 % completed\n",
            "কাউয়া  : কাউয়া\n",
            "74.54453441295547 % completed\n",
            "কাভতেকার  : কাথেকার\n",
            "74.59514170040485 % completed\n",
            "ক্যাকিং  : কায়াকিং\n",
            "74.64574898785425 % completed\n",
            "কেলাভারাপল্লি  : কেলাভারাপাল্লি\n",
            "74.69635627530364 % completed\n",
            "কেশু  : কেশু\n",
            "74.74696356275304 % completed\n",
            "খাঁদী  : খাঁদি\n",
            "74.79757085020243 % completed\n",
            "খানুজা  : খানুজা\n",
            "74.84817813765183 % completed\n",
            "খাতকাদকলা  : খাতকাডকালা\n",
            "74.89878542510121 % completed\n",
            "খোমেইনি  : খোমোনি\n",
            "74.9493927125506 % completed\n",
            "খুকু  : খুঁকু\n",
            "75.0 % completed\n",
            "খুনগ্রা  : খুনগ্রা\n",
            "75.0506072874494 % completed\n",
            "কিচোচা  : কিকোচা\n",
            "75.10121457489879 % completed\n",
            "নট  : নোট\n",
            "75.15182186234817 % completed\n",
            "কোবসা  : কোবসা\n",
            "75.20242914979757 % completed\n",
            "কোলবি  : কোলবে\n",
            "75.25303643724696 % completed\n",
            "কোপারগাঁওকার  : কোপারগাঁওকার\n",
            "75.30364372469636 % completed\n",
            "কোরিয়াক  : কোরিয়াক\n",
            "75.35425101214575 % completed\n",
            "কোঠী  : কোঠী\n",
            "75.40485829959515 % completed\n",
            "ক্রান্তি  : ক্রান্তি\n",
            "75.45546558704453 % completed\n",
            "কৃপারানী  : কৃপারাণী\n",
            "75.50607287449392 % completed\n",
            "কৃষ্ণকিশোর  : কৃষ্ণকিশোর\n",
            "75.55668016194332 % completed\n",
            "কুলাচি  : কুলাচি\n",
            "75.60728744939271 % completed\n",
            "কুতবদ্দিন  : কুতাবুদ্দিন\n",
            "75.65789473684211 % completed\n",
            "লাদেন  : লাডেন\n",
            "75.7085020242915 % completed\n",
            "লজ্জাবতী  : লাজ্জাবতী\n",
            "75.75910931174089 % completed\n",
            "লাক্ষাদ্বীপ  : লক্ষদ্বীপ\n",
            "75.80971659919028 % completed\n",
            "লাল  : লাল\n",
            "75.86032388663968 % completed\n",
            "লালবাহাদুর  : লালবাহাদুর\n",
            "75.91093117408907 % completed\n",
            "লালকুমার  : লালকুমার\n",
            "75.96153846153847 % completed\n",
            "ল্যান্ড  : ল্যান্ড\n",
            "76.01214574898785 % completed\n",
            "ল্যান্ডার্স  : ল্যানডারস\n",
            "76.06275303643724 % completed\n",
            "লাং  : ল্যাং\n",
            "76.11336032388664 % completed\n",
            "লাথম  : লথম\n",
            "76.16396761133603 % completed\n",
            "লটু  : লতু\n",
            "76.21457489878543 % completed\n",
            "লিয়েগুয়েস  : লেগাগুয়েস\n",
            "76.26518218623482 % completed\n",
            "লেলিলগ্রাড  : লেনিনগ্রেড\n",
            "76.3157894736842 % completed\n",
            "লেইউসলেওয়াইস  : লিউইস\n",
            "76.3663967611336 % completed\n",
            "লীলারাণী  : লীলারাণী\n",
            "76.417004048583 % completed\n",
            "লিমায়  : লাইমায়\n",
            "76.46761133603239 % completed\n",
            "লাইনস  : লাইনস\n",
            "76.51821862348179 % completed\n",
            "লোকুহেট্টিগ  : লোকহেটাইজ\n",
            "76.56882591093117 % completed\n",
            "লোন্ধে  : লন্ধে\n",
            "76.61943319838056 % completed\n",
            "লোনকার  : লোঙ্কার\n",
            "76.67004048582996 % completed\n",
            "লাউডাউন  : লোউডাউন\n",
            "76.72064777327935 % completed\n",
            "মাছান্দার  : মাছন্দর\n",
            "76.77125506072875 % completed\n",
            "মেশিন  : মাচিন\n",
            "76.82186234817814 % completed\n",
            "ম্যাকমিলান  : ম্যাকমিল্লান\n",
            "76.87246963562752 % completed\n",
            "মাডেইরা  : মাদেইরা\n",
            "76.92307692307692 % completed\n",
            "মদেশ্বর  : মদেশ্বর\n",
            "76.97368421052632 % completed\n",
            "মাধব  : মাধব\n",
            "77.02429149797571 % completed\n",
            "মাদুগালে  : মাদুগাল্লে\n",
            "77.0748987854251 % completed\n",
            "মগারামমাগারাম  : মগরাম\n",
            "77.1255060728745 % completed\n",
            "মহাসীন  : মহসিন\n",
            "77.17611336032388 % completed\n",
            "মহেন্দর  : মহেন্দর\n",
            "77.22672064777328 % completed\n",
            "মহিদুন  : মহিদুন\n",
            "77.27732793522267 % completed\n",
            "মহিরউদ্দিন  : মহিরউদ্দিন\n",
            "77.32793522267207 % completed\n",
            "মহিরুম  : মহিরুম\n",
            "77.37854251012146 % completed\n",
            "মকিবুল  : মকিবুল\n",
            "77.42914979757084 % completed\n",
            "মাক্ষু  : মাক্ষু\n",
            "77.47975708502024 % completed\n",
            "মকসুদা  : মকসুদা\n",
            "77.53036437246963 % completed\n",
            "মালাবতী  : মালবতী\n",
            "77.58097165991903 % completed\n",
            "মালাধর  : মালধর\n",
            "77.63157894736842 % completed\n",
            "মালেকজান  : মালকজান\n",
            "77.68218623481782 % completed\n",
            "মালঞ্চ  : মালনচা\n",
            "77.7327935222672 % completed\n",
            "মালবোরোজ  : মালবোরোজ\n",
            "77.7834008097166 % completed\n",
            "মালহান  : মালহান\n",
            "77.83400809716599 % completed\n",
            "মলিনাবালা  : মলিনাবালা\n",
            "77.88461538461539 % completed\n",
            "মালোবিকা  : মালোবিকা\n",
            "77.93522267206478 % completed\n",
            "মাম্পী  : মম্পি\n",
            "77.98582995951416 % completed\n",
            "মনবাসনা  : মনবাসানা\n",
            "78.03643724696356 % completed\n",
            "মানবকুমার  : মনবকুমার\n",
            "78.08704453441295 % completed\n",
            "মনহারা  : মানহারা\n",
            "78.13765182186235 % completed\n",
            "মনামী  : মানামী\n",
            "78.18825910931174 % completed\n",
            "মনরঞ্জন  : মনরঞ্জন\n",
            "78.23886639676114 % completed\n",
            "মানস  : মনশ\n",
            "78.28947368421052 % completed\n",
            "মানসীরাণী  : মনসিরানী\n",
            "78.34008097165992 % completed\n",
            "মানেরা  : মানেরা\n",
            "78.39068825910931 % completed\n",
            "মনিজান  : মনিজান\n",
            "78.4412955465587 % completed\n",
            "মনিকান্ত  : মনিকান্ত\n",
            "78.4919028340081 % completed\n",
            "মনীশ  : মনিশ\n",
            "78.5425101214575 % completed\n",
            "মঞ্জুলা  : মঞ্জুলা\n",
            "78.59311740890688 % completed\n",
            "মনোমিলা  : মনোমিলা\n",
            "78.64372469635627 % completed\n",
            "মনোতোষ  : মনোতোষ\n",
            "78.69433198380567 % completed\n",
            "মনসুরআলম  : মনসুরআলম\n",
            "78.74493927125506 % completed\n",
            "মন্ত্রী  : মন্ত্রী\n",
            "78.79554655870446 % completed\n",
            "মানুবালা  : মনুবালা\n",
            "78.84615384615384 % completed\n",
            "মরগশ্যাম  : মার্গাশ্য়াম\n",
            "78.89676113360323 % completed\n",
            "মর্জিনাখাতুন  : মরজিনাখাতুন\n",
            "78.94736842105263 % completed\n",
            "মার্থা  : মার্থ\n",
            "78.99797570850203 % completed\n",
            "মসিবুল  : মসিবুল\n",
            "79.04858299595142 % completed\n",
            "মসিরুল  : মসিরুল\n",
            "79.09919028340082 % completed\n",
            "মসলিমা  : মসলিমা\n",
            "79.1497975708502 % completed\n",
            "মসরুর  : মসরুব\n",
            "79.20040485829959 % completed\n",
            "মাস্টারস  : মাস্টার্স\n",
            "79.25101214574899 % completed\n",
            "মাসুম  : মসুম\n",
            "79.30161943319838 % completed\n",
            "মসুর  : মসুর\n",
            "79.35222672064778 % completed\n",
            "মাসুরা  : মসুরা\n",
            "79.40283400809717 % completed\n",
            "মাতা  : মাতা\n",
            "79.45344129554655 % completed\n",
            "মাটিও  : মাতেও\n",
            "79.50404858299595 % completed\n",
            "মতি  : মতি\n",
            "79.55465587044534 % completed\n",
            "মতিবুল  : মতিবুল\n",
            "79.60526315789474 % completed\n",
            "মুগাম  : মউঘাম\n",
            "79.65587044534414 % completed\n",
            "ম্যাক্স  : ম্যাক্স\n",
            "79.70647773279352 % completed\n",
            "মেনার্ড  : মেইনার্ড\n",
            "79.75708502024291 % completed\n",
            "ম্যাকাকাকোয়ে  : ম্যাককাওয়েলি\n",
            "79.8076923076923 % completed\n",
            "মিসারিং  : মেসুরিং\n",
            "79.8582995951417 % completed\n",
            "ম্যাকলেনবার্গ  : মেকলেনবার্গ\n",
            "79.9089068825911 % completed\n",
            "মেডেলস  : মেডালস\n",
            "79.95951417004049 % completed\n",
            "মেরি  : মেরি\n",
            "80.01012145748987 % completed\n",
            "মেটালিকস  : মেটালিকস\n",
            "80.06072874493927 % completed\n",
            "মেথোডিস্ট  : মেথোডিস্ট\n",
            "80.11133603238866 % completed\n",
            "মিলান  : মিলন\n",
            "80.16194331983806 % completed\n",
            "মিনাক্ষী  : মিনাক্ষী\n",
            "80.21255060728745 % completed\n",
            "মিনারাবিবি  : মিনারাবিবি\n",
            "80.26315789473684 % completed\n",
            "মিনারওয়া  : মিনারওয়া\n",
            "80.31376518218623 % completed\n",
            "মিনো  : মিনু\n",
            "80.36437246963563 % completed\n",
            "মিনুবালা  : মিনুবালা\n",
            "80.41497975708502 % completed\n",
            "মীরজাহান  : মিরজাহান\n",
            "80.46558704453442 % completed\n",
            "মিতুম্বা  : মিটুম্বা\n",
            "80.51619433198381 % completed\n",
            "মোহিনিআট্টম  : মোহিনিয়াটাম\n",
            "80.56680161943319 % completed\n",
            "মোহিতকুমার  : মোহিতকুমার\n",
            "80.61740890688259 % completed\n",
            "মোনাশি  : মোনাশি\n",
            "80.66801619433198 % completed\n",
            "মনোরমাদেবী  : মনোরামাদেবা\n",
            "80.71862348178138 % completed\n",
            "মোনসুর  : মোনসুর\n",
            "80.76923076923077 % completed\n",
            "মোন্টশিরী  : মোন্টস্যারে\n",
            "80.81983805668017 % completed\n",
            "মোটি  : মন্টী\n",
            "80.87044534412955 % completed\n",
            "মুন  : মুন\n",
            "80.92105263157895 % completed\n",
            "মোরেলস  : মোরেলস\n",
            "80.97165991902834 % completed\n",
            "মোরপেন  : মোরেপেন\n",
            "81.02226720647774 % completed\n",
            "মোরিসন  : মোরিসন\n",
            "81.07287449392713 % completed\n",
            "মরো  : মোরো\n",
            "81.12348178137651 % completed\n",
            "মাদার  : মাদার\n",
            "81.17408906882591 % completed\n",
            "মাদারসন  : মাদারসন\n",
            "81.2246963562753 % completed\n",
            "মৌলদা  : মৌলোদা\n",
            "81.2753036437247 % completed\n",
            "মৌসম  : মৌসাম\n",
            "81.32591093117409 % completed\n",
            "মৌসুমি  : মৌসুমী\n",
            "81.37651821862349 % completed\n",
            "মোজাম্বিক  : মোজামবিকি\n",
            "81.42712550607287 % completed\n",
            "মাদ্রিস  : মুড্রিস\n",
            "81.47773279352226 % completed\n",
            "মুহার  : মুহার\n",
            "81.52834008097166 % completed\n",
            "মুকিলটিও  : মুকিলতেও\n",
            "81.57894736842105 % completed\n",
            "মুক্তলতা  : মুক্তলতা\n",
            "81.62955465587045 % completed\n",
            "মুক্তারাণী  : মুক্তারানী\n",
            "81.68016194331983 % completed\n",
            "মুক্তেশ্বর  : মুক্তেশ্বর\n",
            "81.73076923076923 % completed\n",
            "মুক্তিবালা  : মুক্তিবালামুক্তিবালা\n",
            "81.78137651821862 % completed\n",
            "মুকুন্দলাল  : মুকুন্দলাল\n",
            "81.83198380566802 % completed\n",
            "মুলুকচাঁদ  : মুলুকচাঁদ\n",
            "81.88259109311741 % completed\n",
            "মুনেজা  : মুনেজা\n",
            "81.93319838056681 % completed\n",
            "মূনকির  : মুনকির\n",
            "81.98380566801619 % completed\n",
            "মুন্নালাল  : মুন্নালাল\n",
            "82.03441295546558 % completed\n",
            "মুপারিয়া  : মুপারিওয়া\n",
            "82.08502024291498 % completed\n",
            "মুরতাজা  : মুরতাজা\n",
            "82.13562753036437 % completed\n",
            "মুশলিমা  : মুশলিমা\n",
            "82.18623481781377 % completed\n",
            "মুস্তরী  : মুস্তারি\n",
            "82.23684210526316 % completed\n",
            "মুথা  : মুথা\n",
            "82.28744939271255 % completed\n",
            "মুথিয়া  : মুত্তি\n",
            "82.33805668016194 % completed\n",
            "মুজাফফের  : মুজাফার\n",
            "82.38866396761134 % completed\n",
            "নবদ্বীপ  : নবদ্বিপ\n",
            "82.43927125506073 % completed\n",
            "নবনীধর  : নবনীধর\n",
            "82.48987854251013 % completed\n",
            "নবনীতা  : নবানিতা\n",
            "82.54048582995951 % completed\n",
            "নাদিম  : নাদেম\n",
            "82.5910931174089 % completed\n",
            "নাগিনা  : নগিনা\n",
            "82.6417004048583 % completed\n",
            "নাজবুল  : নজবুল\n",
            "82.6923076923077 % completed\n",
            "নাজেলা  : নাজেলা\n",
            "82.74291497975709 % completed\n",
            "নাজিনাবিবি  : নাজিনাবিবি\n",
            "82.79352226720648 % completed\n",
            "নাজমুদ্দিন  : নজমুদ্দিন\n",
            "82.84412955465586 % completed\n",
            "নাজনীন  : নজনীননাজনীন\n",
            "82.89473684210526 % completed\n",
            "নজরুল  : নজরুল\n",
            "82.94534412955466 % completed\n",
            "নালন্দা  : নলন্দ\n",
            "82.99595141700405 % completed\n",
            "নলিনী  : নালিনী\n",
            "83.04655870445345 % completed\n",
            "ন্যান্সি  : নান্সি\n",
            "83.09716599190283 % completed\n",
            "নওসদ  : নওসাদ\n",
            "83.14777327935222 % completed\n",
            "নারানচন্দ্র  : নরনচন্দ্র\n",
            "83.19838056680162 % completed\n",
            "নরুলইসলাম  : নারুলিসলাম\n",
            "83.24898785425101 % completed\n",
            "নাসেদ  : নাসেদ\n",
            "83.29959514170041 % completed\n",
            "নাসিরউদ্দিন  : নসিরুদ্দিন\n",
            "83.3502024291498 % completed\n",
            "নাথোওয়াল  : নাথোওয়াল\n",
            "83.40080971659918 % completed\n",
            "নাভারে  : নাভারে\n",
            "83.45141700404858 % completed\n",
            "নায়েক  : নয়ক\n",
            "83.50202429149797 % completed\n",
            "নেসিসিটি  : নিসেসিসিটি\n",
            "83.55263157894737 % completed\n",
            "নেলাই  : নেলাই\n",
            "83.60323886639677 % completed\n",
            "নেসলে  : নেস্টেল\n",
            "83.65384615384616 % completed\n",
            "নিউবাই  : নিউবি\n",
            "83.70445344129554 % completed\n",
            "নিউডিগেট  : নিউডিগেট\n",
            "83.75506072874494 % completed\n",
            "নিউজস  : নিউস\n",
            "83.80566801619433 % completed\n",
            "নায়াগ্রানিয়াগর  : নিয়াগারা\n",
            "83.85627530364373 % completed\n",
            "নিক  : নিক\n",
            "83.90688259109312 % completed\n",
            "নিগিতসু  : নাইগিটসু\n",
            "83.9574898785425 % completed\n",
            "নীহারবালা  : নিহারবালা\n",
            "84.0080971659919 % completed\n",
            "নিকুঞ্জ  : নিকুঞ্জ\n",
            "84.0587044534413 % completed\n",
            "নিলাদ্রী  : নীলাদ্রি\n",
            "84.10931174089069 % completed\n",
            "নিলীমা  : নিলিমা\n",
            "84.15991902834008 % completed\n",
            "নিলকমল  : নীলকমল\n",
            "84.21052631578948 % completed\n",
            "নিওস  : নিওস\n",
            "84.26113360323886 % completed\n",
            "নিরোশন  : নীরোশন\n",
            "84.31174089068826 % completed\n",
            "নিস্তারিণী  : নিস্তারিনী\n",
            "84.36234817813765 % completed\n",
            "নকুলেশ্বর  : নোকুলেশ্বর\n",
            "84.41295546558705 % completed\n",
            "নরওয়েজিয়ান  : নরওয়েগিয়ান\n",
            "84.46356275303644 % completed\n",
            "নোভোরসিস্ক  : নোভোরোসিস্ক\n",
            "84.51417004048584 % completed\n",
            "নূরআলি  : নুরআলি\n",
            "84.56477732793522 % completed\n",
            "নুরজাহানা  : নুরজাহানা\n",
            "84.61538461538461 % completed\n",
            "নুরজিমা  : নুরজিমা\n",
            "84.66599190283401 % completed\n",
            "নুরনবি  : নুরনাবি\n",
            "84.7165991902834 % completed\n",
            "নুসোম  : নুসোম\n",
            "84.7672064777328 % completed\n",
            "ওবাইদুর  : ওবাইদুর\n",
            "84.81781376518218 % completed\n",
            "ওবুয়া  : ওবুয়া\n",
            "84.86842105263158 % completed\n",
            "ওফেন্সিভ  : ওফেনসিভ\n",
            "84.91902834008097 % completed\n",
            "ওগিলভি  : ওগিলভি\n",
            "84.96963562753037 % completed\n",
            "ওখোটস্ক  : ওখোটস্ক\n",
            "85.02024291497976 % completed\n",
            "অনলাইন  : অনলিন\n",
            "85.07085020242916 % completed\n",
            "ওরাম  : ওরাম\n",
            "85.12145748987854 % completed\n",
            "অরলিনস  : ওরলেনস\n",
            "85.17206477732793 % completed\n",
            "ওসমিয়াম  : ওসমিয়াম\n",
            "85.22267206477733 % completed\n",
            "অক্সিজেন  : অক্সিজেন\n",
            "85.27327935222672 % completed\n",
            "ওযাজদ্দিন  : ওযাজুদ্দিন\n",
            "85.32388663967612 % completed\n",
            "ওজহার  : ওজহার\n",
            "85.3744939271255 % completed\n",
            "পাগ  : পাগে\n",
            "85.4251012145749 % completed\n",
            "পলান  : পালন\n",
            "85.47570850202429 % completed\n",
            "পলাশী  : পলাশী\n",
            "85.52631578947368 % completed\n",
            "পরমজিত  : পরমজিত\n",
            "85.57692307692308 % completed\n",
            "পারাশনাথ  : পরশনাথ\n",
            "85.62753036437248 % completed\n",
            "পরিমলচন্দ্র  : পরিমলচন্দ্র\n",
            "85.67813765182186 % completed\n",
            "পারোরে  : পারোরে\n",
            "85.72874493927125 % completed\n",
            "পস্টারনেক  : পাস্টারনেক\n",
            "85.77935222672065 % completed\n",
            "পটলবালা  : পটলবালা\n",
            "85.82995951417004 % completed\n",
            "পতিতপাবন  : পতিতপাবন\n",
            "85.88056680161944 % completed\n",
            "পেনে  : পেন\n",
            "85.93117408906883 % completed\n",
            "পেকুক  : পেকোক\n",
            "85.98178137651821 % completed\n",
            "পিয়েল  : পিয়েল\n",
            "86.03238866396761 % completed\n",
            "পেচিপারাই  : পেচিপারাই\n",
            "86.082995951417 % completed\n",
            "পেডার  : পিডার\n",
            "86.1336032388664 % completed\n",
            "ফনীগোপাল  : ফণীগোপাল\n",
            "86.1842105263158 % completed\n",
            "ফরিজুল  : ফরিজুল\n",
            "86.23481781376518 % completed\n",
            "ফারশিলা  : ফারশিলা\n",
            "86.28542510121457 % completed\n",
            "ফেলিবালা  : ফেলিবালা\n",
            "86.33603238866397 % completed\n",
            "ফিলাটেলিক  : ফিলাটেলিক\n",
            "86.38663967611336 % completed\n",
            "পিক  : পিক\n",
            "86.43724696356276 % completed\n",
            "পিলিবহিট  : পিলিভিথ\n",
            "86.48785425101215 % completed\n",
            "পিসা  : পিসা\n",
            "86.53846153846153 % completed\n",
            "পিট্টসবার্গ  : পিটসবার্গ\n",
            "86.58906882591093 % completed\n",
            "পিউ  : পিউ\n",
            "86.63967611336032 % completed\n",
            "পোয়ে  : পো\n",
            "86.69028340080972 % completed\n",
            "পোল্যান্ড  : পোলন্ড\n",
            "86.74089068825911 % completed\n",
            "পোলোনিও  : পোলোনিয়া\n",
            "86.7914979757085 % completed\n",
            "পণ্ডিচেরী  : পন্ডিচেরি\n",
            "86.84210526315789 % completed\n",
            "পোর্টল্যান্ড  : পোর্টল্যান্ড\n",
            "86.89271255060729 % completed\n",
            "প্রবাল  : প্রবাল\n",
            "86.94331983805668 % completed\n",
            "প্রভাদেবী  : প্রভাদেবী\n",
            "86.99392712550608 % completed\n",
            "প্রমদা  : প্রমোদা\n",
            "87.04453441295547 % completed\n",
            "প্রসাদী  : প্রসাদি\n",
            "87.09514170040485 % completed\n",
            "প্রতীভা  : প্রতিভা\n",
            "87.14574898785425 % completed\n",
            "প্রিযরঞ্জন  : প্রীযারঞ্জন\n",
            "87.19635627530364 % completed\n",
            "প্রো  : প্র\n",
            "87.24696356275304 % completed\n",
            "পুব  : পুব\n",
            "87.29757085020243 % completed\n",
            "পূবালী  : পুবালি\n",
            "87.34817813765183 % completed\n",
            "পাঞ্জাব  : পাঞ্জব\n",
            "87.39878542510121 % completed\n",
            "পুর্ভদে  : পুরভোদে\n",
            "87.4493927125506 % completed\n",
            "পুষ্পদেবী  : পুস্পদেবী\n",
            "87.5 % completed\n",
            "পুটরী  : পুট্রী\n",
            "87.5506072874494 % completed\n",
            "পুতুলিপুতুলী  : পুটুলি\n",
            "87.60121457489879 % completed\n",
            "কুয়াইলে  : কুয়ালি\n",
            "87.65182186234817 % completed\n",
            "কিলা  : কুইলা\n",
            "87.70242914979757 % completed\n",
            "কুইটো  : কুইটো\n",
            "87.75303643724696 % completed\n",
            "রবিপ্রকাশ  : রবিপ্রকাশ\n",
            "87.80364372469636 % completed\n",
            "রবিরাম  : রবিরাম\n",
            "87.85425101214575 % completed\n",
            "রাধামাধব  : রাধামধব\n",
            "87.90485829959515 % completed\n",
            "রাধিকাদেবী  : রাধিকাদেবী\n",
            "87.95546558704453 % completed\n",
            "রফিজা  : রফিজা\n",
            "88.00607287449392 % completed\n",
            "রাফিক  : রফিক\n",
            "88.05668016194332 % completed\n",
            "রহমতআলি  : রহমতআলি\n",
            "88.10728744939271 % completed\n",
            "রহনীবালা  : রহিনীবালা\n",
            "88.15789473684211 % completed\n",
            "রাইমন  : রাইমন\n",
            "88.2085020242915 % completed\n",
            "রজবআলী  : রাজাবআলি\n",
            "88.25910931174089 % completed\n",
            "রাজবল্লভ  : রাজবল্লভ\n",
            "88.30971659919028 % completed\n",
            "রাজবীর  : রাজবির\n",
            "88.36032388663968 % completed\n",
            "রাজেশ্বর  : রাজেশ্বর\n",
            "88.41093117408907 % completed\n",
            "রাজলক্ষীরাজলক্ষ্মী  : রাজলক্ষী\n",
            "88.46153846153847 % completed\n",
            "রাখাদ  : রাখাদ\n",
            "88.51214574898785 % completed\n",
            "রামান  : রামন\n",
            "88.56275303643724 % completed\n",
            "রমাপদ  : রামাপদ\n",
            "88.61336032388664 % completed\n",
            "রামাপ্পা  : রামাপ্পা\n",
            "88.66396761133603 % completed\n",
            "রমাপ্রসাদ  : রামাপ্রসাদ\n",
            "88.71457489878543 % completed\n",
            "রম্ভাবতী  : রাম্ভাবতী\n",
            "88.76518218623482 % completed\n",
            "রামদেও  : রামদেও\n",
            "88.8157894736842 % completed\n",
            "রামহরি  : রামহারি\n",
            "88.8663967611336 % completed\n",
            "রামফল  : রামফাল\n",
            "88.917004048583 % completed\n",
            "রামসর  : রামসর\n",
            "88.96761133603239 % completed\n",
            "রানাডে  : রানাদে\n",
            "89.01821862348179 % completed\n",
            "রনবীর  : রণবীর\n",
            "89.06882591093117 % completed\n",
            "রত্নাবলী  : রঙ্গবালি\n",
            "89.11943319838056 % completed\n",
            "রঙ্গঁলাল  : রঙ্গলাল\n",
            "89.17004048582996 % completed\n",
            "রংবাহাদুর  : রংবাহাদুর\n",
            "89.22064777327935 % completed\n",
            "রাসল  : রসাল\n",
            "89.27125506072875 % completed\n",
            "রাসেদআলি  : রাসেদআলি\n",
            "89.32186234817814 % completed\n",
            "রাশবেহারী  : রাশবেহারী\n",
            "89.37246963562752 % completed\n",
            "রাস্পবেরি  : রেসপবেরি\n",
            "89.42307692307692 % completed\n",
            "রতন  : রতন\n",
            "89.47368421052632 % completed\n",
            "রথুলাল  : রথুলাল\n",
            "89.52429149797571 % completed\n",
            "রি  : রে\n",
            "89.5748987854251 % completed\n",
            "রেডপথ  : রেডপথ\n",
            "89.6255060728745 % completed\n",
            "রিল  : রিয়েল\n",
            "89.67611336032388 % completed\n",
            "রেহেনা  : রেহেনা\n",
            "89.72672064777328 % completed\n",
            "রেওন  : রিওন\n",
            "89.77732793522267 % completed\n",
            "রেয়িকজাভিক  : রেইকজাভিক\n",
            "89.82793522267207 % completed\n",
            "রিজনাউওতেন  : রিজনাউওয়েন\n",
            "89.87854251012146 % completed\n",
            "রিজ  : রিজ\n",
            "89.92914979757084 % completed\n",
            "রিগা  : রিগা\n",
            "89.97975708502024 % completed\n",
            "রিজাউলহক  : রিজাউলহক\n",
            "90.03036437246963 % completed\n",
            "রিম  : রিম\n",
            "90.08097165991903 % completed\n",
            "রিন্ডলে  : রিনডেল\n",
            "90.13157894736842 % completed\n",
            "রিনেল্লা  : রিনেলা\n",
            "90.18218623481782 % completed\n",
            "ঋষিকান্ত  : ঋষিখান্ত\n",
            "90.2327935222672 % completed\n",
            "হৃষিকেশ  : রিশিকেশ\n",
            "90.2834008097166 % completed\n",
            "রবিনরোবিন  : রোবিন\n",
            "90.33400809716599 % completed\n",
            "রবিনস  : রোবিন্স\n",
            "90.38461538461539 % completed\n",
            "রকফোর্ড  : রকফোর্ড\n",
            "90.43522267206478 % completed\n",
            "রোয়েবাক  : রোইবাক\n",
            "90.48582995951416 % completed\n",
            "রোহিলা  : রোহিলা\n",
            "90.53643724696356 % completed\n",
            "রহিত  : রোহিত\n",
            "90.58704453441295 % completed\n",
            "রোজিনাবেগম  : রোজিনাবেগম\n",
            "90.63765182186235 % completed\n",
            "রোমা  : রোমা\n",
            "90.68825910931174 % completed\n",
            "রোজেনবার্গ  : রোজেনবার্গ\n",
            "90.73886639676114 % completed\n",
            "রসরোজ  : রোস\n",
            "90.78947368421052 % completed\n",
            "রুচি  : রুচি\n",
            "90.84008097165992 % completed\n",
            "রুকসাহানা  : রুকসাহানা\n",
            "90.89068825910931 % completed\n",
            "রুমেলিহিসার  : রুমেলিহিসর\n",
            "90.9412955465587 % completed\n",
            "রুণু  : রুনু\n",
            "90.9919028340081 % completed\n",
            "রুপাই  : রুপাই\n",
            "91.0425101214575 % completed\n",
            "রুপানা  : রুপনা\n",
            "91.09311740890688 % completed\n",
            "রুস  : রুস\n",
            "91.14372469635627 % completed\n",
            "রাষ্টভিলা  : রুস্টাভেলি\n",
            "91.19433198380567 % completed\n",
            "রায়ানায়ার  : রিয়ানের\n",
            "91.24493927125506 % completed\n",
            "সাব্বির  : সাব্বির\n",
            "91.29554655870446 % completed\n",
            "সাবিব  : সাবিব\n",
            "91.34615384615384 % completed\n",
            "সাবিনাল  : সাবিনাল\n",
            "91.39676113360323 % completed\n",
            "সাবিত্রীদেবী  : সবিত্রীদেবী\n",
            "91.44736842105263 % completed\n",
            "সাবনিস  : সাবনিশ\n",
            "91.49797570850203 % completed\n",
            "সচীনন্দন  : শচীন্ননন্দন\n",
            "91.54858299595142 % completed\n",
            "সাদাব  : সাদাব\n",
            "91.59919028340082 % completed\n",
            "সাদাত  : সাদাত\n",
            "91.6497975708502 % completed\n",
            "সৈকত  : সাইকাত\n",
            "91.70040485829959 % completed\n",
            "সজল  : সাজল\n",
            "91.75101214574899 % completed\n",
            "সাকিলা  : সাকিলা\n",
            "91.80161943319838 % completed\n",
            "সালমোন  : সালমন\n",
            "91.85222672064778 % completed\n",
            "সামেদ  : সামেদ\n",
            "91.90283400809717 % completed\n",
            "সমরেন্দ্র  : সামোরেন্দ্রা\n",
            "91.95344129554655 % completed\n",
            "সাঙ্গানের  : সানগানের\n",
            "92.00404858299595 % completed\n",
            "সেপিয়েন্স  : স্যাপিয়েন্স\n",
            "92.05465587044534 % completed\n",
            "সরগডি  : সরগাদি\n",
            "92.10526315789474 % completed\n",
            "সারই  : সারাই\n",
            "92.15587044534414 % completed\n",
            "সারফ্রাজ  : সারফ্রাজ\n",
            "92.20647773279352 % completed\n",
            "সারহাড্ডী  : সরহাদ্দি\n",
            "92.25708502024291 % completed\n",
            "সারজাহান  : সরজাহান\n",
            "92.3076923076923 % completed\n",
            "সুন্দরস  : সাউন্ডারস\n",
            "92.3582995951417 % completed\n",
            "সেকিব  : সেকিব\n",
            "92.4089068825911 % completed\n",
            "সেরা  : সেরা\n",
            "92.45951417004049 % completed\n",
            "সেরাফত্  : সেরাফাথ\n",
            "92.51012145748987 % completed\n",
            "সেরাজ  : সেরাজ\n",
            "92.56072874493927 % completed\n",
            "শচীপদ  : শচীপদ\n",
            "92.61133603238866 % completed\n",
            "সাফিক  : শাফিয়েক\n",
            "92.66194331983806 % completed\n",
            "শাহনাজশাহানাজ  : শাহানাজ\n",
            "92.71255060728745 % completed\n",
            "শম্ভুরাম  : শম্ভুরাম\n",
            "92.76315789473684 % completed\n",
            "শান্তি  : শান্তি\n",
            "92.81376518218623 % completed\n",
            "শর্মিলা  : শর্মিলা\n",
            "92.86437246963563 % completed\n",
            "শতু  : শাতু\n",
            "92.91497975708502 % completed\n",
            "স  : শাও\n",
            "92.96558704453442 % completed\n",
            "শেখপুরা  : শেখপুরা\n",
            "93.01619433198381 % completed\n",
            "শেলফ  : শেলফ\n",
            "93.06680161943319 % completed\n",
            "শেরিন  : শেরিন\n",
            "93.11740890688259 % completed\n",
            "শেরশাহ  : শেরশাহা\n",
            "93.16801619433198 % completed\n",
            "শিমান  : শিমান\n",
            "93.21862348178138 % completed\n",
            "শ্যু  : শোয়েস\n",
            "93.26923076923077 % completed\n",
            "শ্রীকৃষ্ণ  : শ্রীকৃষ্ণ\n",
            "93.31983805668017 % completed\n",
            "শুভাশিস  : শুভাশিষ\n",
            "93.37044534412955 % completed\n",
            "শুভ্রদীপ  : শুভ্রদীপ\n",
            "93.42105263157895 % completed\n",
            "সিদ্ধনাথ  : সিধানাথ\n",
            "93.47165991902834 % completed\n",
            "সিদ্কি  : সিডকি\n",
            "93.52226720647774 % completed\n",
            "সিফি  : সাইফাই\n",
            "93.57287449392713 % completed\n",
            "সিমন্স  : সিমোন্স\n",
            "93.62348178137651 % completed\n",
            "সিন্ধুরাণী  : সিন্ধুরানী\n",
            "93.67408906882591 % completed\n",
            "সিংভি  : সিংহি\n",
            "93.7246963562753 % completed\n",
            "সিরওাল  : সিরওয়াল\n",
            "93.7753036437247 % completed\n",
            "সিভনি  : সিভনী\n",
            "93.82591093117409 % completed\n",
            "স্কেটিং  : স্কাটিং\n",
            "93.87651821862349 % completed\n",
            "স্লেটার  : স্লেডার\n",
            "93.92712550607287 % completed\n",
            "স্মার্ট  : স্মার্ট\n",
            "93.97773279352226 % completed\n",
            "সোমাশ্রী  : সোমাশ্রী\n",
            "94.02834008097166 % completed\n",
            "সোনাহারা  : সোনাহারা\n",
            "94.07894736842105 % completed\n",
            "সোনালি  : সোনালী\n",
            "94.12955465587045 % completed\n",
            "সোনে  : সোনে\n",
            "94.18016194331983 % completed\n",
            "সনিয়া  : সোনিয়া\n",
            "94.23076923076923 % completed\n",
            "সৌখি  : সৌখি\n",
            "94.28137651821862 % completed\n",
            "স্পানিসস্পানিশ  : স্পানিশ\n",
            "94.33198380566802 % completed\n",
            "শ্রেষ্টো  : স্রেশ্থ\n",
            "94.38259109311741 % completed\n",
            "স্টপলেস  : স্টেপ্লস\n",
            "94.43319838056681 % completed\n",
            "স্টেপলটন  : স্টাপ্লেটন\n",
            "94.48380566801619 % completed\n",
            "স্টেউরগট  : স্টুরগেট\n",
            "94.53441295546558 % completed\n",
            "স্টিভ  : স্টিভ\n",
            "94.58502024291498 % completed\n",
            "স্টোরি  : স্টোরেস\n",
            "94.63562753036437 % completed\n",
            "স্টর্ম  : স্টোম\n",
            "94.68623481781377 % completed\n",
            "স্তোতিনকি  : স্টোটিঙ্কি\n",
            "94.73684210526316 % completed\n",
            "স্ট্রনটিয়াম  : স্ট্রন্টিয়াম\n",
            "94.78744939271255 % completed\n",
            "সুভাষচন্দ্র  : শুভাষচন্দ্র\n",
            "94.83805668016194 % completed\n",
            "সুবোধরঞ্জন  : সুবোধরঞ্জন\n",
            "94.88866396761134 % completed\n",
            "সুব্রমণিয়ম  : সুব্রমান্যাম\n",
            "94.93927125506073 % completed\n",
            "সুচিন্ত  : সুচিন্ত\n",
            "94.98987854251013 % completed\n",
            "সুক্রে  : সাক্রি\n",
            "95.04048582995951 % completed\n",
            "সুধীরচন্দ্র  : সুধীরচন্দ্র\n",
            "95.0910931174089 % completed\n",
            "সুদীপ্তসুদীপ্তা  : সুদীপ্তা\n",
            "95.1417004048583 % completed\n",
            "সুখীবালা  : সুখীবালা\n",
            "95.1923076923077 % completed\n",
            "সুলতানাখাতুন  : সুলতানাখাতুন\n",
            "95.24291497975709 % completed\n",
            "স্লুজবেগার  : সাল্জবার্গার\n",
            "95.29352226720648 % completed\n",
            "সুমিত  : সুম্মিত\n",
            "95.34412955465586 % completed\n",
            "সুনন্দা  : সুনন্দ\n",
            "95.39473684210526 % completed\n",
            "সুরেশ  : সুরেশ\n",
            "95.44534412955466 % completed\n",
            "সুভেন  : সুভেন\n",
            "95.49595141700405 % completed\n",
            "ভেনস্কা  : স্ভেন্সকা\n",
            "95.54655870445345 % completed\n",
            "সভির্কা  : স্ভিরকা\n",
            "95.59716599190283 % completed\n",
            "সোন্ন  : সোয়ান\n",
            "95.64777327935222 % completed\n",
            "স্বাতীলেখা  : স্বাতিলেখা\n",
            "95.69838056680162 % completed\n",
            "সিরিয়া  : সায়েরিয়া\n",
            "95.74898785425101 % completed\n",
            "তাজ  : তাজ\n",
            "95.79959514170041 % completed\n",
            "টাকু  : টাকু\n",
            "95.8502024291498 % completed\n",
            "তলা  : তালা\n",
            "95.90080971659918 % completed\n",
            "তলভ  : তালভ\n",
            "95.95141700404858 % completed\n",
            "তালিব  : তালিব\n",
            "96.00202429149797 % completed\n",
            "তমাল  : তামাল\n",
            "96.05263157894737 % completed\n",
            "তমালী  : তামালি\n",
            "96.10323886639677 % completed\n",
            "তামালকৃষ্ণ  : তমলকৃষ্ণ\n",
            "96.15384615384616 % completed\n",
            "টনিবিবি  : তানিবিবি\n",
            "96.20445344129554 % completed\n",
            "তনুবিবি  : তানুবিবি\n",
            "96.25506072874494 % completed\n",
            "তনুজাবিবি  : তনুজাবিবি\n",
            "96.30566801619433 % completed\n",
            "তনুশ্রী  : তানুশ্রী\n",
            "96.35627530364373 % completed\n",
            "তাপস  : তাপস\n",
            "96.40688259109312 % completed\n",
            "তপতীবালা  : তপতিবালা\n",
            "96.4574898785425 % completed\n",
            "তারাকান্ত  : তারাকান্ত\n",
            "96.5080971659919 % completed\n",
            "টারো  : টারো\n",
            "96.5587044534413 % completed\n",
            "টেড  : টেড\n",
            "96.60931174089069 % completed\n",
            "টেং  : টেঙ্গ\n",
            "96.65991902834008 % completed\n",
            "টেক্সাস  : টেক্সাস\n",
            "96.71052631578948 % completed\n",
            "থার্মোস্ফিয়ার  : থার্মোস্ফিয়ার\n",
            "96.76113360323886 % completed\n",
            "তিরুনাভুক্কারাসু  : তিরুনাভুকারাসি\n",
            "96.81174089068826 % completed\n",
            "থোমাস  : থোমাস\n",
            "96.86234817813765 % completed\n",
            "থুনাকাদাভু  : থুনাকাদাভু\n",
            "96.91295546558705 % completed\n",
            "তিকামগড়  : তিকামগড়\n",
            "96.96356275303644 % completed\n",
            "টিক্কেকার  : টিকেকার\n",
            "97.01417004048584 % completed\n",
            "তিরুক্কান্নানকুদি  : তিরুকন্নানকুদি\n",
            "97.06477732793522 % completed\n",
            "তিরুক্কুরুনকুদি  : তিরুকুরুনকুদি\n",
            "97.11538461538461 % completed\n",
            "টোকানতিন্স  : টোকান্টিন্স\n",
            "97.16599190283401 % completed\n",
            "টোটাল  : টোটাল\n",
            "97.2165991902834 % completed\n",
            "টাউন  : টাউন\n",
            "97.2672064777328 % completed\n",
            "ট্রিথলোন  : ট্রারিথলন\n",
            "97.31781376518218 % completed\n",
            "তৃনা  : ত্রিনা\n",
            "97.36842105263158 % completed\n",
            "ত্রিনাথ  : তৃনাথ\n",
            "97.41902834008097 % completed\n",
            "ট্রোব  : ট্রোব\n",
            "97.46963562753037 % completed\n",
            "ট্রুকিন  : ট্রাকিন\n",
            "97.52024291497976 % completed\n",
            "তুলসীচরণ  : তুলসীচরন\n",
            "97.57085020242916 % completed\n",
            "টুনুরাণী  : টুনুরানী\n",
            "97.62145748987854 % completed\n",
            "টুসি  : টুসি\n",
            "97.67206477732793 % completed\n",
            "টু  : টো\n",
            "97.72267206477733 % completed\n",
            "টোস  : টুস\n",
            "97.77327935222672 % completed\n",
            "ত্যাগরাজার  : ত্যাগরাজর\n",
            "97.82388663967612 % completed\n",
            "টাইসন  : টাইসন\n",
            "97.8744939271255 % completed\n",
            "উড়িয়া  : উদিয়া\n",
            "97.9251012145749 % completed\n",
            "উক্কুসিকসালিক  : উক্ষ্কুকসালিক\n",
            "97.97570850202429 % completed\n",
            "উলাঙ্গিনী  : উল্লাঙ্গিনী\n",
            "98.02631578947368 % completed\n",
            "উমেশচন্দ্র  : উমেশচন্দ্র\n",
            "98.07692307692308 % completed\n",
            "ইউনিলিভার  : ইউনিলিভার\n",
            "98.12753036437248 % completed\n",
            "উষাঙ্গিনী  : উষাঙ্গিনী\n",
            "98.17813765182186 % completed\n",
            "ভাহালকার  : ভাহালকার\n",
            "98.22874493927125 % completed\n",
            "ভাল্মোর  : ভালমোর\n",
            "98.27935222672065 % completed\n",
            "ভান্টা  : ভান্তা\n",
            "98.32995951417004 % completed\n",
            "ভারাদকার  : ভারাদকার\n",
            "98.38056680161944 % completed\n",
            "ভারিয়াগ  : ভারয়াগ\n",
            "98.43117408906883 % completed\n",
            "ভীরভূম  : ভীরভূম\n",
            "98.48178137651821 % completed\n",
            "ভেল্লারি  : ভেলারি\n",
            "98.53238866396761 % completed\n",
            "ভেনেরিওলজি  : ভেনেরিওলজি\n",
            "98.582995951417 % completed\n",
            "ভারেগিও  : ভায়ারেগিও\n",
            "98.6336032388664 % completed\n",
            "ভিডিও  : ভিদেও\n",
            "98.6842105263158 % completed\n",
            "বিদ্যা  : বিদ্য\n",
            "98.73481781376518 % completed\n",
            "ভীজ  : ভিজ\n",
            "98.78542510121457 % completed\n",
            "ভিলেজ  : ভিলেজ\n",
            "98.83603238866397 % completed\n",
            "বিপাশা  : বিপাশা\n",
            "98.88663967611336 % completed\n",
            "ভিরয়ানেট  : ভিরানেত\n",
            "98.93724696356276 % completed\n",
            "ভিভিয়ান  : ভিভিয়ান\n",
            "98.98785425101215 % completed\n",
            "ভিমোক্ষ  : প্মক্ষা\n",
            "99.03846153846153 % completed\n",
            "ওয়াচ্ছার  : ওয়াচার\n",
            "99.08906882591093 % completed\n",
            "ওয়াক  : ওয়াল্ক\n",
            "99.13967611336032 % completed\n",
            "ওয়ালাকে  : ওয়ালান\n",
            "99.19028340080972 % completed\n",
            "উইলিংটন  : ওয়ালিংটন\n",
            "99.24089068825911 % completed\n",
            "ওয়ারিওর  : ওয়ারিয়ার\n",
            "99.2914979757085 % completed\n",
            "ওয়াটসন  : ওয়াটসন\n",
            "99.34210526315789 % completed\n",
            "ওয়াট  : ওয়াট\n",
            "99.39271255060729 % completed\n",
            "ওয়াভদে  : ওয়াভদে\n",
            "99.44331983805668 % completed\n",
            "উইলস  : উইলস\n",
            "99.49392712550608 % completed\n",
            "উডেন  : উডেন\n",
            "99.54453441295547 % completed\n",
            "উরাটেন  : ওরেট্যান\n",
            "99.59514170040485 % completed\n",
            "জেল  : এক্সেল\n",
            "99.64574898785425 % completed\n",
            "ইমাগুছি  : যামাগুচি\n",
            "99.69635627530364 % completed\n",
            "ইয়েহিয়াম  : ইয়েহিয়াম\n",
            "99.74696356275304 % completed\n",
            "ইয়েনেঙ্গা  : যেনেনগা\n",
            "99.79757085020243 % completed\n",
            "যুগরাজ  : যোগরাজ\n",
            "99.84817813765183 % completed\n",
            "ইয়োকাডো  : যোকাদো\n",
            "99.89878542510121 % completed\n",
            "ইউসুফযুসুফ  : ইয়োসুফ\n",
            "99.9493927125506 % completed\n",
            "জুইকাকু  : জুইকাকু\n",
            "42.8\n",
            "92.1254011355221\n",
            "0.031770416149691116\n",
            "{'ড', '্', 'ত', 'খ', 'া', 'অ', 'ূ', 'ফ', 'ি', 'উ', 'স', 'ো', 'ঙ', 'হ', 'চ', 'ট', 'ব', 'র', 'জ', 'ঁ', 'ল', 'প', 'ে', 'গ', 'ভ', 'য়', 'ঘ', 'আ', 'ু', 'ক', 'ও', 'য', 'শ', 'ধ', 'দ', 'থ', 'এ', 'ণ', 'ঝ', 'ই', 'ন', 'ষ', 'ী'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGrjquLMV6Ny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @tf.function\n",
        "def predictAccuracyHi(mismatch_pair,strmismatch):\n",
        "  ip = \"\";\n",
        "  cnt = 0;\n",
        "  output = \"\";\n",
        "  trueVal = \"\";\n",
        "  cnt2char = 0;\n",
        "  totalcharcnt = 0;\n",
        "  avgmismatch = 0;\n",
        "  mismatchcnt = 0;\n",
        "  total_hindi_word = 0\n",
        "  l = (int)(len(input_tensor_val));\n",
        "  for i in range(0, l):\n",
        "    print(100*i/l, \"% completed\")\n",
        "    input_word = input_tensor_val[i];\n",
        "    target_word = target_tensor_val[i];\n",
        "    if(input_word[0] != char2idxEn[\"$\"]):\n",
        "      continue\n",
        "    total_hindi_word += 1\n",
        "    for r in input_word:\n",
        "      if(r == 0):\n",
        "        break\n",
        "      else: \n",
        "        ip += idx2charEn[r]\n",
        "    # print(\"hi\")\n",
        "    result = evaluate(ip)\n",
        "    \n",
        "    for k in result:\n",
        "      if (idx2charHi[k.numpy()] not in special_char_set):\n",
        "        output += idx2charHi[k.numpy()]\n",
        "    # print(output)\n",
        "    # print(\"hilo\")\n",
        "    # print(word)\n",
        "    for r in target_word:\n",
        "      if(idx2charHi[r] not in special_char_set):\n",
        "        trueVal += idx2charHi[r]\n",
        "    print(trueVal+\"  : \"+output);\n",
        "    # print(output)\n",
        "    if(len(output) == len(trueVal)):\n",
        "      wordlen = len(trueVal);\n",
        "      totalcharcnt += int(wordlen);\n",
        "      tempcnt = 0;\n",
        "      for k in range(0,int(wordlen)):\n",
        "        if(output[k] == trueVal[k]):\n",
        "          cnt2char +=  1;\n",
        "        else :\n",
        "          mismatch_pair.append({output[k], trueVal[k]});\n",
        "          strmismatch += output[k];\n",
        "          tempcnt += 1;\n",
        "          mismatchcnt += 1;\n",
        "      avgmismatch += (tempcnt/wordlen);\n",
        "    if(output==trueVal):\n",
        "      cnt = cnt+1; \n",
        "    ip = \"\"\n",
        "    output = \"\"\n",
        "    trueVal = \"\"\n",
        "    \n",
        "  print(100*cnt/(int(total_hindi_word)))\n",
        "  print(100*cnt2char/totalcharcnt);\n",
        "  print(avgmismatch/(l-cnt));\n",
        "  print(set(strmismatch));\n",
        "  return 100*cnt/(int(l)), 100*cnt2char/totalcharcnt, (avgmismatch/(l-cnt)), set(strmismatch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfxI8hKjWXp-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ff909028-f4d0-44ad-f655-7f1b7fc7911d"
      },
      "source": [
        "mismatch_pair1 = [];\n",
        "strmismatch1 = \"\";\n",
        "a1,b1,c1,d1 = predictAccuracyHi(mismatch_pair1,strmismatch1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 % completed\n",
            "आचार्यनंदना  : आचार्यनंदना\n",
            "0.05060728744939271 % completed\n",
            "आचार्यसुत  : आचार्यसुत\n",
            "0.10121457489878542 % completed\n",
            "आचार्यनंदन  : आचार्यनंदन\n",
            "0.15182186234817813 % completed\n",
            "आचार्यनंदना  : आचार्यनंदना\n",
            "0.20242914979757085 % completed\n",
            "आदमखोर  : आड़मखोर\n",
            "0.25303643724696356 % completed\n",
            "आग और शोला  : आग और शोला\n",
            "0.30364372469635625 % completed\n",
            "आज की बात  : आज की बात\n",
            "0.354251012145749 % completed\n",
            "आज की ताज़ा खबर  : आज की ताज़ा खबार\n",
            "0.4048582995951417 % completed\n",
            "आकांक्षा  : आकांक्षा\n",
            "0.45546558704453444 % completed\n",
            "आन  : आन\n",
            "0.5060728744939271 % completed\n",
            "आँखों देखी  : आँखों देखी\n",
            "0.5566801619433198 % completed\n",
            "आँसू बन गए फ़ूल  : आँसू बान गए फूल\n",
            "0.6072874493927125 % completed\n",
            "आशा  : आशा\n",
            "0.6578947368421053 % completed\n",
            "आतंक  : आतंक\n",
            "0.708502024291498 % completed\n",
            "अब क्या होगा  : अब क्या होगा\n",
            "0.7591093117408907 % completed\n",
            "अब्दुल हाकिम  : अब्दुल हकीम\n",
            "0.8097165991902834 % completed\n",
            "अब्दुल हन्नान  : अब्दुल हन्नान\n",
            "0.8603238866396761 % completed\n",
            "अब्दुल मुहासिन  : अब्दुल मुहसीन\n",
            "0.9109311740890689 % completed\n",
            "अब्दुल मुईज़  : अब्दुल मुईज़\n",
            "0.9615384615384616 % completed\n",
            "अब्दुल वकील  : अब्दुल वकील\n",
            "1.0121457489878543 % completed\n",
            "एबरडीन  : अबर्दीन\n",
            "1.062753036437247 % completed\n",
            "आभा  : अभा\n",
            "1.1133603238866396 % completed\n",
            "अभिमान  : अभिमन\n",
            "1.1639676113360324 % completed\n",
            "अभिनन्दा  : अभिनन्दा\n",
            "1.214574898785425 % completed\n",
            "एबीसो  : एबिसो\n",
            "1.2651821862348178 % completed\n",
            "अबू मंसूर दक़ीक़ी  : अबु मंसूर दक़ाकी\n",
            "1.3157894736842106 % completed\n",
            "अबुल फजल  : अबुल फज़ल\n",
            "1.3663967611336032 % completed\n",
            "आचार्यसुता  : अचार्यसुता\n",
            "1.417004048582996 % completed\n",
            "अछनेरा जंक्शन  : अचनेरा जंक्शन\n",
            "1.4676113360323886 % completed\n",
            "अचिंद्र  : अचिन्द्र\n",
            "1.5182186234817814 % completed\n",
            "अधिप  : अधिप\n",
            "1.5688259109311742 % completed\n",
            "अदित्याआदित्य  : अदित्य\n",
            "1.6194331983805668 % completed\n",
            "एडमिरैल्टी  : एडमिराल्टी\n",
            "1.6700404858299596 % completed\n",
            "अफसाना  : अफसाना\n",
            "1.7206477732793521 % completed\n",
            "अफसाना  : अफसाना\n",
            "1.771255060728745 % completed\n",
            "अगर तुम न होते  : अगर तुम न होटे\n",
            "1.8218623481781377 % completed\n",
            "एग्लेइया  : अग्लेया\n",
            "1.8724696356275303 % completed\n",
            "अग्नि चक्र  : अग्नि चक्र\n",
            "1.9230769230769231 % completed\n",
            "अग्रिमा  : अगरीमा\n",
            "1.9736842105263157 % completed\n",
            "अकल्मश  : अकलमाश\n",
            "2.0242914979757085 % completed\n",
            "आकर्षण  : अकर्षण\n",
            "2.074898785425101 % completed\n",
            "अकील  : अकील\n",
            "2.125506072874494 % completed\n",
            "अखिला  : अखिला\n",
            "2.1761133603238867 % completed\n",
            "अकीला डेल्ही  : अकिला डेली\n",
            "2.2267206477732793 % completed\n",
            "अकमाल  : अकमल\n",
            "2.277327935222672 % completed\n",
            "ऐलन वेल्स  : एलन वेल्स\n",
            "2.327935222672065 % completed\n",
            "एलेराइस  : एलेरिस\n",
            "2.3785425101214575 % completed\n",
            "अलास्का  : अलस्का\n",
            "2.42914979757085 % completed\n",
            "एल्बर्टसन्स  : अल्बर्टसन्स\n",
            "2.479757085020243 % completed\n",
            "अल्बोरान  : अल्बोरन\n",
            "2.5303643724696356 % completed\n",
            "अलेक्जेवियर  : अलेक्ज़ेवियर\n",
            "2.580971659919028 % completed\n",
            "अलीमा  : अलीमा\n",
            "2.6315789473684212 % completed\n",
            "अल्लेगहेन्ये  : एलेगेनी\n",
            "2.682186234817814 % completed\n",
            "ऑलस्टेट  : एल्स्टेट\n",
            "2.7327935222672064 % completed\n",
            "एली  : एली\n",
            "2.783400809716599 % completed\n",
            "अलोयसियस  : एलोयसियस\n",
            "2.834008097165992 % completed\n",
            "अलुयाबरी रोड  : अलुअबरी रोड\n",
            "2.8846153846153846 % completed\n",
            "एमेली  : एमाली\n",
            "2.935222672064777 % completed\n",
            "एमेरीलिस  : एमरीलिस\n",
            "2.98582995951417 % completed\n",
            "अंबाला  : अंबला\n",
            "3.0364372469635628 % completed\n",
            "अमीरी  : अमीरी\n",
            "3.0870445344129553 % completed\n",
            "आम्रपाली  : अमरापाली\n",
            "3.1376518218623484 % completed\n",
            "अमृत  : अमरीत\n",
            "3.188259109311741 % completed\n",
            "अनल  : अनल\n",
            "3.2388663967611335 % completed\n",
            "अंधा इंतेक़ाम  : अंधा इंतक्वाम\n",
            "3.289473684210526 % completed\n",
            "एंजेलिका  : एंगेलिका\n",
            "3.340080971659919 % completed\n",
            "अनिलात्मज  : अनिलत्मज\n",
            "3.3906882591093117 % completed\n",
            "अनिर्वाण  : अनिर्वाण\n",
            "3.4412955465587043 % completed\n",
            "अनीसा  : अनिसा\n",
            "3.4919028340080973 % completed\n",
            "अंजुम  : अंजुम\n",
            "3.54251012145749 % completed\n",
            "अन्नाबेला  : अन्नबेला\n",
            "3.5931174089068825 % completed\n",
            "अन्नपूर्णा  : अन्नपूर्णा\n",
            "3.6437246963562755 % completed\n",
            "एंथनी स्टुआर्ट  : एंथनी स्टर्ट\n",
            "3.694331983805668 % completed\n",
            "अनुपशहर  : अनुप्शहर\n",
            "3.7449392712550607 % completed\n",
            "अनुसूया  : अनुसूया\n",
            "3.7955465587044532 % completed\n",
            "अनुवा  : अनुवा\n",
            "3.8461538461538463 % completed\n",
            "अनवर  : अन्वर\n",
            "3.896761133603239 % completed\n",
            "अपना घर  : अपना घर\n",
            "3.9473684210526314 % completed\n",
            "अपने दम पर  : अपने दाम पर\n",
            "3.9979757085020244 % completed\n",
            "अपोलो टायर्स  : अपोलो टायर्स\n",
            "4.048582995951417 % completed\n",
            "आरा  : आरा\n",
            "4.09919028340081 % completed\n",
            "आर्बन  : अर्बॉन\n",
            "4.149797570850202 % completed\n",
            "आर्कन  : आर्कन\n",
            "4.200404858299595 % completed\n",
            "अर्घेश्वर  : अर्घेश्वर\n",
            "4.251012145748988 % completed\n",
            "अरिवलगन  : अरिवलगन\n",
            "4.301619433198381 % completed\n",
            "अर्नेठा  : अर्नेथा\n",
            "4.352226720647773 % completed\n",
            "एर्नी  : एर्नी\n",
            "4.402834008097166 % completed\n",
            "आर्टेमस  : अर्टेमस\n",
            "4.4534412955465585 % completed\n",
            "आर्य  : अर्या\n",
            "4.504048582995951 % completed\n",
            "असद  : असाद\n",
            "4.554655870445344 % completed\n",
            "आसही इंडिया  : अशाही इंडिया\n",
            "4.605263157894737 % completed\n",
            "असौती  : असौती\n",
            "4.65587044534413 % completed\n",
            "अशांथा डे मेल  : अशंथा डे मेल\n",
            "4.706477732793522 % completed\n",
            "अशिवन  : अशिवान\n",
            "4.757085020242915 % completed\n",
            "आसियाएशिया  : एसिया\n",
            "4.8076923076923075 % completed\n",
            "आसिफ मोहम्मद  : असिफ मोहम्मद\n",
            "4.8582995951417 % completed\n",
            "अस्लाना  : अस्लाना\n",
            "4.9089068825910935 % completed\n",
            "अटचाफल्या  : अत्चफलाय\n",
            "4.959514170040486 % completed\n",
            "आथर अली खान  : अथार अली खान\n",
            "5.010121457489879 % completed\n",
            "अथर्वन  : अथार्वान\n",
            "5.060728744939271 % completed\n",
            "अटैकर  : एटकर\n",
            "5.111336032388664 % completed\n",
            "अट्टूर  : अत्तूर\n",
            "5.161943319838056 % completed\n",
            "ऑरम  : ऑरम\n",
            "5.212550607287449 % completed\n",
            "अवनि  : एवनी\n",
            "5.2631578947368425 % completed\n",
            "अवनींद्र  : अवनिंद्र\n",
            "5.313765182186235 % completed\n",
            "अज़राकी  : अज़राकी\n",
            "5.364372469635628 % completed\n",
            "बाप बेटी  : बाप बेती\n",
            "5.41497975708502 % completed\n",
            "बाकिर  : बाकिर\n",
            "5.465587044534413 % completed\n",
            "बात एक रात की  : बाट एक रात के\n",
            "5.516194331983805 % completed\n",
            "बाबेल  : बाबल\n",
            "5.566801619433198 % completed\n",
            "बदर  : बदर\n",
            "5.617408906882591 % completed\n",
            "बद्रीप्रसाद  : बद्रीप्रसाद\n",
            "5.668016194331984 % completed\n",
            "बादशाहनगर  : बद्शाहनगर\n",
            "5.718623481781377 % completed\n",
            "बगावत  : बघावत\n",
            "5.769230769230769 % completed\n",
            "बहुरूप  : बहुरूप\n",
            "5.819838056680162 % completed\n",
            "बाजवा  : बजवा\n",
            "5.870445344129554 % completed\n",
            "बालक ध्रुव  : बालक ध्रुव\n",
            "5.921052631578948 % completed\n",
            "बालासोर  : बलासोर\n",
            "5.97165991902834 % completed\n",
            "बलिल  : बलिल\n",
            "6.022267206477733 % completed\n",
            "बल्कीस  : बालकीस\n",
            "6.0728744939271255 % completed\n",
            "बनजित  : बनजित\n",
            "6.123481781376518 % completed\n",
            "बन्फ़  : बनफ\n",
            "6.174089068825911 % completed\n",
            "बैंगई  : बंगुई\n",
            "6.224696356275303 % completed\n",
            "बाँके लाल  : बांके लाल\n",
            "6.275303643724697 % completed\n",
            "बंसी  : बंसी\n",
            "6.325910931174089 % completed\n",
            "बंसीलाल  : बंसिलाल\n",
            "6.376518218623482 % completed\n",
            "बरागांव  : बरागांव\n",
            "6.4271255060728745 % completed\n",
            "बरदोली  : बरदोली\n",
            "6.477732793522267 % completed\n",
            "बरेथ  : बरेथ\n",
            "6.52834008097166 % completed\n",
            "बरहान  : बरहान\n",
            "6.578947368421052 % completed\n",
            "बसित अली  : बसित अली\n",
            "6.629554655870446 % completed\n",
            "बतूल  : बतूल\n",
            "6.680161943319838 % completed\n",
            "बत्रा  : बत्रा\n",
            "6.730769230769231 % completed\n",
            "बयाना जंक्शन  : बयाना जंक्शन\n",
            "6.781376518218623 % completed\n",
            "बर्न  : बियर्न\n",
            "6.831983805668016 % completed\n",
            "बीस साल बाद  : बीस साल बाद\n",
            "6.882591093117409 % completed\n",
            "बहके कदम  : बहाके कदम\n",
            "6.933198380566802 % completed\n",
            "बेखबर  : बेखबर\n",
            "6.983805668016195 % completed\n",
            "बेलगॉम  : बेलगॉम\n",
            "7.034412955465587 % completed\n",
            "बरचा  : बेर्चा\n",
            "7.08502024291498 % completed\n",
            "बेटी  : बेती\n",
            "7.135627530364372 % completed\n",
            "भारतीय  : भारतीय\n",
            "7.186234817813765 % completed\n",
            "भचउ  : भच्छौ\n",
            "7.2368421052631575 % completed\n",
            "भडकमकर  : भडकमकर\n",
            "7.287449392712551 % completed\n",
            "भद्राचलम  : भद्रचलम\n",
            "7.338056680161944 % completed\n",
            "भाग्यवती  : भाग्यवती\n",
            "7.388663967611336 % completed\n",
            "भाई साहब  : भाई सहब\n",
            "7.439271255060729 % completed\n",
            "भामिनी  : भामिनी\n",
            "7.489878542510121 % completed\n",
            "भंडारदरा  : भंडर्दरा\n",
            "7.540485829959514 % completed\n",
            "भानुप्रसाद  : भानुप्रसाद\n",
            "7.5910931174089065 % completed\n",
            "भटपुर  : भटपुर\n",
            "7.6417004048583 % completed\n",
            "भेदी लुटेरा  : भेडी लुटेरा\n",
            "7.6923076923076925 % completed\n",
            "भेल  : भेल\n",
            "7.742914979757085 % completed\n",
            "भेरूलाल  : भेरूलाल\n",
            "7.793522267206478 % completed\n",
            "भिलाईनगर  : भिलाइनगर\n",
            "7.84412955465587 % completed\n",
            "भीलड़ी  : भिलदी\n",
            "7.894736842105263 % completed\n",
            "भोली  : भोली\n",
            "7.945344129554656 % completed\n",
            "भोंगीर  : भोंगीर\n",
            "7.995951417004049 % completed\n",
            "भूतनाथ  : भूटनाथ\n",
            "8.04655870445344 % completed\n",
            "भूधर  : भुधर\n",
            "8.097165991902834 % completed\n",
            "भूरण्यु  : भुरन्यु\n",
            "8.147773279352228 % completed\n",
            "बिछिया  : बिचिया\n",
            "8.19838056680162 % completed\n",
            "बिक्रम  : बिकराम\n",
            "8.248987854251013 % completed\n",
            "बिल्हौर  : बिलहॉर\n",
            "8.299595141700404 % completed\n",
            "बिस्ला  : बिस्ला\n",
            "8.350202429149798 % completed\n",
            "बिस्मार्क  : बिस्मार्क\n",
            "8.40080971659919 % completed\n",
            "ब्लूमबर्ग टॉवर  : ब्लूम्बर्ग टॉवर\n",
            "8.451417004048583 % completed\n",
            "ब्लू डार्ट  : ब्लू डार्ट\n",
            "8.502024291497976 % completed\n",
            "बॉम्बे मस्जिद  : बॉम्बे मैसजीड\n",
            "8.552631578947368 % completed\n",
            "बॉम्बे वार  : बॉम्बे वार\n",
            "8.603238866396762 % completed\n",
            "बॉन्गाईगांव  : बोंगाईगांव\n",
            "8.653846153846153 % completed\n",
            "बूट पॉलिश  : बूट पुलिश\n",
            "8.704453441295547 % completed\n",
            "बॉजमेन  : बोज़ेमन\n",
            "8.755060728744938 % completed\n",
            "ब्रेकन  : ब्रैकन\n",
            "8.805668016194332 % completed\n",
            "ब्राझोस्पोर्ट  : ब्राज़ोस्पोर्ट\n",
            "8.856275303643725 % completed\n",
            "ब्रेंडन ब्रेसवेल  : ब्रेंडन ब्रैसवेल\n",
            "8.906882591093117 % completed\n",
            "ब्रिटिश बुक अवार्ड्स  : ब्रिटिश बुक अवार्ड्स\n",
            "8.95748987854251 % completed\n",
            "ब्रूक्स  : ब्रूक्स\n",
            "9.008097165991902 % completed\n",
            "ब्रूस मेडल  : ब्रूस मेडल\n",
            "9.058704453441296 % completed\n",
            "बुदालुर  : बुदालुर\n",
            "9.109311740890687 % completed\n",
            "बनी हॉप  : बूनी हॉप\n",
            "9.15991902834008 % completed\n",
            "बरनेट  : बर्नेट\n",
            "9.210526315789474 % completed\n",
            "बॉरोज  : ब्यूरॉस\n",
            "9.261133603238866 % completed\n",
            "बुशरा  : बुश्र\n",
            "9.31174089068826 % completed\n",
            "कैडमियम  : कैडमियम\n",
            "9.362348178137651 % completed\n",
            "कैतिर  : कैटिर\n",
            "9.412955465587045 % completed\n",
            "कैला  : कैला\n",
            "9.463562753036438 % completed\n",
            "कैमिला  : कैमिला\n",
            "9.51417004048583 % completed\n",
            "केप कॉड  : केप कॉड\n",
            "9.564777327935223 % completed\n",
            "केप मैकलियर  : केप मैकलियर\n",
            "9.615384615384615 % completed\n",
            "कैराफ  : कैराफ\n",
            "9.665991902834008 % completed\n",
            "कार  : कैर\n",
            "9.7165991902834 % completed\n",
            "कार्सन  : कैरसन\n",
            "9.767206477732794 % completed\n",
            "कास्पियन  : कैस्पियन\n",
            "9.817813765182187 % completed\n",
            "कॅथे बेट्स  : कैथी बेट्स\n",
            "9.868421052631579 % completed\n",
            "कैस्किल  : कैट्स्किल\n",
            "9.919028340080972 % completed\n",
            "सेंटाइम्स  : सेंटीम्स\n",
            "9.969635627530364 % completed\n",
            "चाड  : चाड़\n",
            "10.020242914979757 % completed\n",
            "छाबड़ा  : चब्ब्रा\n",
            "10.070850202429149 % completed\n",
            "चाहा  : चाहा\n",
            "10.121457489878543 % completed\n",
            "चैनवा  : चैनवा\n",
            "10.172064777327936 % completed\n",
            "चक्रपाणि  : चक्रपणि\n",
            "10.222672064777328 % completed\n",
            "चाकसू  : चाक्सु\n",
            "10.273279352226721 % completed\n",
            "चमिंडा वास  : चमिंदा वास\n",
            "10.323886639676113 % completed\n",
            "कैमोमाइल  : कैमोमाइल\n",
            "10.374493927125506 % completed\n",
            "चंपका रामनायक  : चंपका रमनायके\n",
            "10.425101214574898 % completed\n",
            "चंदन का पालना  : चंदन का पलना\n",
            "10.475708502024291 % completed\n",
            "चंद्रगुप्त  : चंद्रगुप्त\n",
            "10.526315789473685 % completed\n",
            "चपरमुख जंक्शन  : चपर्मुख जंक्शन\n",
            "10.576923076923077 % completed\n",
            "चाफेकर  : चफेकर\n",
            "10.62753036437247 % completed\n",
            "चरिथा बुद्धिका  : चरिथा बुड़्धिका\n",
            "10.678137651821862 % completed\n",
            "चार्ल्स डार्विन  : चार्ल्स डार्विन\n",
            "10.728744939271255 % completed\n",
            "चारुशीला  : चैरुशीला\n",
            "10.779352226720647 % completed\n",
            "चेस्टर  : चेस्टर\n",
            "10.82995951417004 % completed\n",
            "चिचागॉफ़  : चिचागोफ\n",
            "10.880566801619434 % completed\n",
            "चिकमंगलूर  : चिकमैंगलर\n",
            "10.931174089068826 % completed\n",
            "चाइना फ़ाइनेंस ऑनलाइन  : चाइना फिनेंस ओनलाइन\n",
            "10.981781376518219 % completed\n",
            "चिन्ना  : चिन्ना\n",
            "11.03238866396761 % completed\n",
            "चिन्नार रिज़रवायर  : चाइन्नार रिज़रवायर\n",
            "11.082995951417004 % completed\n",
            "चितहरा  : चिताहरा\n",
            "11.133603238866396 % completed\n",
            "चोर चोर  : चोर चोर\n",
            "11.18421052631579 % completed\n",
            "कॉरडोफोन  : कॉरडोफोन\n",
            "11.234817813765183 % completed\n",
            "क्रिस्टी हैन्फ़र  : क्रिस्टी हेफनर\n",
            "11.285425101214575 % completed\n",
            "शुब  : चब्ब\n",
            "11.336032388663968 % completed\n",
            "क्लारा  : क्लेरा\n",
            "11.38663967611336 % completed\n",
            "क्लारेंस  : क्लेरेंस\n",
            "11.437246963562753 % completed\n",
            "क्लेलैंड  : क्लेलैंड\n",
            "11.487854251012147 % completed\n",
            "क्लेटा  : क्लेटा\n",
            "11.538461538461538 % completed\n",
            "कोबाल्ट  : कोबल्ट\n",
            "11.589068825910932 % completed\n",
            "कॉबॉर्न  : कोबोर्न\n",
            "11.639676113360323 % completed\n",
            "कॉलिस किंग  : कॉलिस किंग\n",
            "11.690283400809717 % completed\n",
            "कोलोरैडो केटल रिवर  : कोलोरॅडो केटल रिवर\n",
            "11.740890688259109 % completed\n",
            "कोलम्बिया  : कोलंबिया\n",
            "11.791497975708502 % completed\n",
            "कम्फर्ट  : कॉमफोर्ट\n",
            "11.842105263157896 % completed\n",
            "कॉम्पटन क्रूक अवार्ड  : कॉम्पटन क्रुक अवार्ड\n",
            "11.892712550607287 % completed\n",
            "कॉर्मेक  : कॉर्मैक\n",
            "11.94331983805668 % completed\n",
            "कॉस्को  : कोस्को\n",
            "11.993927125506072 % completed\n",
            "क्रेग ईवंस  : क्रेग इवैन्स\n",
            "12.044534412955466 % completed\n",
            "क्रैनफील्ड यूनिवर्सिटी  : क्रैनफिल्ड यूनिवर्सिटी\n",
            "12.095141700404858 % completed\n",
            "क्रेडिट सुसे  : क्रेड सससस\n",
            "12.145748987854251 % completed\n",
            "क्रिकेट  : क्रिकेट\n",
            "12.196356275303645 % completed\n",
            "क्रिकेटर  : क्रिकिटर\n",
            "12.246963562753036 % completed\n",
            "सायबिल  : सायबल\n",
            "12.29757085020243 % completed\n",
            "सायप्रस  : सायप्रस\n",
            "12.348178137651821 % completed\n",
            "दबोलिम  : डबोलिम\n",
            "12.398785425101215 % completed\n",
            "दैनिक जन्मभूमि  : दैनिक जनांभुमी\n",
            "12.449392712550607 % completed\n",
            "डाक बाबू  : डाक बाबू\n",
            "12.5 % completed\n",
            "डाकू और महात्मा  : डाकू और महात्मा\n",
            "12.550607287449393 % completed\n",
            "डाकू हसीना  : डाकू हासिना\n",
            "12.601214574898785 % completed\n",
            "डाकू रानी हिम्मतवाली  : डाकू रानी हिम्मतवाली\n",
            "12.651821862348179 % completed\n",
            "दलौदा  : दालौदा\n",
            "12.70242914979757 % completed\n",
            "डेलविले बैपटिस्ट  : डेलेविले बैपटिस्ट\n",
            "12.753036437246964 % completed\n",
            "दामाद  : दमाद\n",
            "12.803643724696355 % completed\n",
            "डंग  : डंग\n",
            "12.854251012145749 % completed\n",
            "दरबान  : डार्बन\n",
            "12.904858299595142 % completed\n",
            "डैरिन  : दरीन\n",
            "12.955465587044534 % completed\n",
            "डॉरेन गॉ  : डैरेन गगगॉ\n",
            "13.006072874493928 % completed\n",
            "डैरन सैम्मी  : डैरेन सैमी\n",
            "13.05668016194332 % completed\n",
            "डेरिन मुर्रे  : डैरिन मुर्रे\n",
            "13.107287449392713 % completed\n",
            "दरवाज़ा  : दर्वाज़ा\n",
            "13.157894736842104 % completed\n",
            "डैश  : दशा\n",
            "13.208502024291498 % completed\n",
            "डेविड टर्ब्रग  : डेविड टर्ब्रज\n",
            "13.259109311740891 % completed\n",
            "डी ज़ेवेन प्रोविंसियन  : डे ज़ीवन प्रॉविंशन\n",
            "13.309716599190283 % completed\n",
            "दीपाबाली  : दीपाबली\n",
            "13.360323886639677 % completed\n",
            "दीपमाला  : दीपमाला\n",
            "13.410931174089068 % completed\n",
            "देखा जाएगा  : देखा जयेगा\n",
            "13.461538461538462 % completed\n",
            "डेल्ही कैंनटॉनमेंट  : डेल्ही कैनटॉनमेंट\n",
            "13.512145748987853 % completed\n",
            "डेलोरेस  : डेलोर्स\n",
            "13.562753036437247 % completed\n",
            "डेमी मूर  : डेमी मूर\n",
            "13.61336032388664 % completed\n",
            "डेरिक  : डेरिक\n",
            "13.663967611336032 % completed\n",
            "देस परदेस  : डेस पार्डेस\n",
            "13.714574898785425 % completed\n",
            "देस्वाल  : देस्वल\n",
            "13.765182186234817 % completed\n",
            "डेस्वेल  : डेस्वेल\n",
            "13.81578947368421 % completed\n",
            "डूएल  : देउएल\n",
            "13.866396761133604 % completed\n",
            "देऊसकर  : ड्यूस्कर\n",
            "13.917004048582996 % completed\n",
            "देविंदरपाल  : डेविन्डरपाल\n",
            "13.96761133603239 % completed\n",
            "देवनारायण  : देवनारायण\n",
            "14.018218623481781 % completed\n",
            "देवप्रयाग  : देवप्रायाग\n",
            "14.068825910931174 % completed\n",
            "देवव्रत  : देवरत\n",
            "14.119433198380566 % completed\n",
            "धडवईवाले  : धडवएवाले\n",
            "14.17004048582996 % completed\n",
            "धाम  : धम\n",
            "14.220647773279353 % completed\n",
            "धमकी  : धमकी\n",
            "14.271255060728745 % completed\n",
            "धरम काँटा  : धरम कांता\n",
            "14.321862348178138 % completed\n",
            "धरम वीर  : धरम वीर\n",
            "14.37246963562753 % completed\n",
            "धरनगांव  : धरंगाँव\n",
            "14.423076923076923 % completed\n",
            "धोबी डॉक्टर  : ढ़ोबी डॉकटर\n",
            "14.473684210526315 % completed\n",
            "धृति  : धृति\n",
            "14.524291497975709 % completed\n",
            "धूम्र  : धुमर\n",
            "14.574898785425102 % completed\n",
            "धुम्रवर्ण  : धुमरावर्ण\n",
            "14.625506072874494 % completed\n",
            "डिएर्ड्रा  : डिएर्ड्रा\n",
            "14.676113360323887 % completed\n",
            "दीक्षा  : डिक्षा\n",
            "14.726720647773279 % completed\n",
            "दिलवरदिलावर  : दिलावार\n",
            "14.777327935222672 % completed\n",
            "दिलबर  : डिल्बर\n",
            "14.827935222672064 % completed\n",
            "डिंपल  : डिमप्ल\n",
            "14.878542510121457 % completed\n",
            "दीपा  : दीपा\n",
            "14.929149797570851 % completed\n",
            "दिश्मन  : दिश्मन\n",
            "14.979757085020243 % completed\n",
            "दो कैदी  : दो कैदी\n",
            "15.030364372469636 % completed\n",
            "डोबेलार  : डॉबलेयर\n",
            "15.080971659919028 % completed\n",
            "दोइवाला  : दोइवाला\n",
            "15.131578947368421 % completed\n",
            "डोमिनियन  : डोमिनियन\n",
            "15.182186234817813 % completed\n",
            "दोनघ  : डोनाग\n",
            "15.232793522267206 % completed\n",
            "डोएन  : दोयेन\n",
            "15.2834008097166 % completed\n",
            "दोज़ख  : डोज़ख\n",
            "15.334008097165992 % completed\n",
            "ड्रेक्सिस हेल्थ  : ड्रैक्सिस हेल्थ\n",
            "15.384615384615385 % completed\n",
            "दूधानी  : दुधानी\n",
            "15.435222672064777 % completed\n",
            "दूधिया खुर्द  : दुधिया खुर्द\n",
            "15.48582995951417 % completed\n",
            "डुदुक  : ड्यूडक\n",
            "15.536437246963562 % completed\n",
            "दुंदलोद  : डुंडलोड\n",
            "15.587044534412955 % completed\n",
            "दुश्मनी  : दुष्मणि\n",
            "15.637651821862349 % completed\n",
            "इदाक्क्ड़  : एडकड\n",
            "15.68825910931174 % completed\n",
            "इनाडू  : ईनादू\n",
            "15.738866396761134 % completed\n",
            "ईस्नर अवार्ड्स  : एस्नर अवार्ड्स\n",
            "15.789473684210526 % completed\n",
            "एक जान हैं हम  : एक जान है हम\n",
            "15.84008097165992 % completed\n",
            "एल्बुर्ज़  : एल्बर्ज़\n",
            "15.890688259109313 % completed\n",
            "इलेक्ट्रा  : इलेक्ट्रा\n",
            "15.941295546558704 % completed\n",
            "इलियास  : एलियास\n",
            "15.991902834008098 % completed\n",
            "एलिज़ाबेथ डोल  : एलिज़ाबेथ डॉल\n",
            "16.04251012145749 % completed\n",
            "इमर्सन  : एमरसन\n",
            "16.09311740890688 % completed\n",
            "एमिर  : एमिर\n",
            "16.143724696356276 % completed\n",
            "एण्डीवर  : एन्डियर\n",
            "16.194331983805668 % completed\n",
            "इओलैंड  : ईओलेन्डे\n",
            "16.24493927125506 % completed\n",
            "एथेल्डा  : एथेल्डा\n",
            "16.295546558704455 % completed\n",
            "इवेलिया  : इवेलिया\n",
            "16.346153846153847 % completed\n",
            "एक्सपोर्ट्स  : एक्सपोर्ट्स\n",
            "16.39676113360324 % completed\n",
            "फैदी  : फादी\n",
            "16.44736842105263 % completed\n",
            "फै़क  : फैक\n",
            "16.497975708502025 % completed\n",
            "फैज़ुलापुर  : फैज़उलपुर\n",
            "16.548582995951417 % completed\n",
            "फकीहाह  : फकीहाह\n",
            "16.59919028340081 % completed\n",
            "फ़ैमिली ऑफ गॉड  : फैमिली ऑफ गॉड\n",
            "16.649797570850204 % completed\n",
            "फार्लिंगटन रीडाउट  : फार्लिंग्टन रिडाउट\n",
            "16.700404858299596 % completed\n",
            "फौलाद  : फौलाद\n",
            "16.751012145748987 % completed\n",
            "फेडोरा  : फेडोरा\n",
            "16.80161943319838 % completed\n",
            "फ़िलीस श्चेल्फी  : फ़ेलिस शेल्फ\n",
            "16.852226720647774 % completed\n",
            "फर्डीनांड  : फर्डिनैंड\n",
            "16.902834008097166 % completed\n",
            "फेरोक  : फेरोक\n",
            "16.953441295546558 % completed\n",
            "फिफ्टी फिफ्टी  : फिफ़्टी फ़िफ्टी\n",
            "17.004048582995953 % completed\n",
            "फियोरेंज़ा  : फियोरेंज़ा\n",
            "17.054655870445345 % completed\n",
            "फ्लोरा  : फ्लोरा\n",
            "17.105263157894736 % completed\n",
            "फोर्ब्सगंज  : फ़ॉर्बसगंज\n",
            "17.155870445344128 % completed\n",
            "फोर्ट एसीनिबोइन  : फोर्ट ऐस्नीबॉइन\n",
            "17.206477732793523 % completed\n",
            "फोर्ट बेंघिसा  : फोर्ट बेंघिसा\n",
            "17.257085020242915 % completed\n",
            "फोर्ट बोकर  : फोर्ट बोकर\n",
            "17.307692307692307 % completed\n",
            "फोर्ट क्लार्क  : फोर्ट क्लार्क\n",
            "17.358299595141702 % completed\n",
            "फोर्ट कोलंबिया  : फोर्ट कम्बिया\n",
            "17.408906882591094 % completed\n",
            "फोर्ट डॉफिन  : फोर्ट डॉफिन\n",
            "17.459514170040485 % completed\n",
            "फोर्ट हॉन्सविज़्क  : फोर्ट हॉनस्विजक\n",
            "17.510121457489877 % completed\n",
            "फोर्ट मैनोएल  : फोर्ट मैनोएल\n",
            "17.560728744939272 % completed\n",
            "फोर्ट मार्लबोरॉ  : फोर्ट मार्ल्बोरो\n",
            "17.611336032388664 % completed\n",
            "फोर्ट स्मिथ  : फोर्ट स्मिथ\n",
            "17.661943319838056 % completed\n",
            "फोर्ट ट्रेगैन्टल  : फोर्ट ट्रेगैंटल\n",
            "17.71255060728745 % completed\n",
            "फोर्ट वेन  : फोर्ट वेने\n",
            "17.763157894736842 % completed\n",
            "फर्कटिंग जंक्शन  : फुर्कतिंग जंक्शन\n",
            "17.813765182186234 % completed\n",
            "फज़ेलाह  : फुसैलाह\n",
            "17.864372469635626 % completed\n",
            "गगरोली  : गागरोली\n",
            "17.91497975708502 % completed\n",
            "गेहमर  : गहमार\n",
            "17.965587044534413 % completed\n",
            "गजदंत  : गजदंत\n",
            "18.016194331983804 % completed\n",
            "गजानन  : गजनन\n",
            "18.0668016194332 % completed\n",
            "जेमिनी परेरा  : गैमिनी पेरा\n",
            "18.11740890688259 % completed\n",
            "गंडक  : गंडक\n",
            "18.168016194331983 % completed\n",
            "गणेश्वर  : गणेश्वर\n",
            "18.218623481781375 % completed\n",
            "गंगा  : गंगा\n",
            "18.26923076923077 % completed\n",
            "गैरेथ  : गैरेथ\n",
            "18.31983805668016 % completed\n",
            "गैरेथ हॉप्किंस  : गैरेथ हॉपकिंस\n",
            "18.370445344129553 % completed\n",
            "गर्नेट क्रुगर  : गार्नेट क्रजर\n",
            "18.42105263157895 % completed\n",
            "गॉलोइस  : गौलोइस\n",
            "18.47165991902834 % completed\n",
            "गौरीशंकर  : गौरएशंकर\n",
            "18.522267206477732 % completed\n",
            "गैवोट  : गैवॉट\n",
            "18.572874493927124 % completed\n",
            "जिऑफ बॉयकॉट  : जिऑफ बायकॉट\n",
            "18.62348178137652 % completed\n",
            "जॉर्ज बर्नार्ड शॉ  : जॉर्ज बर्नार्ड शॉ\n",
            "18.67408906882591 % completed\n",
            "जार्जियाना  : जॉर्जियना\n",
            "18.724696356275302 % completed\n",
            "जर्मन  : गर्मन\n",
            "18.775303643724698 % completed\n",
            "घर द्वार  : घार द्वार\n",
            "18.82591093117409 % completed\n",
            "घासो  : घासो\n",
            "18.87651821862348 % completed\n",
            "घातम  : घाटम\n",
            "18.927125506072876 % completed\n",
            "गौथ  : ग़ौथ\n",
            "18.977732793522268 % completed\n",
            "ग़ाज़ी  : गाज़ी\n",
            "19.02834008097166 % completed\n",
            "घोरपुरी  : घोर्पुरी\n",
            "19.07894736842105 % completed\n",
            "ग़ुफयराह  : ग़ुफैराह\n",
            "19.129554655870447 % completed\n",
            "जीनी  : गिन्नी\n",
            "19.18016194331984 % completed\n",
            "गिरिराज  : गिरिराज\n",
            "19.23076923076923 % completed\n",
            "गिर्ना  : गिर्ना\n",
            "19.281376518218625 % completed\n",
            "गिज़ी  : गिज़ी\n",
            "19.331983805668017 % completed\n",
            "गोवा  : गोआ\n",
            "19.38259109311741 % completed\n",
            "गोडल प्राइज़ अवार्ड  : गोडल प्राइज़ अवार्ड\n",
            "19.4331983805668 % completed\n",
            "गोमंतक टाइम्स  : गोमंटक टाइम्स\n",
            "19.483805668016196 % completed\n",
            "गोपिका  : गोपीका\n",
            "19.534412955465587 % completed\n",
            "गोविन्द  : गोविंद\n",
            "19.58502024291498 % completed\n",
            "गोविंदगढ़ माल्क  : गोविंदगढ़ मैक\n",
            "19.635627530364374 % completed\n",
            "ग्रीम पोर्टर  : ग्रेम पोर्टर\n",
            "19.686234817813766 % completed\n",
            "ग्रीम स्वान  : ग्रीम स्वन\n",
            "19.736842105263158 % completed\n",
            "ग्रेग मैथ्यूज  : ग्रेग मैट्ह्यूस\n",
            "19.78744939271255 % completed\n",
            "ग्रिडको  : ग्रिडको\n",
            "19.838056680161944 % completed\n",
            "ग्रिफिथ्स  : ग्रिफिथ्स\n",
            "19.888663967611336 % completed\n",
            "ग्रिम्स  : ग्रिम्ज़\n",
            "19.939271255060728 % completed\n",
            "ग्रिनहैम  : ग्रिनहैम\n",
            "19.989878542510123 % completed\n",
            "ग्रिसम  : ग्रिसॉम\n",
            "20.040485829959515 % completed\n",
            "ग्रिज़ली  : ग्रिज्जली\n",
            "20.091093117408906 % completed\n",
            "ग्रुप पिनॉल्ट प्रिंट  : ग्रुप पिनॉल्ट प्रिंट\n",
            "20.141700404858298 % completed\n",
            "गुडालुपे  : ग्युएडाल्यूप\n",
            "20.192307692307693 % completed\n",
            "गुआजिरा  : गुआजिरा\n",
            "20.242914979757085 % completed\n",
            "गुरानी  : गुआरानी\n",
            "20.293522267206477 % completed\n",
            "गुड्डी  : गुडडी\n",
            "20.344129554655872 % completed\n",
            "गुलधर  : गुलधार\n",
            "20.394736842105264 % completed\n",
            "गुणदरदेही  : गुंडरदेही\n",
            "20.445344129554655 % completed\n",
            "गुड़गाँवगुड़गांव  : गुरगांव\n",
            "20.495951417004047 % completed\n",
            "गुरुगुरू  : गुरु\n",
            "20.546558704453442 % completed\n",
            "गुरु दक्षिणा  : गुरू डाक्षिना\n",
            "20.597165991902834 % completed\n",
            "गुरू ग्रंथ साहिब  : गुरू ग्रांथ साहिब\n",
            "20.647773279352226 % completed\n",
            "गुरूद्वारा खंडूर साहिब  : गुरूद्वारा खंडूर साहिब\n",
            "20.69838056680162 % completed\n",
            "गुरूद्वारा लिखणसार  : गुरूद्वारा लिखंसर\n",
            "20.748987854251013 % completed\n",
            "गुरूद्वारा ठंडा बुर्ज  : गुरूद्वारा दन्दा बुर्ज\n",
            "20.799595141700404 % completed\n",
            "हफिज़ुर रहमान  : हफीज़र रहमान\n",
            "20.850202429149796 % completed\n",
            "हलाकांडी  : हैलकांदी\n",
            "20.90080971659919 % completed\n",
            "हजराह  : हजराह\n",
            "20.951417004048583 % completed\n",
            "हमीदहामिद  : हमीद\n",
            "21.002024291497975 % completed\n",
            "हैमीडीह  : हैमिदीह\n",
            "21.05263157894737 % completed\n",
            "हन्नाह  : हन्नाह\n",
            "21.10323886639676 % completed\n",
            "हनुमान  : हनुमान\n",
            "21.153846153846153 % completed\n",
            "हार्टफ़ोर्ड  : हार्टफोर्ड\n",
            "21.204453441295545 % completed\n",
            "हावर्ड यूनिवर्सिटी  : हार्वर्ड यूनिवर्सिटी\n",
            "21.25506072874494 % completed\n",
            "हार्वी  : हार्वी\n",
            "21.305668016194332 % completed\n",
            "हशीद  : हाशिद\n",
            "21.356275303643724 % completed\n",
            "हैट्स रशियन वार  : हैट्स रुशियन वार\n",
            "21.40688259109312 % completed\n",
            "हॉपैंगो  : हॉपैंगो\n",
            "21.45748987854251 % completed\n",
            "हव्वा  : हवव्वा\n",
            "21.508097165991902 % completed\n",
            "हीर रांझा  : हीर रंझा\n",
            "21.558704453441294 % completed\n",
            "हेमंग बदानी  : हेमंग बदनी\n",
            "21.60931174089069 % completed\n",
            "हेमचंद  : हेमचंद\n",
            "21.65991902834008 % completed\n",
            "हेनली  : हेनली\n",
            "21.710526315789473 % completed\n",
            "हीरा  : हेरा\n",
            "21.761133603238868 % completed\n",
            "हर्मीस  : हर्म्स\n",
            "21.81174089068826 % completed\n",
            "हार्से  : हरसेय\n",
            "21.86234817813765 % completed\n",
            "हाईलैंड्स  : हाईलैंड्स\n",
            "21.912955465587043 % completed\n",
            "हिमालय  : हिमालय\n",
            "21.963562753036438 % completed\n",
            "हिंदुस्तान लीवर  : हिंदुस्तान लीवर\n",
            "22.01417004048583 % completed\n",
            "हिसार  : हिसर\n",
            "22.06477732793522 % completed\n",
            "हॉक  : होचे\n",
            "22.115384615384617 % completed\n",
            "हॉलिस  : हॉलिस\n",
            "22.16599190283401 % completed\n",
            "हॉलीवुड वॉक ऑफ फेम  : हॉल्यवुड वैक ऑफ फेम\n",
            "22.2165991902834 % completed\n",
            "हुबायशाह  : हुबयशाह\n",
            "22.267206477732792 % completed\n",
            "हम सब उस्ताद हैं  : हम सुब उस्ताद हैं\n",
            "22.317813765182187 % completed\n",
            "हुमा  : हुमा\n",
            "22.36842105263158 % completed\n",
            "हुमायूँ  : हुमायून\n",
            "22.41902834008097 % completed\n",
            "हुज़ायल  : हुज़ैल\n",
            "22.469635627530366 % completed\n",
            "इआन रेडपाथ  : इआन रेडपाथ\n",
            "22.520242914979757 % completed\n",
            "आइडेमित्सु कोसान  : इडेमिट्सु कोसन\n",
            "22.57085020242915 % completed\n",
            "इखलास  : इखलास\n",
            "22.62145748987854 % completed\n",
            "इकी  : इकी\n",
            "22.672064777327936 % completed\n",
            "लियाम्ना  : इलियाम्ना\n",
            "22.722672064777328 % completed\n",
            "इंक्रेडिमेल  : इंक्रेडिमेल\n",
            "22.77327935222672 % completed\n",
            "इंदापुरकर  : इंडापुरकर\n",
            "22.823886639676115 % completed\n",
            "इन्दरदीप  : इन्दरदीप\n",
            "22.874493927125506 % completed\n",
            "इन्दुजा  : इन्दुजा\n",
            "22.925101214574898 % completed\n",
            "इन्दुकला  : इन्दुकाला\n",
            "22.975708502024293 % completed\n",
            "इंफ़ोटेक एन्टर  : इनफ़ॉटेक एन्टर\n",
            "23.026315789473685 % completed\n",
            "ईरान की एक रात  : इरान की एक रात\n",
            "23.076923076923077 % completed\n",
            "इतिहास  : इतिहास\n",
            "23.12753036437247 % completed\n",
            "इज़्ज़  : इज़्ज़\n",
            "23.178137651821864 % completed\n",
            "जैक हेरन  : जैक हेरॉन\n",
            "23.228744939271255 % completed\n",
            "जैकी  : जैक्वी\n",
            "23.279352226720647 % completed\n",
            "जगन्नाथ पुरी  : जगन्नाथ पुरी\n",
            "23.329959514170042 % completed\n",
            "जगदंबा  : जगदंबा\n",
            "23.380566801619434 % completed\n",
            "जहदमाह  : जहदामाह\n",
            "23.431174089068826 % completed\n",
            "जय  : जय\n",
            "23.481781376518217 % completed\n",
            "जैनिज़्म  : जैनिज\n",
            "23.532388663967613 % completed\n",
            "जयप्रकाश नारायण  : जयप्रकाश नारायण\n",
            "23.582995951417004 % completed\n",
            "जेम्स लॉफलिन अवार्ड  : जेम्स लाफलिन अवार्ड\n",
            "23.633603238866396 % completed\n",
            "जनक  : जैनक\n",
            "23.68421052631579 % completed\n",
            "जेनेट रीनो  : जेनेट रिनो\n",
            "23.734817813765183 % completed\n",
            "जावेद मियंदाद  : जवेड मिएंडडडाद\n",
            "23.785425101214575 % completed\n",
            "जय विजय  : जय विजय\n",
            "23.836032388663966 % completed\n",
            "जयसेकरा  : जयसेकरा\n",
            "23.88663967611336 % completed\n",
            "जीनी  : जिएन\n",
            "23.937246963562753 % completed\n",
            "जीवन नैया  : जीवन नैया\n",
            "23.987854251012145 % completed\n",
            "जीवन प्रभात  : जीवन प्रभत\n",
            "24.03846153846154 % completed\n",
            "जीवन रेखा  : जीवन रेखा\n",
            "24.089068825910932 % completed\n",
            "जेफ विल्सन  : जेफ विल्सन\n",
            "24.139676113360323 % completed\n",
            "जेमा  : जेमा\n",
            "24.190283400809715 % completed\n",
            "जिब्रान  : जिबरान\n",
            "24.24089068825911 % completed\n",
            "जिमी हैंड्रिक्स  : जिमी हेन्ड्रिक्स\n",
            "24.291497975708502 % completed\n",
            "जिमुता  : जिमुता\n",
            "24.342105263157894 % completed\n",
            "जिनेल  : जिनेले\n",
            "24.39271255060729 % completed\n",
            "जिवितेश  : जिवितेश\n",
            "24.44331983805668 % completed\n",
            "जोकस्ता  : जोकास्ता\n",
            "24.493927125506072 % completed\n",
            "जोगी  : जोगी\n",
            "24.544534412955464 % completed\n",
            "जोगराज  : जोगराज\n",
            "24.59514170040486 % completed\n",
            "जॉन एफ केनेडी  : जॉन फ कैनेडी\n",
            "24.64574898785425 % completed\n",
            "जॉन पेन  : जॉन पेन\n",
            "24.696356275303643 % completed\n",
            "जॉन केंट  : जॉन केंट\n",
            "24.746963562753038 % completed\n",
            "जोसि  : जोसी\n",
            "24.79757085020243 % completed\n",
            "जूदाइज़्म  : जुदैय्म\n",
            "24.84817813765182 % completed\n",
            "जंगल किंग  : जंगल किंग\n",
            "24.898785425101213 % completed\n",
            "जस्टिस चौधरी  : जस्टीस चौधार्य\n",
            "24.94939271255061 % completed\n",
            "ज्वालामुखी  : ज्वालामुखी\n",
            "25.0 % completed\n",
            "कामना  : कामना\n",
            "25.05060728744939 % completed\n",
            "कारण  : कारण\n",
            "25.101214574898787 % completed\n",
            "कच्ची कली  : कच्ची कली\n",
            "25.15182186234818 % completed\n",
            "केसिया  : कैसिया\n",
            "25.20242914979757 % completed\n",
            "कैलाश  : कैलाश\n",
            "25.253036437246962 % completed\n",
            "कैसे कहूँ  : कैसे कहूँ\n",
            "25.303643724696357 % completed\n",
            "कैलिया  : कालिया\n",
            "25.35425101214575 % completed\n",
            "कमलकमाल  : कमल\n",
            "25.40485829959514 % completed\n",
            "कामेश  : कमेश\n",
            "25.455465587044536 % completed\n",
            "कामयाब  : कामयाब\n",
            "25.506072874493928 % completed\n",
            "कनकप्रिया  : कनक्प्रिया\n",
            "25.55668016194332 % completed\n",
            "कंचन और गंगा  : कंचन और गंगा\n",
            "25.60728744939271 % completed\n",
            "कंवल  : कानवल\n",
            "25.657894736842106 % completed\n",
            "कैरिन  : करिन\n",
            "25.708502024291498 % completed\n",
            "कार्तिक  : कार्टिक\n",
            "25.75910931174089 % completed\n",
            "कैसिया  : कैसिया\n",
            "25.809716599190285 % completed\n",
            "कटक  : काटक\n",
            "25.860323886639677 % completed\n",
            "कत्तौरा  : कैटोरा\n",
            "25.910931174089068 % completed\n",
            "कैटी  : केटी\n",
            "25.96153846153846 % completed\n",
            "कौमुदी  : कौमुधि\n",
            "26.012145748987855 % completed\n",
            "कौस्तव  : कौस्ताव\n",
            "26.062753036437247 % completed\n",
            "कीन  : कीने\n",
            "26.11336032388664 % completed\n",
            "केनन  : केन्नन\n",
            "26.163967611336034 % completed\n",
            "केशिहन  : केशिहाँ\n",
            "26.214574898785425 % completed\n",
            "केविन डुअर्स  : केविन डर्स\n",
            "26.265182186234817 % completed\n",
            "खहेरा  : खहेरा\n",
            "26.31578947368421 % completed\n",
            "ख़ार्का  : खार्का\n",
            "26.366396761133604 % completed\n",
            "खातून  : खातून\n",
            "26.417004048582996 % completed\n",
            "खट्टड़ा  : खत्ता\n",
            "26.467611336032387 % completed\n",
            "खेल किस्मत का  : खेल किस्मत का\n",
            "26.518218623481783 % completed\n",
            "खोज  : खोज\n",
            "26.568825910931174 % completed\n",
            "खुद्दार  : ख़ुददार\n",
            "26.619433198380566 % completed\n",
            "खुफिया महल  : खुफिया महल\n",
            "26.670040485829958 % completed\n",
            "खुरायमाह  : खुरयमाह\n",
            "26.720647773279353 % completed\n",
            "ख्वाजा मीर दर्द  : ख्वाजा मीर दार्ड\n",
            "26.771255060728745 % completed\n",
            "किंतन  : किंतन\n",
            "26.821862348178136 % completed\n",
            "किरण्मय  : किरान्मय\n",
            "26.87246963562753 % completed\n",
            "किरिल  : किरिल\n",
            "26.923076923076923 % completed\n",
            "क्लामथ  : क्लमाथ\n",
            "26.973684210526315 % completed\n",
            "कोणार्क सूर्य  : कोनार्क सुर्य\n",
            "27.024291497975707 % completed\n",
            "कॉनिंग दर नीदरलैंडन  : कॉनिंग डर नेडरलैंडन\n",
            "27.074898785425102 % completed\n",
            "कोरी  : कोरी\n",
            "27.125506072874494 % completed\n",
            "क्रिस्टी  : क्रिस्टी\n",
            "27.176113360323885 % completed\n",
            "कुफ़्रा  : कुफरा\n",
            "27.22672064777328 % completed\n",
            "कुमारी  : कुमारी\n",
            "27.277327935222672 % completed\n",
            "कुंटे  : कुंते\n",
            "27.327935222672064 % completed\n",
            "कुंती  : कुंती\n",
            "27.37854251012146 % completed\n",
            "कुश  : कुश\n",
            "27.42914979757085 % completed\n",
            "कुसुमाधिराज  : कुसुमाधिराज\n",
            "27.479757085020243 % completed\n",
            "क्यूशू  : क्युषु\n",
            "27.530364372469634 % completed\n",
            "लालमणि  : लालमणि\n",
            "27.58097165991903 % completed\n",
            "लागू  : लागू\n",
            "27.63157894736842 % completed\n",
            "लाहौर फोर्ट  : लहरे फोर्ट\n",
            "27.682186234817813 % completed\n",
            "लक्ष्मीश्री  : लक्ष्मिश्री\n",
            "27.732793522267208 % completed\n",
            "लाल कुँवर  : लाल कुँवार\n",
            "27.7834008097166 % completed\n",
            "लाल पत्थर  : लाल पत्थर\n",
            "27.83400809716599 % completed\n",
            "ललाटिका  : लालतिका\n",
            "27.884615384615383 % completed\n",
            "ललन  : लैलन\n",
            "27.93522267206478 % completed\n",
            "लैन्स क्लूजनर  : लैन्स क्ल्यूसेनर\n",
            "27.98582995951417 % completed\n",
            "लैंडर  : लैंडलर\n",
            "28.036437246963562 % completed\n",
            "लैरीसा  : लैरिसा\n",
            "28.087044534412957 % completed\n",
            "लैटोना  : लतोना\n",
            "28.13765182186235 % completed\n",
            "लवाटे  : लावाते\n",
            "28.18825910931174 % completed\n",
            "लॉरेंस स्कूल  : लॉरेंस श्कूल\n",
            "28.238866396761132 % completed\n",
            "लय्याह  : लेयाह\n",
            "28.289473684210527 % completed\n",
            "लीट्रिक्स  : लीट्रिक्स\n",
            "28.34008097165992 % completed\n",
            "लेबनॉन  : लेबैनॉन\n",
            "28.39068825910931 % completed\n",
            "लीलाराम  : लीलाराम\n",
            "28.441295546558706 % completed\n",
            "लेम्ही  : लेमही\n",
            "28.491902834008098 % completed\n",
            "लिब्रेस  : लिबरेस\n",
            "28.54251012145749 % completed\n",
            "लाइट हाउस  : लाइट हाउस\n",
            "28.59311740890688 % completed\n",
            "लिलियाना  : लिलियाना\n",
            "28.643724696356276 % completed\n",
            "लिनाएव  : लिनेवे\n",
            "28.694331983805668 % completed\n",
            "लिंकन यूनिवर्सिटी  : लिंकॉल्न यूनिवर्सिटी\n",
            "28.74493927125506 % completed\n",
            "लायन  : लियोन\n",
            "28.795546558704455 % completed\n",
            "लिवरपूल कम्युनिटी  : लिवरपुल कम्युनिटी\n",
            "28.846153846153847 % completed\n",
            "लोकमत  : लोक्मत\n",
            "28.89676113360324 % completed\n",
            "लॉस मार्मोल्स  : लॉस मारमॉल्स\n",
            "28.94736842105263 % completed\n",
            "लॉथरिंगन  : लॉथरिंगन\n",
            "28.997975708502025 % completed\n",
            "लव इन शिमला  : लव इन सिमला\n",
            "29.048582995951417 % completed\n",
            "ल्यूसी  : ल्यूसिया\n",
            "29.09919028340081 % completed\n",
            "ल्युसिआनो  : ल्यूसियानो\n",
            "29.149797570850204 % completed\n",
            "लकी नंबर  : लक्की नंबर\n",
            "29.200404858299596 % completed\n",
            "लुकतुके  : लुक्टुके\n",
            "29.251012145748987 % completed\n",
            "माधवी  : माधवी\n",
            "29.30161943319838 % completed\n",
            "मैक्रॉनिक्स इंटरनेशनल  : मैक्रोनिक्स इंटरनेशनल\n",
            "29.352226720647774 % completed\n",
            "मदन मंजरी  : मदन मंजरी\n",
            "29.402834008097166 % completed\n",
            "मधु  : माधु\n",
            "29.453441295546558 % completed\n",
            "मादिवन  : मदिवान\n",
            "29.504048582995953 % completed\n",
            "मफिज़र रहमान  : मफीज़र रहमान\n",
            "29.554655870445345 % completed\n",
            "मघवाजित  : मघवाजित\n",
            "29.605263157894736 % completed\n",
            "महाश्वेता  : महाश्वेता\n",
            "29.655870445344128 % completed\n",
            "महावत  : महावत\n",
            "29.706477732793523 % completed\n",
            "महाबली हनुमान  : महाबली हनुमान\n",
            "29.757085020242915 % completed\n",
            "महाश्वेता  : महास्वेता\n",
            "29.807692307692307 % completed\n",
            "महिजुबा  : महिजुबा\n",
            "29.858299595141702 % completed\n",
            "महिरा  : महिरा\n",
            "29.908906882591094 % completed\n",
            "महिश  : महिश\n",
            "29.959514170040485 % completed\n",
            "महोत्साह  : महोत्साह\n",
            "30.010121457489877 % completed\n",
            "मैना  : मैना\n",
            "30.060728744939272 % completed\n",
            "मकायला  : मकायला\n",
            "30.111336032388664 % completed\n",
            "मालायला मनोरमा  : मलायला मनोरामा\n",
            "30.161943319838056 % completed\n",
            "मैल्पसेट डैम  : माल्पसेट डैम\n",
            "30.21255060728745 % completed\n",
            "मंगतराम  : मंगत्राम\n",
            "30.263157894736842 % completed\n",
            "मणिमुथर रिज़रवायर  : मणिमुथर रिज़रवायर\n",
            "30.313765182186234 % completed\n",
            "मणिराम  : मणिराम\n",
            "30.364372469635626 % completed\n",
            "मनीष  : मणिश\n",
            "30.41497975708502 % completed\n",
            "मन्मथ  : मन्मथा\n",
            "30.465587044534413 % completed\n",
            "मनुहार  : मनुहार\n",
            "30.516194331983804 % completed\n",
            "मंज़र  : मंज़र\n",
            "30.5668016194332 % completed\n",
            "मर मिटेंगे  : मार मिटेंजे\n",
            "30.61740890688259 % completed\n",
            "मरासी  : मरसि\n",
            "30.668016194331983 % completed\n",
            "मार्दव  : मर्दव\n",
            "30.718623481781375 % completed\n",
            "मेरीकोपा  : मैरिकोपा\n",
            "30.76923076923077 % completed\n",
            "मारीगाँव  : मरिगांव\n",
            "30.81983805668016 % completed\n",
            "मैरीगोल्ड  : मैरीगॉल्ड\n",
            "30.870445344129553 % completed\n",
            "मैरिसा  : मैरिसा\n",
            "30.92105263157895 % completed\n",
            "मार्टिन सूजी  : मार्टिन सूजी\n",
            "30.97165991902834 % completed\n",
            "मसाडा  : मसादा\n",
            "31.022267206477732 % completed\n",
            "मस्तानी  : मस्तानी\n",
            "31.072874493927124 % completed\n",
            "मतीनदास  : मतीनादास\n",
            "31.12348178137652 % completed\n",
            "मौरिलिओ  : मौरिलिओ\n",
            "31.17408906882591 % completed\n",
            "मावसिल  : मौसिल\n",
            "31.224696356275302 % completed\n",
            "मक्सिमा  : मक्ज़िमा\n",
            "31.275303643724698 % completed\n",
            "माज़दा मोटर  : मज़दा मोटर\n",
            "31.32591093117409 % completed\n",
            "मेदनीपुर  : मेद्नीपुर\n",
            "31.37651821862348 % completed\n",
            "मीरा श्याम  : मीरा श्याम\n",
            "31.427125506072876 % completed\n",
            "मीट वन ग्रीट वन  : मीट ओने ग्रीट ओने\n",
            "31.477732793522268 % completed\n",
            "मेहमान  : महमान\n",
            "31.52834008097166 % completed\n",
            "मेहरुन्निसा  : मेहरूनिसा\n",
            "31.57894736842105 % completed\n",
            "मैलोडियन  : मेलोडिऑनमेलोडियन\n",
            "31.629554655870447 % completed\n",
            "मेंगक्वांग डैम  : मेंगक्वांग डैम\n",
            "31.68016194331984 % completed\n",
            "मेरा मुक़द्दर  : मेरा मुकादर\n",
            "31.73076923076923 % completed\n",
            "मेरा सुहाग  : मेरा सुहग\n",
            "31.781376518218625 % completed\n",
            "मेरी आशा  : मेरी आशा\n",
            "31.831983805668017 % completed\n",
            "मेरु बेतिरी  : मेरू बेतिरी\n",
            "31.88259109311741 % completed\n",
            "मेसेटर्म  : मेसेटर्म\n",
            "31.9331983805668 % completed\n",
            "मेवन पाइरिस  : मिवन पीरिस\n",
            "31.983805668016196 % completed\n",
            "मिलन मीर  : मियान मिर\n",
            "32.034412955465584 % completed\n",
            "माइकल बेवन  : माइकल बेवन\n",
            "32.08502024291498 % completed\n",
            "माइक एथर्टन  : माइक एथर्टन\n",
            "32.135627530364374 % completed\n",
            "मिंजोनेट  : मिंजोनेट\n",
            "32.18623481781376 % completed\n",
            "मॉडर्न यूथ  : मॉडर्न यूथ\n",
            "32.23684210526316 % completed\n",
            "मॉनीटर  : मोनिटर\n",
            "32.28744939271255 % completed\n",
            "मोनरोविया  : मोनरोविया\n",
            "32.33805668016194 % completed\n",
            "मूकांबिका  : मूकांबिका\n",
            "32.388663967611336 % completed\n",
            "मोरग  : मोरग\n",
            "32.43927125506073 % completed\n",
            "माउंट आबू  : माउंट अबु\n",
            "32.48987854251012 % completed\n",
            "मृदुल  : मृदुल\n",
            "32.540485829959515 % completed\n",
            "मुदित  : मुदित\n",
            "32.59109311740891 % completed\n",
            "मुद्रा  : मुद्रा\n",
            "32.6417004048583 % completed\n",
            "मुहरिज़  : मुहरीज़\n",
            "32.69230769230769 % completed\n",
            "मुजद्दिद  : मुजाद्दीद\n",
            "32.74291497975708 % completed\n",
            "मुकादम  : मुकाडम\n",
            "32.79352226720648 % completed\n",
            "मुखतार  : मुखातार\n",
            "32.84412955465587 % completed\n",
            "मुकुलित  : मुकुलित\n",
            "32.89473684210526 % completed\n",
            "मुकुन्द  : मुकुंडा\n",
            "32.945344129554655 % completed\n",
            "मुकुट  : मुकुट\n",
            "32.99595141700405 % completed\n",
            "मुंसिफ डेल्ही  : म्युंसिफ डेली\n",
            "33.04655870445344 % completed\n",
            "मुकद्दर  : मुक़द्दर\n",
            "33.097165991902834 % completed\n",
            "मुक़्तसिद  : मुक़्तस्त\n",
            "33.14777327935223 % completed\n",
            "मुरारी  : मुरारी\n",
            "33.19838056680162 % completed\n",
            "मूर्ति  : मूर्ति\n",
            "33.24898785425101 % completed\n",
            "मुश्ताक अहमद  : मुश्तक़ अहमद\n",
            "33.29959514170041 % completed\n",
            "मुस्तफीद  : मुस्तफीद\n",
            "33.350202429149796 % completed\n",
            "नाटक  : नातक\n",
            "33.40080971659919 % completed\n",
            "नभन  : नभन\n",
            "33.45141700404859 % completed\n",
            "नाहान्नी  : नहन्नी\n",
            "33.502024291497975 % completed\n",
            "नाइ  : नई\n",
            "33.55263157894737 % completed\n",
            "नैमिश  : नैमिश\n",
            "33.60323886639676 % completed\n",
            "नैरित  : नैरित\n",
            "33.65384615384615 % completed\n",
            "नाजिया  : नजियाह\n",
            "33.70445344129555 % completed\n",
            "नंदा देवी  : नंदा देवी\n",
            "33.75506072874494 % completed\n",
            "नश्वा  : नश्वा\n",
            "33.80566801619433 % completed\n",
            "नाथन ब्रेकन  : नैथन ब्रैकन\n",
            "33.85627530364373 % completed\n",
            "नावेद अशरफ  : नवेद अश्रफ\n",
            "33.906882591093115 % completed\n",
            "नावेद लतीफ  : नवेड लतिफ\n",
            "33.95748987854251 % completed\n",
            "नय रास्ता  : नया रस्ता\n",
            "34.008097165991906 % completed\n",
            "नज़र का शिकार  : नज़र का शिकार\n",
            "34.058704453441294 % completed\n",
            "नीलाब्जा  : नीलबजा\n",
            "34.10931174089069 % completed\n",
            "नीलमणि  : नील्मणि\n",
            "34.159919028340084 % completed\n",
            "नीमच  : नीमुच\n",
            "34.21052631578947 % completed\n",
            "नीयोडिमियम  : नियोडिमियम\n",
            "34.26113360323887 % completed\n",
            "न्यूबेरी हॉनर  : न्यूबेरी होनर\n",
            "34.311740890688256 % completed\n",
            "नियामुर रशीद  : नियामुर रशीद\n",
            "34.36234817813765 % completed\n",
            "नाइससिस्टम्स लिमिटेड  : नाइसेस्टेम्स लिमिटेड\n",
            "34.412955465587046 % completed\n",
            "निकोलस पिरामल  : निकोलस पिरमा\n",
            "34.463562753036435 % completed\n",
            "निकुंजा  : निकुंजा\n",
            "34.51417004048583 % completed\n",
            "नीलाग्रीव  : निलाग्रिव\n",
            "34.564777327935225 % completed\n",
            "नीलिमा  : निलिमा\n",
            "34.61538461538461 % completed\n",
            "निनाद  : निनद\n",
            "34.66599190283401 % completed\n",
            "नीरज  : निरज\n",
            "34.716599190283404 % completed\n",
            "नित्यगोपाल  : नित्यागोपाल\n",
            "34.76720647773279 % completed\n",
            "नित्यानन्द  : नित्यनंद\n",
            "34.81781376518219 % completed\n",
            "नित्यसुन्दर  : नित्यसुन्दर\n",
            "34.86842105263158 % completed\n",
            "नोलेटा  : नोलिटा\n",
            "34.91902834008097 % completed\n",
            "नूपुर  : नूपुर\n",
            "34.969635627530366 % completed\n",
            "नूर जहाँ  : नूर जहाँ\n",
            "35.020242914979754 % completed\n",
            "नूरी  : नूरी\n",
            "35.07085020242915 % completed\n",
            "नूरजहाँ  : नूर्जहाँ\n",
            "35.121457489878544 % completed\n",
            "नॉरलैंड  : नोर्डलैंड\n",
            "35.17206477732793 % completed\n",
            "ओक्लाहोमा सिटी  : ओक्लाहोमा सिटी\n",
            "35.22267206477733 % completed\n",
            "ऑलीवर क्रॉमवेल  : ओलिवर क्रोमवेल\n",
            "35.27327935222672 % completed\n",
            "ओमर खैय्यम  : ओमर खइयाम\n",
            "35.32388663967611 % completed\n",
            "ओफिरा  : ऑफिरा\n",
            "35.374493927125506 % completed\n",
            "ऑर्बोटेक  : ऑर्बोटेक\n",
            "35.4251012145749 % completed\n",
            "ऑर्किड केमिकल्स  : ऑर्चिड कैमिकल\n",
            "35.47570850202429 % completed\n",
            "ऑडर ऑफ द क्राउन  : ऑडर ऑफ द क्राउन\n",
            "35.526315789473685 % completed\n",
            "ऑरिजिन्स अवार्ड  : ओरिजिन्स अवार्ड\n",
            "35.57692307692308 % completed\n",
            "ऑर्थोफ़िक्स  : ऑर्थोफिक्स\n",
            "35.62753036437247 % completed\n",
            "उस्मान  : ओस्मान\n",
            "35.678137651821864 % completed\n",
            "ओवा  : ओवा\n",
            "35.72874493927125 % completed\n",
            "पल्लब  : पल्लब\n",
            "35.77935222672065 % completed\n",
            "पनामा सिटी  : पनामा सिटी\n",
            "35.82995951417004 % completed\n",
            "पंचायत  : पंचायत\n",
            "35.88056680161943 % completed\n",
            "पंढरी  : पंधारी\n",
            "35.931174089068826 % completed\n",
            "पन्नागेश  : पन्नागेश\n",
            "35.98178137651822 % completed\n",
            "परिचय  : परिचय\n",
            "36.03238866396761 % completed\n",
            "पेरिस ऑरले  : पैरिस ऑर्ली\n",
            "36.082995951417004 % completed\n",
            "परिवर्तन  : परिवर्तन\n",
            "36.1336032388664 % completed\n",
            "पशुपति  : पशुपति\n",
            "36.18421052631579 % completed\n",
            "पैटर्सन थॉमप्सन  : पॅटरसन दॉपसन\n",
            "36.23481781376518 % completed\n",
            "पीस  : पीस\n",
            "36.28542510121458 % completed\n",
            "पेचीपराई  : पेचीपराई\n",
            "36.336032388663966 % completed\n",
            "पेडर स्क्रेम  : पीडर स्क्रम\n",
            "36.38663967611336 % completed\n",
            "पेंडसे  : पेंडसे\n",
            "36.43724696356275 % completed\n",
            "पेनगंगा  : पेंगंग\n",
            "36.487854251012145 % completed\n",
            "पेंशनर  : पेंशनर\n",
            "36.53846153846154 % completed\n",
            "पेट्रोब्रस  : प्रोब्रस\n",
            "36.58906882591093 % completed\n",
            "फडतरे  : फडातेरे\n",
            "36.63967611336032 % completed\n",
            "फागुन  : फगुन\n",
            "36.69028340080972 % completed\n",
            "फिल कार्लसन  : फिल कार्लसन\n",
            "36.74089068825911 % completed\n",
            "फिल डेफ्रेटास  : फिल डेफ्रेटास\n",
            "36.7914979757085 % completed\n",
            "फिल सिमंस  : फिल सिमॉन्स\n",
            "36.8421052631579 % completed\n",
            "फिलाडेल्फ़िया  : फिलेडेल्फिया\n",
            "36.892712550607285 % completed\n",
            "फिलिस  : फिलिस\n",
            "36.94331983805668 % completed\n",
            "फिजियोलॉजी  : फायसिओलॉजी\n",
            "36.993927125506076 % completed\n",
            "पिंक  : पिंक\n",
            "37.044534412955464 % completed\n",
            "पोली  : पोलाई\n",
            "37.09514170040486 % completed\n",
            "पूजित  : पूजित\n",
            "37.14574898785425 % completed\n",
            "पूनम की रात  : पूनम की रात\n",
            "37.19635627530364 % completed\n",
            "पावरफुल  : पॉवरफुल\n",
            "37.24696356275304 % completed\n",
            "प्रजापत  : प्रजापत\n",
            "37.297570850202426 % completed\n",
            "प्रार्थना  : प्ररणा\n",
            "37.34817813765182 % completed\n",
            "प्रसन्नजित  : प्रसंजित\n",
            "37.39878542510122 % completed\n",
            "प्रतिमा  : प्रतिमा\n",
            "37.449392712550605 % completed\n",
            "प्रवीण  : प्रवीन\n",
            "37.5 % completed\n",
            "प्रिटॉरियस  : प्रेटोरियस\n",
            "37.550607287449395 % completed\n",
            "प्रॉक्टर  : प्रोक्टर\n",
            "37.60121457489878 % completed\n",
            "प्रोमिथेउस  : प्रोमीथियस\n",
            "37.65182186234818 % completed\n",
            "प्रयॉर  : प्रयोर\n",
            "37.702429149797574 % completed\n",
            "पुनर्नवा  : पुणर्णवा\n",
            "37.75303643724696 % completed\n",
            "पुष्पराज  : पुष्पराज\n",
            "37.80364372469636 % completed\n",
            "प्यार का तूफान  : प्यार का तूफान\n",
            "37.85425101214575 % completed\n",
            "प्यास  : प्यास\n",
            "37.90485829959514 % completed\n",
            "कैदी  : कैदी\n",
            "37.955465587044536 % completed\n",
            "रागिनी  : रागिनी\n",
            "38.006072874493924 % completed\n",
            "राजमुनि  : राजमुनि\n",
            "38.05668016194332 % completed\n",
            "रासविहारी  : रासविहारी\n",
            "38.107287449392715 % completed\n",
            "राघवेंद्र  : राघवेन्द्र\n",
            "38.1578947368421 % completed\n",
            "रायचूर  : रायचुर\n",
            "38.2085020242915 % completed\n",
            "रेन कैल्सिंइंग  : रेन कैल्सिंग\n",
            "38.25910931174089 % completed\n",
            "राज नर्तकी  : राज नार्टकी\n",
            "38.30971659919028 % completed\n",
            "राजे  : राजे\n",
            "38.36032388663968 % completed\n",
            "राजेश्वर  : राजेश्वर\n",
            "38.41093117408907 % completed\n",
            "राम अवतार  : राम अवतार\n",
            "38.46153846153846 % completed\n",
            "रामबाण  : राम्बान\n",
            "38.512145748987855 % completed\n",
            "रम्भा  : रांभा\n",
            "38.56275303643725 % completed\n",
            "रामूवालिया  : रामुवालिया\n",
            "38.61336032388664 % completed\n",
            "रणजय  : रनजय\n",
            "38.663967611336034 % completed\n",
            "रैंस  : रेंस\n",
            "38.71457489878542 % completed\n",
            "रणधीर  : रंधीर\n",
            "38.76518218623482 % completed\n",
            "रसाल  : रसाल\n",
            "38.81578947368421 % completed\n",
            "रशीद  : रशीद\n",
            "38.8663967611336 % completed\n",
            "रसिका  : रसिका\n",
            "38.917004048582996 % completed\n",
            "रिपोर्टर राजू  : रिपोर्टर राजू\n",
            "38.96761133603239 % completed\n",
            "रिकज़विक  : रेकजाविक\n",
            "39.01821862348178 % completed\n",
            "रिचमंड  : रिचमॉन्ड\n",
            "39.068825910931174 % completed\n",
            "रिक  : रिक\n",
            "39.11943319838057 % completed\n",
            "रॉबिन उथाप्पा  : रॉबिन उथैपा\n",
            "39.17004048582996 % completed\n",
            "रोशेल  : रॉचेल\n",
            "39.22064777327935 % completed\n",
            "रोडन  : रॉडन\n",
            "39.27125506072875 % completed\n",
            "रॉलेंड बुचर  : रॉलैंड बचर\n",
            "39.321862348178136 % completed\n",
            "रोमांटिक इंडिया  : रोमैनटिक इंडिया\n",
            "39.37246963562753 % completed\n",
            "रोमेश कालुविथराणा  : रोमिश कलुइथहाराना\n",
            "39.42307692307692 % completed\n",
            "रोज़ीन  : रोज़िएन\n",
            "39.473684210526315 % completed\n",
            "रोशनी  : रोशनी\n",
            "39.52429149797571 % completed\n",
            "रुडी  : रुडी\n",
            "39.5748987854251 % completed\n",
            "रुपैया  : रुपैया\n",
            "39.625506072874494 % completed\n",
            "रसेल क्रोवी  : रशेल क्रोवी\n",
            "39.67611336032389 % completed\n",
            "सादात  : सादत\n",
            "39.72672064777328 % completed\n",
            "सच  : सच\n",
            "39.77732793522267 % completed\n",
            "सच्चे का बोलबाला  : सच्चे का बोल्बाला\n",
            "39.82793522267207 % completed\n",
            "सचिन तेंडुलकर  : सचिन तेन्दुलकर\n",
            "39.878542510121456 % completed\n",
            "सदीकाह  : सदीकाह\n",
            "39.92914979757085 % completed\n",
            "साहब  : साहब\n",
            "39.979757085020246 % completed\n",
            "सैलाब  : सैलाब\n",
            "40.030364372469634 % completed\n",
            "सैलेश  : साइलेश\n",
            "40.08097165991903 % completed\n",
            "सेंट हेलेन्स फोर्ट  : सेंट हेलेंस फोर्ट\n",
            "40.13157894736842 % completed\n",
            "सेंट मेरी  : सेंटे मैरी\n",
            "40.18218623481781 % completed\n",
            "साईप्रताप  : सईप्रताप\n",
            "40.23279352226721 % completed\n",
            "सजन  : सजन\n",
            "40.283400809716596 % completed\n",
            "सजीवा डे सिल्वा  : सजीवा डे सिल्वा\n",
            "40.33400809716599 % completed\n",
            "सजनी  : सजनी\n",
            "40.38461538461539 % completed\n",
            "सलिल अंकोला  : सलील एंकोला\n",
            "40.435222672064775 % completed\n",
            "समाज पतन  : समज पतन\n",
            "40.48582995951417 % completed\n",
            "संबद  : सम्बाद\n",
            "40.536437246963565 % completed\n",
            "समबरन  : संबरन\n",
            "40.587044534412954 % completed\n",
            "समरेंदु  : सम्रेंद्रु\n",
            "40.63765182186235 % completed\n",
            "सैन मार्टिनो  : सैन मार्टिनो\n",
            "40.688259109311744 % completed\n",
            "सन पेओलो मी  : सैन पाओलो इमी\n",
            "40.73886639676113 % completed\n",
            "संघेरा  : संघेरा\n",
            "40.78947368421053 % completed\n",
            "सेंटोज़  : संतोस\n",
            "40.840080971659916 % completed\n",
            "सरयू  : सरायु\n",
            "40.89068825910931 % completed\n",
            "सरीन  : सरीन\n",
            "40.941295546558706 % completed\n",
            "सरिस्का  : सैरिस्का\n",
            "40.991902834008094 % completed\n",
            "सैस्कैचवान  : सास्केटचवान\n",
            "41.04251012145749 % completed\n",
            "सती अंजनी  : सती अनजानी\n",
            "41.093117408906885 % completed\n",
            "सती नागकन्या  : सती नागकनया\n",
            "41.14372469635627 % completed\n",
            "सतनाम ओवरसीस  : सतनाम ओवर्सियास\n",
            "41.19433198380567 % completed\n",
            "सत्याकि  : सत्यकी\n",
            "41.24493927125506 % completed\n",
            "सौ साल बाद  : सौ साल बाद\n",
            "41.29554655870445 % completed\n",
            "सॉन्डर्स  : सेंडर्स\n",
            "41.34615384615385 % completed\n",
            "स्कॉटिया सी  : स्कोटिया सिया\n",
            "41.39676113360324 % completed\n",
            "सीमांत  : सीमांत\n",
            "41.44736842105263 % completed\n",
            "सेकरे  : सेकरे\n",
            "41.497975708502025 % completed\n",
            "सेलिया  : सेलिया\n",
            "41.54858299595141 % completed\n",
            "सेनेगल  : सेनेगल\n",
            "41.59919028340081 % completed\n",
            "सेरिंगापटम  : सेरीनगापतम\n",
            "41.649797570850204 % completed\n",
            "सेवाराम  : सेवाराम\n",
            "41.70040485829959 % completed\n",
            "शैतान  : शैतन\n",
            "41.75101214574899 % completed\n",
            "शेक हैंड्स  : शेक हैंड्स\n",
            "41.80161943319838 % completed\n",
            "शम्पा  : शम्पा\n",
            "41.85222672064777 % completed\n",
            "शमशीर ए अरब  : शमशीर एरब\n",
            "41.902834008097166 % completed\n",
            "शान  : शान\n",
            "41.95344129554656 % completed\n",
            "शंघाई म्युज़ियम  : शंघाई म्युज़ियम\n",
            "42.00404858299595 % completed\n",
            "शंपाक  : शंपाक\n",
            "42.054655870445345 % completed\n",
            "शारदिनी  : शरदिनी\n",
            "42.10526315789474 % completed\n",
            "शेरॉन स्टोन  : शैरॉन स्टोन\n",
            "42.15587044534413 % completed\n",
            "शत्रुघ्न  : शत्रुघन\n",
            "42.20647773279352 % completed\n",
            "शेरी  : शेरी\n",
            "42.25708502024292 % completed\n",
            "शिमेन मारू  : शिमाने मारू\n",
            "42.30769230769231 % completed\n",
            "शोएब खान  : शोएब अख्तर\n",
            "42.3582995951417 % completed\n",
            "शोएब  : शोएब\n",
            "42.40890688259109 % completed\n",
            "शॉटपुट  : शोतपुत\n",
            "42.459514170040485 % completed\n",
            "श्रेष्ठ  : श्रेष्ठ\n",
            "42.51012145748988 % completed\n",
            "श्रीदेवी  : श्रीदेवी\n",
            "42.56072874493927 % completed\n",
            "श्रीधर  : श्रीधर\n",
            "42.611336032388664 % completed\n",
            "श्रीपद  : श्रीपद\n",
            "42.66194331983806 % completed\n",
            "शुआ  : शुआ\n",
            "42.71255060728745 % completed\n",
            "शुभांग  : शुभांग\n",
            "42.76315789473684 % completed\n",
            "शुंगारे  : शंगेरे\n",
            "42.81376518218624 % completed\n",
            "शुरायह  : शुरायह\n",
            "42.864372469635626 % completed\n",
            "श्यामा  : श्यामा\n",
            "42.91497975708502 % completed\n",
            "सिहल्सी  : सिल्सी\n",
            "42.965587044534416 % completed\n",
            "सिल्वैन  : सिल्वेन\n",
            "43.016194331983804 % completed\n",
            "साइमन कैटिच  : साइमन केटीक\n",
            "43.0668016194332 % completed\n",
            "सिपहिया  : सिपहिया\n",
            "43.11740890688259 % completed\n",
            "सिराली  : सिराली\n",
            "43.16801619433198 % completed\n",
            "सिरन  : सिरान\n",
            "43.21862348178138 % completed\n",
            "सिउसन  : सिउसन\n",
            "43.26923076923077 % completed\n",
            "स्किपर  : स्किपर\n",
            "43.31983805668016 % completed\n",
            "स्लोमेन  : स्लाउमैन\n",
            "43.37044534412956 % completed\n",
            "स्नेहा  : स्नेहा\n",
            "43.421052631578945 % completed\n",
            "स्निग्धा  : स्निग्धा\n",
            "43.47165991902834 % completed\n",
            "सोहनी  : सोहणी\n",
            "43.522267206477736 % completed\n",
            "सोहनी  : सोहनी\n",
            "43.572874493927124 % completed\n",
            "सोल्फेरिनो  : सॉल्फेरीनो\n",
            "43.62348178137652 % completed\n",
            "सोम  : सोम\n",
            "43.674089068825914 % completed\n",
            "सोमकांता  : सोमकांता\n",
            "43.7246963562753 % completed\n",
            "साउदर्न आयरन  : साउदर्न आयरन\n",
            "43.7753036437247 % completed\n",
            "सोवानी  : सोवानी\n",
            "43.825910931174086 % completed\n",
            "स्पर्श  : स्पर्श\n",
            "43.87651821862348 % completed\n",
            "स्टीव मार्टिन  : स्टीव मार्टन\n",
            "43.927125506072876 % completed\n",
            "स्टीवन्स  : स्टीवेंस\n",
            "43.977732793522264 % completed\n",
            "स्ट्राइड आर्कोलैब  : स्ट्रिड आर्कोलैब\n",
            "44.02834008097166 % completed\n",
            "सुभाषचंद्र  : सुभाशचंद्र\n",
            "44.078947368421055 % completed\n",
            "सुचि  : सुचि\n",
            "44.12955465587044 % completed\n",
            "सुदर्शन  : सुदर्शन\n",
            "44.18016194331984 % completed\n",
            "सुहरेवर्दी  : सुहरएवार्डी\n",
            "44.23076923076923 % completed\n",
            "सुजया  : सुजया\n",
            "44.28137651821862 % completed\n",
            "सुखीजा  : सुखिजा\n",
            "44.33198380566802 % completed\n",
            "सुलेमानसुलैमान  : सुलैमान\n",
            "44.38259109311741 % completed\n",
            "सुल्तानाह  : सुल्तनाह\n",
            "44.4331983805668 % completed\n",
            "सन माइक्रोसिस्टम  : सन मिक्रोसिस्टम्स\n",
            "44.483805668016196 % completed\n",
            "सनऑप्टा  : सुनोप्ता\n",
            "44.534412955465584 % completed\n",
            "सर्जरी  : सर्जेरी\n",
            "44.58502024291498 % completed\n",
            "सुज़ेन सेरेन्डॉन  : सुसन सरन्दन\n",
            "44.635627530364374 % completed\n",
            "सूवो  : सुवो\n",
            "44.68623481781376 % completed\n",
            "स्वानस्वैन  : स्वैन\n",
            "44.73684210526316 % completed\n",
            "सय्यद अख्तर इमाम क़ादरी  : सय्यद अख्तर इमाम कादरी\n",
            "44.78744939271255 % completed\n",
            "सिंडीकेट बैंक  : सिन्डीकेट बैंक\n",
            "44.83805668016194 % completed\n",
            "तलक्कड  : तलक्कड़\n",
            "44.888663967611336 % completed\n",
            "तालिका  : टेलिका\n",
            "44.93927125506073 % completed\n",
            "तनुज  : तनुज\n",
            "44.98987854251012 % completed\n",
            "तनवीर  : तनविर\n",
            "45.040485829959515 % completed\n",
            "टारगेट  : तर्गेत\n",
            "45.09109311740891 % completed\n",
            "तारि़काह  : तरि़काह\n",
            "45.1417004048583 % completed\n",
            "तरुलता  : तरुलता\n",
            "45.19230769230769 % completed\n",
            "टैरिन  : टेरिन\n",
            "45.24291497975708 % completed\n",
            "टाटा टी  : टाटा टिया\n",
            "45.29352226720648 % completed\n",
            "टैज़वेल  : टैज़वेल\n",
            "45.34412955465587 % completed\n",
            "तेजा  : तेजा\n",
            "45.39473684210526 % completed\n",
            "तेजस्विनी  : तेजस्विनी\n",
            "45.445344129554655 % completed\n",
            "तेल अविव  : टेल एविव\n",
            "45.49595141700405 % completed\n",
            "तेरा करम मेरा धरम  : तेरा करम मेरा धरम\n",
            "45.54655870445344 % completed\n",
            "थार  : थार\n",
            "45.597165991902834 % completed\n",
            "द टाइम्स ऑफ इंडिया  : द टाइम्स ऑफ इंडिया\n",
            "45.64777327935223 % completed\n",
            "थरिंगन  : थ्यूरिंगन\n",
            "45.69838056680162 % completed\n",
            "थायरा  : थाइरा\n",
            "45.74898785425101 % completed\n",
            "तिलक  : टिलक\n",
            "45.79959514170041 % completed\n",
            "तिमिन  : टिमिन\n",
            "45.850202429149796 % completed\n",
            "तिरप  : तिरप\n",
            "45.90080971659919 % completed\n",
            "तोईयाबे  : टोइयाबे\n",
            "45.95141700404859 % completed\n",
            "टोनी  : टोनी\n",
            "46.002024291497975 % completed\n",
            "तूफान  : टूफन\n",
            "46.05263157894737 % completed\n",
            "टोरी  : टोरी\n",
            "46.10323886639676 % completed\n",
            "ट्रेसी  : ट्रेस\n",
            "46.15384615384615 % completed\n",
            "ट्रेवेलियन  : ट्रीवलियन\n",
            "46.20445344129555 % completed\n",
            "ट्रिनिटी बायोटेक  : ट्रिनिटी बायोटेक\n",
            "46.25506072874494 % completed\n",
            "ट्रूडा  : ट्रूडा\n",
            "46.30566801619433 % completed\n",
            "ट्रूली  : ट्रूली\n",
            "46.35627530364373 % completed\n",
            "ट्रम्प वर्ल्ड टॉवर  : ट्रमैंप वर्ल्ड टॉवर\n",
            "46.406882591093115 % completed\n",
            "ट्यूब इन्वेस्टमेंट  : ट्यूब इंवेस्टमेंट\n",
            "46.45748987854251 % completed\n",
            "तुंगभद्रा  : तुंगाभद्र\n",
            "46.508097165991906 % completed\n",
            "टू प्रुडेन्शियल प्लाज़ा  : ट्वो प्रुडेंटियल प्लाज़ा\n",
            "46.558704453441294 % completed\n",
            "उबेजा  : उबेजा\n",
            "46.60931174089069 % completed\n",
            "उमापति  : उमपति\n",
            "46.659919028340084 % completed\n",
            "उम्मय्याह  : उम्मय्याह\n",
            "46.71052631578947 % completed\n",
            "यूनिवर्सिटी ऑफ अलास्का  : यूनिवर्सिटी ऑफ एलैस्का\n",
            "46.76113360323887 % completed\n",
            "यूनिवर्सिटी ऑफ डंडी  : यूनिवर्सिटी ऑफ डंडंडे\n",
            "46.811740890688256 % completed\n",
            "यूनिवर्सिटी ऑफ हल  : यूनिवर्सिटी ऑफ हल\n",
            "46.86234817813765 % completed\n",
            "यूनिवर्सिटी ऑफ कीले  : यूनिवर्सिटी ऑफ कीले\n",
            "46.912955465587046 % completed\n",
            "यूरेनिया  : उरानिया\n",
            "46.963562753036435 % completed\n",
            "उर्सला  : उरसला\n",
            "47.01417004048583 % completed\n",
            "उत्तर कन्नड़  : उत्तर कन्नादा\n",
            "47.064777327935225 % completed\n",
            "वज्र  : वजरा\n",
            "47.11538461538461 % completed\n",
            "वैलेंटिनो  : वैलेन्टिनो\n",
            "47.16599190283401 % completed\n",
            "वल्ली  : वल्ली\n",
            "47.216599190283404 % completed\n",
            "वन  : वैन\n",
            "47.26720647773279 % completed\n",
            "वैनॉइस  : वैनोइस\n",
            "47.31781376518219 % completed\n",
            "वर्धा  : वर्धा\n",
            "47.36842105263158 % completed\n",
            "वेला  : वेला\n",
            "47.41902834008097 % completed\n",
            "वेंकटेश  : वेंकटेश\n",
            "47.469635627530366 % completed\n",
            "वेंकटेश्वर  : वेंकटेश्वर\n",
            "47.520242914979754 % completed\n",
            "वेओलिया एनवायरमेंट  : विया इन्विरोनमेंट\n",
            "47.57085020242915 % completed\n",
            "विद्युत  : विद्युत\n",
            "47.621457489878544 % completed\n",
            "विजयनगर  : विजयनगर\n",
            "47.67206477732793 % completed\n",
            "विमोहिनी  : विमोहिनी\n",
            "47.72267206477733 % completed\n",
            "विप्लाव  : विप्लाव\n",
            "47.77327935222672 % completed\n",
            "विरेश  : विरेश\n",
            "47.82388663967611 % completed\n",
            "विशालगढ़  : विशालगढ़\n",
            "47.874493927125506 % completed\n",
            "विश्राम  : विश्राम\n",
            "47.9251012145749 % completed\n",
            "विशिष्ट सेवा मेडल  : विसिष्ट सेवा मेडल\n",
            "47.97570850202429 % completed\n",
            "विक्टोरियो इमानुएल  : विटोरियो इमैन्यूएल\n",
            "48.026315789473685 % completed\n",
            "वृंदावनेश्वरी  : व्रणदावनेश्वरी\n",
            "48.07692307692308 % completed\n",
            "वायटिस  : वायटिस\n",
            "48.12753036437247 % completed\n",
            "वच्चर  : वछार\n",
            "48.178137651821864 % completed\n",
            "वैट  : वैटे\n",
            "48.22874493927125 % completed\n",
            "वॉकर म्युज़ियम  : वॉकर म्युज़ियम\n",
            "48.27935222672065 % completed\n",
            "वॉक्ले अवार्ड  : वॉकले अवार्ड\n",
            "48.32995951417004 % completed\n",
            "वॉल्ट डिज़्नी  : वॉल्ट डिस्ने\n",
            "48.38056680161943 % completed\n",
            "वार्नर  : वार्नर\n",
            "48.431174089068826 % completed\n",
            "वॉशिंगटनवॉशिंग्टन  : वॉशिंगटन\n",
            "48.48178137651822 % completed\n",
            "वतन के रखवाले  : वाटन के रखवाले\n",
            "48.53238866396761 % completed\n",
            "वज़ीरा  : वज़ीरा\n",
            "48.582995951417004 % completed\n",
            "वेडेल  : वेडेल\n",
            "48.6336032388664 % completed\n",
            "विलार्ड  : विला\n",
            "48.68421052631579 % completed\n",
            "वॉकहार्ड  : वॉकहार्ड\n",
            "48.73481781376518 % completed\n",
            "वुडवर्ड  : वुडवार्ड\n",
            "48.78542510121458 % completed\n",
            "य़कीन  : यकीन\n",
            "48.836032388663966 % completed\n",
            "य़ाकुब  : य़़ाक\n",
            "48.88663967611336 % completed\n",
            "यार  : यार\n",
            "48.93724696356275 % completed\n",
            "यासिर अराफत  : यसिर अरफत\n",
            "48.987854251012145 % completed\n",
            "येहैम फोर्ट  : यहियाम फोर्ट\n",
            "49.03846153846154 % completed\n",
            "योगराज  : योगराज\n",
            "49.08906882591093 % completed\n",
            "यूकॉन  : युकॉन\n",
            "49.13967611336032 % completed\n",
            "युवराज सिंह  : युवराज सिंह\n",
            "49.19028340080972 % completed\n",
            "ज़हूर इलाही  : ज़हर एलाही\n",
            "49.24089068825911 % completed\n",
            "ज़लील  : ज़लील\n",
            "49.2914979757085 % completed\n",
            "ज़ैब  : ज़ैब\n",
            "49.3421052631579 % completed\n",
            "ज़ोरियन  : ज़ोरियन\n",
            "49.392712550607285 % completed\n",
            "49.44331983805668 % completed\n",
            "49.493927125506076 % completed\n",
            "49.544534412955464 % completed\n",
            "49.59514170040486 % completed\n",
            "49.64574898785425 % completed\n",
            "49.69635627530364 % completed\n",
            "49.74696356275304 % completed\n",
            "49.797570850202426 % completed\n",
            "49.84817813765182 % completed\n",
            "49.89878542510122 % completed\n",
            "49.949392712550605 % completed\n",
            "50.0 % completed\n",
            "50.050607287449395 % completed\n",
            "50.10121457489878 % completed\n",
            "50.15182186234818 % completed\n",
            "50.202429149797574 % completed\n",
            "50.25303643724696 % completed\n",
            "50.30364372469636 % completed\n",
            "50.35425101214575 % completed\n",
            "50.40485829959514 % completed\n",
            "50.455465587044536 % completed\n",
            "50.506072874493924 % completed\n",
            "50.55668016194332 % completed\n",
            "50.607287449392715 % completed\n",
            "50.6578947368421 % completed\n",
            "50.7085020242915 % completed\n",
            "50.75910931174089 % completed\n",
            "50.80971659919028 % completed\n",
            "50.86032388663968 % completed\n",
            "50.91093117408907 % completed\n",
            "50.96153846153846 % completed\n",
            "51.012145748987855 % completed\n",
            "51.06275303643725 % completed\n",
            "51.11336032388664 % completed\n",
            "51.163967611336034 % completed\n",
            "51.21457489878542 % completed\n",
            "51.26518218623482 % completed\n",
            "51.31578947368421 % completed\n",
            "51.3663967611336 % completed\n",
            "51.417004048582996 % completed\n",
            "51.46761133603239 % completed\n",
            "51.51821862348178 % completed\n",
            "51.568825910931174 % completed\n",
            "51.61943319838057 % completed\n",
            "51.67004048582996 % completed\n",
            "51.72064777327935 % completed\n",
            "51.77125506072875 % completed\n",
            "51.821862348178136 % completed\n",
            "51.87246963562753 % completed\n",
            "51.92307692307692 % completed\n",
            "51.973684210526315 % completed\n",
            "52.02429149797571 % completed\n",
            "52.0748987854251 % completed\n",
            "52.125506072874494 % completed\n",
            "52.17611336032389 % completed\n",
            "52.22672064777328 % completed\n",
            "52.27732793522267 % completed\n",
            "52.32793522267207 % completed\n",
            "52.378542510121456 % completed\n",
            "52.42914979757085 % completed\n",
            "52.479757085020246 % completed\n",
            "52.530364372469634 % completed\n",
            "52.58097165991903 % completed\n",
            "52.63157894736842 % completed\n",
            "52.68218623481781 % completed\n",
            "52.73279352226721 % completed\n",
            "52.783400809716596 % completed\n",
            "52.83400809716599 % completed\n",
            "52.88461538461539 % completed\n",
            "52.935222672064775 % completed\n",
            "52.98582995951417 % completed\n",
            "53.036437246963565 % completed\n",
            "53.087044534412954 % completed\n",
            "53.13765182186235 % completed\n",
            "53.188259109311744 % completed\n",
            "53.23886639676113 % completed\n",
            "53.28947368421053 % completed\n",
            "53.340080971659916 % completed\n",
            "53.39068825910931 % completed\n",
            "53.441295546558706 % completed\n",
            "53.491902834008094 % completed\n",
            "53.54251012145749 % completed\n",
            "53.593117408906885 % completed\n",
            "53.64372469635627 % completed\n",
            "53.69433198380567 % completed\n",
            "53.74493927125506 % completed\n",
            "53.79554655870445 % completed\n",
            "53.84615384615385 % completed\n",
            "53.89676113360324 % completed\n",
            "53.94736842105263 % completed\n",
            "53.997975708502025 % completed\n",
            "54.04858299595141 % completed\n",
            "54.09919028340081 % completed\n",
            "54.149797570850204 % completed\n",
            "54.20040485829959 % completed\n",
            "54.25101214574899 % completed\n",
            "54.30161943319838 % completed\n",
            "54.35222672064777 % completed\n",
            "54.402834008097166 % completed\n",
            "54.45344129554656 % completed\n",
            "54.50404858299595 % completed\n",
            "54.554655870445345 % completed\n",
            "54.60526315789474 % completed\n",
            "54.65587044534413 % completed\n",
            "54.70647773279352 % completed\n",
            "54.75708502024292 % completed\n",
            "54.80769230769231 % completed\n",
            "54.8582995951417 % completed\n",
            "54.90890688259109 % completed\n",
            "54.959514170040485 % completed\n",
            "55.01012145748988 % completed\n",
            "55.06072874493927 % completed\n",
            "55.111336032388664 % completed\n",
            "55.16194331983806 % completed\n",
            "55.21255060728745 % completed\n",
            "55.26315789473684 % completed\n",
            "55.31376518218624 % completed\n",
            "55.364372469635626 % completed\n",
            "55.41497975708502 % completed\n",
            "55.465587044534416 % completed\n",
            "55.516194331983804 % completed\n",
            "55.5668016194332 % completed\n",
            "55.61740890688259 % completed\n",
            "55.66801619433198 % completed\n",
            "55.71862348178138 % completed\n",
            "55.76923076923077 % completed\n",
            "55.81983805668016 % completed\n",
            "55.87044534412956 % completed\n",
            "55.921052631578945 % completed\n",
            "55.97165991902834 % completed\n",
            "56.022267206477736 % completed\n",
            "56.072874493927124 % completed\n",
            "56.12348178137652 % completed\n",
            "56.174089068825914 % completed\n",
            "56.2246963562753 % completed\n",
            "56.2753036437247 % completed\n",
            "56.325910931174086 % completed\n",
            "56.37651821862348 % completed\n",
            "56.427125506072876 % completed\n",
            "56.477732793522264 % completed\n",
            "56.52834008097166 % completed\n",
            "56.578947368421055 % completed\n",
            "56.62955465587044 % completed\n",
            "56.68016194331984 % completed\n",
            "56.73076923076923 % completed\n",
            "56.78137651821862 % completed\n",
            "56.83198380566802 % completed\n",
            "56.88259109311741 % completed\n",
            "56.9331983805668 % completed\n",
            "56.983805668016196 % completed\n",
            "57.034412955465584 % completed\n",
            "57.08502024291498 % completed\n",
            "57.135627530364374 % completed\n",
            "57.18623481781376 % completed\n",
            "57.23684210526316 % completed\n",
            "57.28744939271255 % completed\n",
            "57.33805668016194 % completed\n",
            "57.388663967611336 % completed\n",
            "57.43927125506073 % completed\n",
            "57.48987854251012 % completed\n",
            "57.540485829959515 % completed\n",
            "57.59109311740891 % completed\n",
            "57.6417004048583 % completed\n",
            "57.69230769230769 % completed\n",
            "57.74291497975708 % completed\n",
            "57.79352226720648 % completed\n",
            "57.84412955465587 % completed\n",
            "57.89473684210526 % completed\n",
            "57.945344129554655 % completed\n",
            "57.99595141700405 % completed\n",
            "58.04655870445344 % completed\n",
            "58.097165991902834 % completed\n",
            "58.14777327935223 % completed\n",
            "58.19838056680162 % completed\n",
            "58.24898785425101 % completed\n",
            "58.29959514170041 % completed\n",
            "58.350202429149796 % completed\n",
            "58.40080971659919 % completed\n",
            "58.45141700404859 % completed\n",
            "58.502024291497975 % completed\n",
            "58.55263157894737 % completed\n",
            "58.60323886639676 % completed\n",
            "58.65384615384615 % completed\n",
            "58.70445344129555 % completed\n",
            "58.75506072874494 % completed\n",
            "58.80566801619433 % completed\n",
            "58.85627530364373 % completed\n",
            "58.906882591093115 % completed\n",
            "58.95748987854251 % completed\n",
            "59.008097165991906 % completed\n",
            "59.058704453441294 % completed\n",
            "59.10931174089069 % completed\n",
            "59.159919028340084 % completed\n",
            "59.21052631578947 % completed\n",
            "59.26113360323887 % completed\n",
            "59.311740890688256 % completed\n",
            "59.36234817813765 % completed\n",
            "59.412955465587046 % completed\n",
            "59.463562753036435 % completed\n",
            "59.51417004048583 % completed\n",
            "59.564777327935225 % completed\n",
            "59.61538461538461 % completed\n",
            "59.66599190283401 % completed\n",
            "59.716599190283404 % completed\n",
            "59.76720647773279 % completed\n",
            "59.81781376518219 % completed\n",
            "59.86842105263158 % completed\n",
            "59.91902834008097 % completed\n",
            "59.969635627530366 % completed\n",
            "60.020242914979754 % completed\n",
            "60.07085020242915 % completed\n",
            "60.121457489878544 % completed\n",
            "60.17206477732793 % completed\n",
            "60.22267206477733 % completed\n",
            "60.27327935222672 % completed\n",
            "60.32388663967611 % completed\n",
            "60.374493927125506 % completed\n",
            "60.4251012145749 % completed\n",
            "60.47570850202429 % completed\n",
            "60.526315789473685 % completed\n",
            "60.57692307692308 % completed\n",
            "60.62753036437247 % completed\n",
            "60.678137651821864 % completed\n",
            "60.72874493927125 % completed\n",
            "60.77935222672065 % completed\n",
            "60.82995951417004 % completed\n",
            "60.88056680161943 % completed\n",
            "60.931174089068826 % completed\n",
            "60.98178137651822 % completed\n",
            "61.03238866396761 % completed\n",
            "61.082995951417004 % completed\n",
            "61.1336032388664 % completed\n",
            "61.18421052631579 % completed\n",
            "61.23481781376518 % completed\n",
            "61.28542510121458 % completed\n",
            "61.336032388663966 % completed\n",
            "61.38663967611336 % completed\n",
            "61.43724696356275 % completed\n",
            "61.487854251012145 % completed\n",
            "61.53846153846154 % completed\n",
            "61.58906882591093 % completed\n",
            "61.63967611336032 % completed\n",
            "61.69028340080972 % completed\n",
            "61.74089068825911 % completed\n",
            "61.7914979757085 % completed\n",
            "61.8421052631579 % completed\n",
            "61.892712550607285 % completed\n",
            "61.94331983805668 % completed\n",
            "61.993927125506076 % completed\n",
            "62.044534412955464 % completed\n",
            "62.09514170040486 % completed\n",
            "62.14574898785425 % completed\n",
            "62.19635627530364 % completed\n",
            "62.24696356275304 % completed\n",
            "62.297570850202426 % completed\n",
            "62.34817813765182 % completed\n",
            "62.39878542510122 % completed\n",
            "62.449392712550605 % completed\n",
            "62.5 % completed\n",
            "62.550607287449395 % completed\n",
            "62.60121457489878 % completed\n",
            "62.65182186234818 % completed\n",
            "62.702429149797574 % completed\n",
            "62.75303643724696 % completed\n",
            "62.80364372469636 % completed\n",
            "62.85425101214575 % completed\n",
            "62.90485829959514 % completed\n",
            "62.955465587044536 % completed\n",
            "63.006072874493924 % completed\n",
            "63.05668016194332 % completed\n",
            "63.107287449392715 % completed\n",
            "63.1578947368421 % completed\n",
            "63.2085020242915 % completed\n",
            "63.25910931174089 % completed\n",
            "63.30971659919028 % completed\n",
            "63.36032388663968 % completed\n",
            "63.41093117408907 % completed\n",
            "63.46153846153846 % completed\n",
            "63.512145748987855 % completed\n",
            "63.56275303643725 % completed\n",
            "63.61336032388664 % completed\n",
            "63.663967611336034 % completed\n",
            "63.71457489878542 % completed\n",
            "63.76518218623482 % completed\n",
            "63.81578947368421 % completed\n",
            "63.8663967611336 % completed\n",
            "63.917004048582996 % completed\n",
            "63.96761133603239 % completed\n",
            "64.01821862348179 % completed\n",
            "64.06882591093117 % completed\n",
            "64.11943319838056 % completed\n",
            "64.17004048582996 % completed\n",
            "64.22064777327935 % completed\n",
            "64.27125506072875 % completed\n",
            "64.32186234817814 % completed\n",
            "64.37246963562752 % completed\n",
            "64.42307692307692 % completed\n",
            "64.47368421052632 % completed\n",
            "64.52429149797571 % completed\n",
            "64.5748987854251 % completed\n",
            "64.6255060728745 % completed\n",
            "64.67611336032388 % completed\n",
            "64.72672064777328 % completed\n",
            "64.77732793522267 % completed\n",
            "64.82793522267207 % completed\n",
            "64.87854251012146 % completed\n",
            "64.92914979757084 % completed\n",
            "64.97975708502024 % completed\n",
            "65.03036437246963 % completed\n",
            "65.08097165991903 % completed\n",
            "65.13157894736842 % completed\n",
            "65.18218623481782 % completed\n",
            "65.2327935222672 % completed\n",
            "65.2834008097166 % completed\n",
            "65.33400809716599 % completed\n",
            "65.38461538461539 % completed\n",
            "65.43522267206478 % completed\n",
            "65.48582995951416 % completed\n",
            "65.53643724696356 % completed\n",
            "65.58704453441295 % completed\n",
            "65.63765182186235 % completed\n",
            "65.68825910931174 % completed\n",
            "65.73886639676114 % completed\n",
            "65.78947368421052 % completed\n",
            "65.84008097165992 % completed\n",
            "65.89068825910931 % completed\n",
            "65.9412955465587 % completed\n",
            "65.9919028340081 % completed\n",
            "66.0425101214575 % completed\n",
            "66.09311740890688 % completed\n",
            "66.14372469635627 % completed\n",
            "66.19433198380567 % completed\n",
            "66.24493927125506 % completed\n",
            "66.29554655870446 % completed\n",
            "66.34615384615384 % completed\n",
            "66.39676113360323 % completed\n",
            "66.44736842105263 % completed\n",
            "66.49797570850203 % completed\n",
            "66.54858299595142 % completed\n",
            "66.59919028340082 % completed\n",
            "66.6497975708502 % completed\n",
            "66.70040485829959 % completed\n",
            "66.75101214574899 % completed\n",
            "66.80161943319838 % completed\n",
            "66.85222672064778 % completed\n",
            "66.90283400809717 % completed\n",
            "66.95344129554655 % completed\n",
            "67.00404858299595 % completed\n",
            "67.05465587044534 % completed\n",
            "67.10526315789474 % completed\n",
            "67.15587044534414 % completed\n",
            "67.20647773279352 % completed\n",
            "67.25708502024291 % completed\n",
            "67.3076923076923 % completed\n",
            "67.3582995951417 % completed\n",
            "67.4089068825911 % completed\n",
            "67.45951417004049 % completed\n",
            "67.51012145748987 % completed\n",
            "67.56072874493927 % completed\n",
            "67.61133603238866 % completed\n",
            "67.66194331983806 % completed\n",
            "67.71255060728745 % completed\n",
            "67.76315789473684 % completed\n",
            "67.81376518218623 % completed\n",
            "67.86437246963563 % completed\n",
            "67.91497975708502 % completed\n",
            "67.96558704453442 % completed\n",
            "68.01619433198381 % completed\n",
            "68.06680161943319 % completed\n",
            "68.11740890688259 % completed\n",
            "68.16801619433198 % completed\n",
            "68.21862348178138 % completed\n",
            "68.26923076923077 % completed\n",
            "68.31983805668017 % completed\n",
            "68.37044534412955 % completed\n",
            "68.42105263157895 % completed\n",
            "68.47165991902834 % completed\n",
            "68.52226720647774 % completed\n",
            "68.57287449392713 % completed\n",
            "68.62348178137651 % completed\n",
            "68.67408906882591 % completed\n",
            "68.7246963562753 % completed\n",
            "68.7753036437247 % completed\n",
            "68.82591093117409 % completed\n",
            "68.87651821862349 % completed\n",
            "68.92712550607287 % completed\n",
            "68.97773279352226 % completed\n",
            "69.02834008097166 % completed\n",
            "69.07894736842105 % completed\n",
            "69.12955465587045 % completed\n",
            "69.18016194331983 % completed\n",
            "69.23076923076923 % completed\n",
            "69.28137651821862 % completed\n",
            "69.33198380566802 % completed\n",
            "69.38259109311741 % completed\n",
            "69.43319838056681 % completed\n",
            "69.48380566801619 % completed\n",
            "69.53441295546558 % completed\n",
            "69.58502024291498 % completed\n",
            "69.63562753036437 % completed\n",
            "69.68623481781377 % completed\n",
            "69.73684210526316 % completed\n",
            "69.78744939271255 % completed\n",
            "69.83805668016194 % completed\n",
            "69.88866396761134 % completed\n",
            "69.93927125506073 % completed\n",
            "69.98987854251013 % completed\n",
            "70.04048582995951 % completed\n",
            "70.0910931174089 % completed\n",
            "70.1417004048583 % completed\n",
            "70.1923076923077 % completed\n",
            "70.24291497975709 % completed\n",
            "70.29352226720648 % completed\n",
            "70.34412955465586 % completed\n",
            "70.39473684210526 % completed\n",
            "70.44534412955466 % completed\n",
            "70.49595141700405 % completed\n",
            "70.54655870445345 % completed\n",
            "70.59716599190283 % completed\n",
            "70.64777327935222 % completed\n",
            "70.69838056680162 % completed\n",
            "70.74898785425101 % completed\n",
            "70.79959514170041 % completed\n",
            "70.8502024291498 % completed\n",
            "70.90080971659918 % completed\n",
            "70.95141700404858 % completed\n",
            "71.00202429149797 % completed\n",
            "71.05263157894737 % completed\n",
            "71.10323886639677 % completed\n",
            "71.15384615384616 % completed\n",
            "71.20445344129554 % completed\n",
            "71.25506072874494 % completed\n",
            "71.30566801619433 % completed\n",
            "71.35627530364373 % completed\n",
            "71.40688259109312 % completed\n",
            "71.4574898785425 % completed\n",
            "71.5080971659919 % completed\n",
            "71.5587044534413 % completed\n",
            "71.60931174089069 % completed\n",
            "71.65991902834008 % completed\n",
            "71.71052631578948 % completed\n",
            "71.76113360323886 % completed\n",
            "71.81174089068826 % completed\n",
            "71.86234817813765 % completed\n",
            "71.91295546558705 % completed\n",
            "71.96356275303644 % completed\n",
            "72.01417004048584 % completed\n",
            "72.06477732793522 % completed\n",
            "72.11538461538461 % completed\n",
            "72.16599190283401 % completed\n",
            "72.2165991902834 % completed\n",
            "72.2672064777328 % completed\n",
            "72.31781376518218 % completed\n",
            "72.36842105263158 % completed\n",
            "72.41902834008097 % completed\n",
            "72.46963562753037 % completed\n",
            "72.52024291497976 % completed\n",
            "72.57085020242916 % completed\n",
            "72.62145748987854 % completed\n",
            "72.67206477732793 % completed\n",
            "72.72267206477733 % completed\n",
            "72.77327935222672 % completed\n",
            "72.82388663967612 % completed\n",
            "72.8744939271255 % completed\n",
            "72.9251012145749 % completed\n",
            "72.97570850202429 % completed\n",
            "73.02631578947368 % completed\n",
            "73.07692307692308 % completed\n",
            "73.12753036437248 % completed\n",
            "73.17813765182186 % completed\n",
            "73.22874493927125 % completed\n",
            "73.27935222672065 % completed\n",
            "73.32995951417004 % completed\n",
            "73.38056680161944 % completed\n",
            "73.43117408906883 % completed\n",
            "73.48178137651821 % completed\n",
            "73.53238866396761 % completed\n",
            "73.582995951417 % completed\n",
            "73.6336032388664 % completed\n",
            "73.6842105263158 % completed\n",
            "73.73481781376518 % completed\n",
            "73.78542510121457 % completed\n",
            "73.83603238866397 % completed\n",
            "73.88663967611336 % completed\n",
            "73.93724696356276 % completed\n",
            "73.98785425101215 % completed\n",
            "74.03846153846153 % completed\n",
            "74.08906882591093 % completed\n",
            "74.13967611336032 % completed\n",
            "74.19028340080972 % completed\n",
            "74.24089068825911 % completed\n",
            "74.2914979757085 % completed\n",
            "74.34210526315789 % completed\n",
            "74.39271255060729 % completed\n",
            "74.44331983805668 % completed\n",
            "74.49392712550608 % completed\n",
            "74.54453441295547 % completed\n",
            "74.59514170040485 % completed\n",
            "74.64574898785425 % completed\n",
            "74.69635627530364 % completed\n",
            "74.74696356275304 % completed\n",
            "74.79757085020243 % completed\n",
            "74.84817813765183 % completed\n",
            "74.89878542510121 % completed\n",
            "74.9493927125506 % completed\n",
            "75.0 % completed\n",
            "75.0506072874494 % completed\n",
            "75.10121457489879 % completed\n",
            "75.15182186234817 % completed\n",
            "75.20242914979757 % completed\n",
            "75.25303643724696 % completed\n",
            "75.30364372469636 % completed\n",
            "75.35425101214575 % completed\n",
            "75.40485829959515 % completed\n",
            "75.45546558704453 % completed\n",
            "75.50607287449392 % completed\n",
            "75.55668016194332 % completed\n",
            "75.60728744939271 % completed\n",
            "75.65789473684211 % completed\n",
            "75.7085020242915 % completed\n",
            "75.75910931174089 % completed\n",
            "75.80971659919028 % completed\n",
            "75.86032388663968 % completed\n",
            "75.91093117408907 % completed\n",
            "75.96153846153847 % completed\n",
            "76.01214574898785 % completed\n",
            "76.06275303643724 % completed\n",
            "76.11336032388664 % completed\n",
            "76.16396761133603 % completed\n",
            "76.21457489878543 % completed\n",
            "76.26518218623482 % completed\n",
            "76.3157894736842 % completed\n",
            "76.3663967611336 % completed\n",
            "76.417004048583 % completed\n",
            "76.46761133603239 % completed\n",
            "76.51821862348179 % completed\n",
            "76.56882591093117 % completed\n",
            "76.61943319838056 % completed\n",
            "76.67004048582996 % completed\n",
            "76.72064777327935 % completed\n",
            "76.77125506072875 % completed\n",
            "76.82186234817814 % completed\n",
            "76.87246963562752 % completed\n",
            "76.92307692307692 % completed\n",
            "76.97368421052632 % completed\n",
            "77.02429149797571 % completed\n",
            "77.0748987854251 % completed\n",
            "77.1255060728745 % completed\n",
            "77.17611336032388 % completed\n",
            "77.22672064777328 % completed\n",
            "77.27732793522267 % completed\n",
            "77.32793522267207 % completed\n",
            "77.37854251012146 % completed\n",
            "77.42914979757084 % completed\n",
            "77.47975708502024 % completed\n",
            "77.53036437246963 % completed\n",
            "77.58097165991903 % completed\n",
            "77.63157894736842 % completed\n",
            "77.68218623481782 % completed\n",
            "77.7327935222672 % completed\n",
            "77.7834008097166 % completed\n",
            "77.83400809716599 % completed\n",
            "77.88461538461539 % completed\n",
            "77.93522267206478 % completed\n",
            "77.98582995951416 % completed\n",
            "78.03643724696356 % completed\n",
            "78.08704453441295 % completed\n",
            "78.13765182186235 % completed\n",
            "78.18825910931174 % completed\n",
            "78.23886639676114 % completed\n",
            "78.28947368421052 % completed\n",
            "78.34008097165992 % completed\n",
            "78.39068825910931 % completed\n",
            "78.4412955465587 % completed\n",
            "78.4919028340081 % completed\n",
            "78.5425101214575 % completed\n",
            "78.59311740890688 % completed\n",
            "78.64372469635627 % completed\n",
            "78.69433198380567 % completed\n",
            "78.74493927125506 % completed\n",
            "78.79554655870446 % completed\n",
            "78.84615384615384 % completed\n",
            "78.89676113360323 % completed\n",
            "78.94736842105263 % completed\n",
            "78.99797570850203 % completed\n",
            "79.04858299595142 % completed\n",
            "79.09919028340082 % completed\n",
            "79.1497975708502 % completed\n",
            "79.20040485829959 % completed\n",
            "79.25101214574899 % completed\n",
            "79.30161943319838 % completed\n",
            "79.35222672064778 % completed\n",
            "79.40283400809717 % completed\n",
            "79.45344129554655 % completed\n",
            "79.50404858299595 % completed\n",
            "79.55465587044534 % completed\n",
            "79.60526315789474 % completed\n",
            "79.65587044534414 % completed\n",
            "79.70647773279352 % completed\n",
            "79.75708502024291 % completed\n",
            "79.8076923076923 % completed\n",
            "79.8582995951417 % completed\n",
            "79.9089068825911 % completed\n",
            "79.95951417004049 % completed\n",
            "80.01012145748987 % completed\n",
            "80.06072874493927 % completed\n",
            "80.11133603238866 % completed\n",
            "80.16194331983806 % completed\n",
            "80.21255060728745 % completed\n",
            "80.26315789473684 % completed\n",
            "80.31376518218623 % completed\n",
            "80.36437246963563 % completed\n",
            "80.41497975708502 % completed\n",
            "80.46558704453442 % completed\n",
            "80.51619433198381 % completed\n",
            "80.56680161943319 % completed\n",
            "80.61740890688259 % completed\n",
            "80.66801619433198 % completed\n",
            "80.71862348178138 % completed\n",
            "80.76923076923077 % completed\n",
            "80.81983805668017 % completed\n",
            "80.87044534412955 % completed\n",
            "80.92105263157895 % completed\n",
            "80.97165991902834 % completed\n",
            "81.02226720647774 % completed\n",
            "81.07287449392713 % completed\n",
            "81.12348178137651 % completed\n",
            "81.17408906882591 % completed\n",
            "81.2246963562753 % completed\n",
            "81.2753036437247 % completed\n",
            "81.32591093117409 % completed\n",
            "81.37651821862349 % completed\n",
            "81.42712550607287 % completed\n",
            "81.47773279352226 % completed\n",
            "81.52834008097166 % completed\n",
            "81.57894736842105 % completed\n",
            "81.62955465587045 % completed\n",
            "81.68016194331983 % completed\n",
            "81.73076923076923 % completed\n",
            "81.78137651821862 % completed\n",
            "81.83198380566802 % completed\n",
            "81.88259109311741 % completed\n",
            "81.93319838056681 % completed\n",
            "81.98380566801619 % completed\n",
            "82.03441295546558 % completed\n",
            "82.08502024291498 % completed\n",
            "82.13562753036437 % completed\n",
            "82.18623481781377 % completed\n",
            "82.23684210526316 % completed\n",
            "82.28744939271255 % completed\n",
            "82.33805668016194 % completed\n",
            "82.38866396761134 % completed\n",
            "82.43927125506073 % completed\n",
            "82.48987854251013 % completed\n",
            "82.54048582995951 % completed\n",
            "82.5910931174089 % completed\n",
            "82.6417004048583 % completed\n",
            "82.6923076923077 % completed\n",
            "82.74291497975709 % completed\n",
            "82.79352226720648 % completed\n",
            "82.84412955465586 % completed\n",
            "82.89473684210526 % completed\n",
            "82.94534412955466 % completed\n",
            "82.99595141700405 % completed\n",
            "83.04655870445345 % completed\n",
            "83.09716599190283 % completed\n",
            "83.14777327935222 % completed\n",
            "83.19838056680162 % completed\n",
            "83.24898785425101 % completed\n",
            "83.29959514170041 % completed\n",
            "83.3502024291498 % completed\n",
            "83.40080971659918 % completed\n",
            "83.45141700404858 % completed\n",
            "83.50202429149797 % completed\n",
            "83.55263157894737 % completed\n",
            "83.60323886639677 % completed\n",
            "83.65384615384616 % completed\n",
            "83.70445344129554 % completed\n",
            "83.75506072874494 % completed\n",
            "83.80566801619433 % completed\n",
            "83.85627530364373 % completed\n",
            "83.90688259109312 % completed\n",
            "83.9574898785425 % completed\n",
            "84.0080971659919 % completed\n",
            "84.0587044534413 % completed\n",
            "84.10931174089069 % completed\n",
            "84.15991902834008 % completed\n",
            "84.21052631578948 % completed\n",
            "84.26113360323886 % completed\n",
            "84.31174089068826 % completed\n",
            "84.36234817813765 % completed\n",
            "84.41295546558705 % completed\n",
            "84.46356275303644 % completed\n",
            "84.51417004048584 % completed\n",
            "84.56477732793522 % completed\n",
            "84.61538461538461 % completed\n",
            "84.66599190283401 % completed\n",
            "84.7165991902834 % completed\n",
            "84.7672064777328 % completed\n",
            "84.81781376518218 % completed\n",
            "84.86842105263158 % completed\n",
            "84.91902834008097 % completed\n",
            "84.96963562753037 % completed\n",
            "85.02024291497976 % completed\n",
            "85.07085020242916 % completed\n",
            "85.12145748987854 % completed\n",
            "85.17206477732793 % completed\n",
            "85.22267206477733 % completed\n",
            "85.27327935222672 % completed\n",
            "85.32388663967612 % completed\n",
            "85.3744939271255 % completed\n",
            "85.4251012145749 % completed\n",
            "85.47570850202429 % completed\n",
            "85.52631578947368 % completed\n",
            "85.57692307692308 % completed\n",
            "85.62753036437248 % completed\n",
            "85.67813765182186 % completed\n",
            "85.72874493927125 % completed\n",
            "85.77935222672065 % completed\n",
            "85.82995951417004 % completed\n",
            "85.88056680161944 % completed\n",
            "85.93117408906883 % completed\n",
            "85.98178137651821 % completed\n",
            "86.03238866396761 % completed\n",
            "86.082995951417 % completed\n",
            "86.1336032388664 % completed\n",
            "86.1842105263158 % completed\n",
            "86.23481781376518 % completed\n",
            "86.28542510121457 % completed\n",
            "86.33603238866397 % completed\n",
            "86.38663967611336 % completed\n",
            "86.43724696356276 % completed\n",
            "86.48785425101215 % completed\n",
            "86.53846153846153 % completed\n",
            "86.58906882591093 % completed\n",
            "86.63967611336032 % completed\n",
            "86.69028340080972 % completed\n",
            "86.74089068825911 % completed\n",
            "86.7914979757085 % completed\n",
            "86.84210526315789 % completed\n",
            "86.89271255060729 % completed\n",
            "86.94331983805668 % completed\n",
            "86.99392712550608 % completed\n",
            "87.04453441295547 % completed\n",
            "87.09514170040485 % completed\n",
            "87.14574898785425 % completed\n",
            "87.19635627530364 % completed\n",
            "87.24696356275304 % completed\n",
            "87.29757085020243 % completed\n",
            "87.34817813765183 % completed\n",
            "87.39878542510121 % completed\n",
            "87.4493927125506 % completed\n",
            "87.5 % completed\n",
            "87.5506072874494 % completed\n",
            "87.60121457489879 % completed\n",
            "87.65182186234817 % completed\n",
            "87.70242914979757 % completed\n",
            "87.75303643724696 % completed\n",
            "87.80364372469636 % completed\n",
            "87.85425101214575 % completed\n",
            "87.90485829959515 % completed\n",
            "87.95546558704453 % completed\n",
            "88.00607287449392 % completed\n",
            "88.05668016194332 % completed\n",
            "88.10728744939271 % completed\n",
            "88.15789473684211 % completed\n",
            "88.2085020242915 % completed\n",
            "88.25910931174089 % completed\n",
            "88.30971659919028 % completed\n",
            "88.36032388663968 % completed\n",
            "88.41093117408907 % completed\n",
            "88.46153846153847 % completed\n",
            "88.51214574898785 % completed\n",
            "88.56275303643724 % completed\n",
            "88.61336032388664 % completed\n",
            "88.66396761133603 % completed\n",
            "88.71457489878543 % completed\n",
            "88.76518218623482 % completed\n",
            "88.8157894736842 % completed\n",
            "88.8663967611336 % completed\n",
            "88.917004048583 % completed\n",
            "88.96761133603239 % completed\n",
            "89.01821862348179 % completed\n",
            "89.06882591093117 % completed\n",
            "89.11943319838056 % completed\n",
            "89.17004048582996 % completed\n",
            "89.22064777327935 % completed\n",
            "89.27125506072875 % completed\n",
            "89.32186234817814 % completed\n",
            "89.37246963562752 % completed\n",
            "89.42307692307692 % completed\n",
            "89.47368421052632 % completed\n",
            "89.52429149797571 % completed\n",
            "89.5748987854251 % completed\n",
            "89.6255060728745 % completed\n",
            "89.67611336032388 % completed\n",
            "89.72672064777328 % completed\n",
            "89.77732793522267 % completed\n",
            "89.82793522267207 % completed\n",
            "89.87854251012146 % completed\n",
            "89.92914979757084 % completed\n",
            "89.97975708502024 % completed\n",
            "90.03036437246963 % completed\n",
            "90.08097165991903 % completed\n",
            "90.13157894736842 % completed\n",
            "90.18218623481782 % completed\n",
            "90.2327935222672 % completed\n",
            "90.2834008097166 % completed\n",
            "90.33400809716599 % completed\n",
            "90.38461538461539 % completed\n",
            "90.43522267206478 % completed\n",
            "90.48582995951416 % completed\n",
            "90.53643724696356 % completed\n",
            "90.58704453441295 % completed\n",
            "90.63765182186235 % completed\n",
            "90.68825910931174 % completed\n",
            "90.73886639676114 % completed\n",
            "90.78947368421052 % completed\n",
            "90.84008097165992 % completed\n",
            "90.89068825910931 % completed\n",
            "90.9412955465587 % completed\n",
            "90.9919028340081 % completed\n",
            "91.0425101214575 % completed\n",
            "91.09311740890688 % completed\n",
            "91.14372469635627 % completed\n",
            "91.19433198380567 % completed\n",
            "91.24493927125506 % completed\n",
            "91.29554655870446 % completed\n",
            "91.34615384615384 % completed\n",
            "91.39676113360323 % completed\n",
            "91.44736842105263 % completed\n",
            "91.49797570850203 % completed\n",
            "91.54858299595142 % completed\n",
            "91.59919028340082 % completed\n",
            "91.6497975708502 % completed\n",
            "91.70040485829959 % completed\n",
            "91.75101214574899 % completed\n",
            "91.80161943319838 % completed\n",
            "91.85222672064778 % completed\n",
            "91.90283400809717 % completed\n",
            "91.95344129554655 % completed\n",
            "92.00404858299595 % completed\n",
            "92.05465587044534 % completed\n",
            "92.10526315789474 % completed\n",
            "92.15587044534414 % completed\n",
            "92.20647773279352 % completed\n",
            "92.25708502024291 % completed\n",
            "92.3076923076923 % completed\n",
            "92.3582995951417 % completed\n",
            "92.4089068825911 % completed\n",
            "92.45951417004049 % completed\n",
            "92.51012145748987 % completed\n",
            "92.56072874493927 % completed\n",
            "92.61133603238866 % completed\n",
            "92.66194331983806 % completed\n",
            "92.71255060728745 % completed\n",
            "92.76315789473684 % completed\n",
            "92.81376518218623 % completed\n",
            "92.86437246963563 % completed\n",
            "92.91497975708502 % completed\n",
            "92.96558704453442 % completed\n",
            "93.01619433198381 % completed\n",
            "93.06680161943319 % completed\n",
            "93.11740890688259 % completed\n",
            "93.16801619433198 % completed\n",
            "93.21862348178138 % completed\n",
            "93.26923076923077 % completed\n",
            "93.31983805668017 % completed\n",
            "93.37044534412955 % completed\n",
            "93.42105263157895 % completed\n",
            "93.47165991902834 % completed\n",
            "93.52226720647774 % completed\n",
            "93.57287449392713 % completed\n",
            "93.62348178137651 % completed\n",
            "93.67408906882591 % completed\n",
            "93.7246963562753 % completed\n",
            "93.7753036437247 % completed\n",
            "93.82591093117409 % completed\n",
            "93.87651821862349 % completed\n",
            "93.92712550607287 % completed\n",
            "93.97773279352226 % completed\n",
            "94.02834008097166 % completed\n",
            "94.07894736842105 % completed\n",
            "94.12955465587045 % completed\n",
            "94.18016194331983 % completed\n",
            "94.23076923076923 % completed\n",
            "94.28137651821862 % completed\n",
            "94.33198380566802 % completed\n",
            "94.38259109311741 % completed\n",
            "94.43319838056681 % completed\n",
            "94.48380566801619 % completed\n",
            "94.53441295546558 % completed\n",
            "94.58502024291498 % completed\n",
            "94.63562753036437 % completed\n",
            "94.68623481781377 % completed\n",
            "94.73684210526316 % completed\n",
            "94.78744939271255 % completed\n",
            "94.83805668016194 % completed\n",
            "94.88866396761134 % completed\n",
            "94.93927125506073 % completed\n",
            "94.98987854251013 % completed\n",
            "95.04048582995951 % completed\n",
            "95.0910931174089 % completed\n",
            "95.1417004048583 % completed\n",
            "95.1923076923077 % completed\n",
            "95.24291497975709 % completed\n",
            "95.29352226720648 % completed\n",
            "95.34412955465586 % completed\n",
            "95.39473684210526 % completed\n",
            "95.44534412955466 % completed\n",
            "95.49595141700405 % completed\n",
            "95.54655870445345 % completed\n",
            "95.59716599190283 % completed\n",
            "95.64777327935222 % completed\n",
            "95.69838056680162 % completed\n",
            "95.74898785425101 % completed\n",
            "95.79959514170041 % completed\n",
            "95.8502024291498 % completed\n",
            "95.90080971659918 % completed\n",
            "95.95141700404858 % completed\n",
            "96.00202429149797 % completed\n",
            "96.05263157894737 % completed\n",
            "96.10323886639677 % completed\n",
            "96.15384615384616 % completed\n",
            "96.20445344129554 % completed\n",
            "96.25506072874494 % completed\n",
            "96.30566801619433 % completed\n",
            "96.35627530364373 % completed\n",
            "96.40688259109312 % completed\n",
            "96.4574898785425 % completed\n",
            "96.5080971659919 % completed\n",
            "96.5587044534413 % completed\n",
            "96.60931174089069 % completed\n",
            "96.65991902834008 % completed\n",
            "96.71052631578948 % completed\n",
            "96.76113360323886 % completed\n",
            "96.81174089068826 % completed\n",
            "96.86234817813765 % completed\n",
            "96.91295546558705 % completed\n",
            "96.96356275303644 % completed\n",
            "97.01417004048584 % completed\n",
            "97.06477732793522 % completed\n",
            "97.11538461538461 % completed\n",
            "97.16599190283401 % completed\n",
            "97.2165991902834 % completed\n",
            "97.2672064777328 % completed\n",
            "97.31781376518218 % completed\n",
            "97.36842105263158 % completed\n",
            "97.41902834008097 % completed\n",
            "97.46963562753037 % completed\n",
            "97.52024291497976 % completed\n",
            "97.57085020242916 % completed\n",
            "97.62145748987854 % completed\n",
            "97.67206477732793 % completed\n",
            "97.72267206477733 % completed\n",
            "97.77327935222672 % completed\n",
            "97.82388663967612 % completed\n",
            "97.8744939271255 % completed\n",
            "97.9251012145749 % completed\n",
            "97.97570850202429 % completed\n",
            "98.02631578947368 % completed\n",
            "98.07692307692308 % completed\n",
            "98.12753036437248 % completed\n",
            "98.17813765182186 % completed\n",
            "98.22874493927125 % completed\n",
            "98.27935222672065 % completed\n",
            "98.32995951417004 % completed\n",
            "98.38056680161944 % completed\n",
            "98.43117408906883 % completed\n",
            "98.48178137651821 % completed\n",
            "98.53238866396761 % completed\n",
            "98.582995951417 % completed\n",
            "98.6336032388664 % completed\n",
            "98.6842105263158 % completed\n",
            "98.73481781376518 % completed\n",
            "98.78542510121457 % completed\n",
            "98.83603238866397 % completed\n",
            "98.88663967611336 % completed\n",
            "98.93724696356276 % completed\n",
            "98.98785425101215 % completed\n",
            "99.03846153846153 % completed\n",
            "99.08906882591093 % completed\n",
            "99.13967611336032 % completed\n",
            "99.19028340080972 % completed\n",
            "99.24089068825911 % completed\n",
            "99.2914979757085 % completed\n",
            "99.34210526315789 % completed\n",
            "99.39271255060729 % completed\n",
            "99.44331983805668 % completed\n",
            "99.49392712550608 % completed\n",
            "99.54453441295547 % completed\n",
            "99.59514170040485 % completed\n",
            "99.64574898785425 % completed\n",
            "99.69635627530364 % completed\n",
            "99.74696356275304 % completed\n",
            "99.79757085020243 % completed\n",
            "99.84817813765183 % completed\n",
            "99.89878542510121 % completed\n",
            "99.9493927125506 % completed\n",
            "40.368852459016395\n",
            "90.97932762580915\n",
            "0.03445183527272374\n",
            "{'ू', 'म', 'व', 'ई', '्', 'ड़', '़', 'ड', 'ल', 'ह', 'घ', 'द', 'उ', 'ए', 'ढ', 'ग', 'े', 'क़', 'स', 'ु', 'ौ', 'ॉ', 'ि', 'श', 'ज़', 'ध', 'क', 'फ', 'ो', 'थ', 'ऑ', 'ब', ' ', 'अ', 'ष', 'भ', 'ँ', 'य', 'ं', 'र', 'ऐ', 'च', 'ै', 'इ', 'ओ', 'ी', 'ण', 'ट', 'न', 'ॅ', 'त', 'ा', 'ज'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RqQ1fIsLwkGE"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this tutorial, you learned about positional encoding, multi-head attention, the importance of masking and how to create a transformer.\n",
        "\n",
        "Try using a different dataset to train the transformer. You can also create the base transformer or transformer XL by changing the hyperparameters above. You can also use the layers defined here to create [BERT](https://arxiv.org/abs/1810.04805) and train state of the art models. Futhermore, you can implement beam search to get better predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q93OgSuIZ3LA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for (batch, (inp, tar)) in enumerate(dataset):\n",
        "  print(inp[0][0] == char2idxHi[\"$\"])\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr_iUf-jbAmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding = tf.keras.layers.Embedding(4, 128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbFsYYEu_kn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuD3RRqx_o9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}